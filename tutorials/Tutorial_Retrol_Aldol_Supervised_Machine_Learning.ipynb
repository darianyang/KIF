{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for Supervised and Unsupervised Learning on Simulations of a Retro Aldolase\n",
    "\n",
    "In this jupyter notebook we will use the model_building.py module to identify differences in the molecular interactions for a retro aldolase when it is in a catatlytically competent state and when it is \n",
    "\n",
    "\n",
    "across PTP1B\n",
    "when the WPD-loop of PTP1B is in the Closed state, versus when the WPD-loop is in the Open state.\n",
    "This notebook will also cover all the pre- and post-processing steps requireds to prepare, analyse and visualise the results.\n",
    "\n",
    "The dataset used here is for PTP1B is the same as what we used in the manuscript. \n",
    "\n",
    "<center><img src=\"miscellaneous/TODO.png\" alt=\"Drawing\" style=\"width: 70%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # note temporary... \n",
    "sys.path.append(\"..\") # note temporary...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from key_interactions_finder import pycontact_processing\n",
    "from key_interactions_finder import data_preperation\n",
    "from key_interactions_finder import model_building\n",
    "from key_interactions_finder import post_proccessing\n",
    "from key_interactions_finder import pymol_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Process PyContact files with the pycontact_processing.py module \n",
    "\n",
    "In this section we will work with the PyContact output files generated. \n",
    "Here we will merge our seperate runs together and remove any false interactions that can be generated by the PyContact library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your PyContact file(s) have been succefully processed.\n",
      "You have 3056 features and 10000 observations.\n",
      "The fully processed dataframe is accesible from the '.prepared_df' class attribute.\n"
     ]
    }
   ],
   "source": [
    "pycontact_files_horizontal = [\"PyContact_Per_Frame_Interactions_Block1.csv\", \"PyContact_Per_Frame_Interactions_Block2.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block3.csv\", \"PyContact_Per_Frame_Interactions_Block4.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block5.csv\", \"PyContact_Per_Frame_Interactions_Block6.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block7.csv\", \"PyContact_Per_Frame_Interactions_Block8.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block9.csv\", \"PyContact_Per_Frame_Interactions_Block10.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block11.csv\", \"PyContact_Per_Frame_Interactions_Block12.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block13.csv\", \"PyContact_Per_Frame_Interactions_Block14.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block15.csv\", \"PyContact_Per_Frame_Interactions_Block16.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block17.csv\"]\n",
    "\n",
    "pycontact_dataset = pycontact_processing.PyContactInitializer(\n",
    "    pycontact_files=pycontact_files_horizontal,\n",
    "    multiple_files=True,\n",
    "    merge_files_method=\"horizontal\",  \n",
    "    remove_false_interactions=True,\n",
    "    in_dir=\"datasets/retrol_aldolase_data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1Pro 140Glu Hbond bb-sc</th>\n",
       "      <th>1Pro 135Ile Hbond bb-bb</th>\n",
       "      <th>1Pro 136Leu Hbond bb-bb</th>\n",
       "      <th>1Pro 113Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 12Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 137Thr Hbond bb-sc</th>\n",
       "      <th>1Pro 3Tyr Hbond bb-bb</th>\n",
       "      <th>2Arg 137Thr Hbond sc-bb</th>\n",
       "      <th>2Arg 140Glu Hbond bb-sc</th>\n",
       "      <th>2Arg 136Leu Hbond sc-bb</th>\n",
       "      <th>...</th>\n",
       "      <th>242Ile 212Ile Other bb-sc</th>\n",
       "      <th>246Ile 46Ala Other sc-bb</th>\n",
       "      <th>242Ile 234Ser Other sc-bb</th>\n",
       "      <th>244Glu 222Arg Other bb-sc</th>\n",
       "      <th>241Lys 211Gly Other sc-bb</th>\n",
       "      <th>241Lys 71Phe Other bb-sc</th>\n",
       "      <th>246Ile 77Val Other sc-bb</th>\n",
       "      <th>242Ile 237Arg Other sc-bb</th>\n",
       "      <th>245Leu 44Ile Other bb-sc</th>\n",
       "      <th>242Ile 48Ile Other sc-bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.69070</td>\n",
       "      <td>2.69143</td>\n",
       "      <td>3.20350</td>\n",
       "      <td>3.28620</td>\n",
       "      <td>1.36506</td>\n",
       "      <td>0.74495</td>\n",
       "      <td>0.64727</td>\n",
       "      <td>3.34225</td>\n",
       "      <td>0.87675</td>\n",
       "      <td>9.87756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.47441</td>\n",
       "      <td>3.23497</td>\n",
       "      <td>4.82080</td>\n",
       "      <td>1.07496</td>\n",
       "      <td>0.25386</td>\n",
       "      <td>2.58459</td>\n",
       "      <td>0.45446</td>\n",
       "      <td>2.34583</td>\n",
       "      <td>0.45081</td>\n",
       "      <td>9.17317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.11200</td>\n",
       "      <td>1.66876</td>\n",
       "      <td>1.58322</td>\n",
       "      <td>2.21242</td>\n",
       "      <td>0.02944</td>\n",
       "      <td>1.15886</td>\n",
       "      <td>0.81023</td>\n",
       "      <td>2.03891</td>\n",
       "      <td>0.84995</td>\n",
       "      <td>6.66903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.28064</td>\n",
       "      <td>3.30286</td>\n",
       "      <td>1.54644</td>\n",
       "      <td>0.05986</td>\n",
       "      <td>0.96466</td>\n",
       "      <td>2.25997</td>\n",
       "      <td>0.43410</td>\n",
       "      <td>1.61199</td>\n",
       "      <td>0.36436</td>\n",
       "      <td>7.82080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.54559</td>\n",
       "      <td>2.78183</td>\n",
       "      <td>1.79891</td>\n",
       "      <td>0.27192</td>\n",
       "      <td>0.44629</td>\n",
       "      <td>1.13325</td>\n",
       "      <td>0.74145</td>\n",
       "      <td>0.25292</td>\n",
       "      <td>0.07107</td>\n",
       "      <td>2.40651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10.43428</td>\n",
       "      <td>2.87244</td>\n",
       "      <td>0.37792</td>\n",
       "      <td>0.84401</td>\n",
       "      <td>1.36240</td>\n",
       "      <td>0.45684</td>\n",
       "      <td>0.79760</td>\n",
       "      <td>4.82421</td>\n",
       "      <td>0.83238</td>\n",
       "      <td>8.17372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7.96627</td>\n",
       "      <td>3.38587</td>\n",
       "      <td>0.16006</td>\n",
       "      <td>0.06228</td>\n",
       "      <td>0.51337</td>\n",
       "      <td>4.56594</td>\n",
       "      <td>0.10768</td>\n",
       "      <td>4.04402</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.07718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7.35284</td>\n",
       "      <td>3.23050</td>\n",
       "      <td>0.00974</td>\n",
       "      <td>0.76542</td>\n",
       "      <td>0.93003</td>\n",
       "      <td>0.90531</td>\n",
       "      <td>0.45525</td>\n",
       "      <td>3.65877</td>\n",
       "      <td>0.09956</td>\n",
       "      <td>10.29806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7.92164</td>\n",
       "      <td>2.47504</td>\n",
       "      <td>0.27218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10206</td>\n",
       "      <td>2.02611</td>\n",
       "      <td>0.10234</td>\n",
       "      <td>1.57470</td>\n",
       "      <td>0.01281</td>\n",
       "      <td>5.87328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8.05632</td>\n",
       "      <td>3.65106</td>\n",
       "      <td>0.13702</td>\n",
       "      <td>0.81143</td>\n",
       "      <td>1.85742</td>\n",
       "      <td>2.68653</td>\n",
       "      <td>0.22565</td>\n",
       "      <td>2.16886</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>5.60869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3056 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1Pro 140Glu Hbond bb-sc  1Pro 135Ile Hbond bb-bb  \\\n",
       "0                    10.69070                  2.69143   \n",
       "1                    11.47441                  3.23497   \n",
       "2                    10.11200                  1.66876   \n",
       "3                     9.28064                  3.30286   \n",
       "4                     8.54559                  2.78183   \n",
       "...                       ...                      ...   \n",
       "9995                 10.43428                  2.87244   \n",
       "9996                  7.96627                  3.38587   \n",
       "9997                  7.35284                  3.23050   \n",
       "9998                  7.92164                  2.47504   \n",
       "9999                  8.05632                  3.65106   \n",
       "\n",
       "      1Pro 136Leu Hbond bb-bb  1Pro 113Val Hydrophobic sc-sc  \\\n",
       "0                     3.20350                        3.28620   \n",
       "1                     4.82080                        1.07496   \n",
       "2                     1.58322                        2.21242   \n",
       "3                     1.54644                        0.05986   \n",
       "4                     1.79891                        0.27192   \n",
       "...                       ...                            ...   \n",
       "9995                  0.37792                        0.84401   \n",
       "9996                  0.16006                        0.06228   \n",
       "9997                  0.00974                        0.76542   \n",
       "9998                  0.27218                        0.00000   \n",
       "9999                  0.13702                        0.81143   \n",
       "\n",
       "      1Pro 12Val Hydrophobic sc-sc  1Pro 137Thr Hbond bb-sc  \\\n",
       "0                          1.36506                  0.74495   \n",
       "1                          0.25386                  2.58459   \n",
       "2                          0.02944                  1.15886   \n",
       "3                          0.96466                  2.25997   \n",
       "4                          0.44629                  1.13325   \n",
       "...                            ...                      ...   \n",
       "9995                       1.36240                  0.45684   \n",
       "9996                       0.51337                  4.56594   \n",
       "9997                       0.93003                  0.90531   \n",
       "9998                       0.10206                  2.02611   \n",
       "9999                       1.85742                  2.68653   \n",
       "\n",
       "      1Pro 3Tyr Hbond bb-bb  2Arg 137Thr Hbond sc-bb  2Arg 140Glu Hbond bb-sc  \\\n",
       "0                   0.64727                  3.34225                  0.87675   \n",
       "1                   0.45446                  2.34583                  0.45081   \n",
       "2                   0.81023                  2.03891                  0.84995   \n",
       "3                   0.43410                  1.61199                  0.36436   \n",
       "4                   0.74145                  0.25292                  0.07107   \n",
       "...                     ...                      ...                      ...   \n",
       "9995                0.79760                  4.82421                  0.83238   \n",
       "9996                0.10768                  4.04402                  0.00000   \n",
       "9997                0.45525                  3.65877                  0.09956   \n",
       "9998                0.10234                  1.57470                  0.01281   \n",
       "9999                0.22565                  2.16886                  0.03367   \n",
       "\n",
       "      2Arg 136Leu Hbond sc-bb  ...  242Ile 212Ile Other bb-sc  \\\n",
       "0                     9.87756  ...                        0.0   \n",
       "1                     9.17317  ...                        0.0   \n",
       "2                     6.66903  ...                        0.0   \n",
       "3                     7.82080  ...                        0.0   \n",
       "4                     2.40651  ...                        0.0   \n",
       "...                       ...  ...                        ...   \n",
       "9995                  8.17372  ...                        0.0   \n",
       "9996                  5.07718  ...                        0.0   \n",
       "9997                 10.29806  ...                        0.0   \n",
       "9998                  5.87328  ...                        0.0   \n",
       "9999                  5.60869  ...                        0.0   \n",
       "\n",
       "      246Ile 46Ala Other sc-bb  242Ile 234Ser Other sc-bb  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "9995                       0.0                        0.0   \n",
       "9996                       0.0                        0.0   \n",
       "9997                       0.0                        0.0   \n",
       "9998                       0.0                        0.0   \n",
       "9999                       0.0                        0.0   \n",
       "\n",
       "      244Glu 222Arg Other bb-sc  241Lys 211Gly Other sc-bb  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "9995                        0.0                        0.0   \n",
       "9996                        0.0                        0.0   \n",
       "9997                        0.0                        0.0   \n",
       "9998                        0.0                        0.0   \n",
       "9999                        0.0                        0.0   \n",
       "\n",
       "      241Lys 71Phe Other bb-sc  246Ile 77Val Other sc-bb  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "9995                       0.0                       0.0   \n",
       "9996                       0.0                       0.0   \n",
       "9997                       0.0                       0.0   \n",
       "9998                       0.0                       0.0   \n",
       "9999                       0.0                       0.0   \n",
       "\n",
       "      242Ile 237Arg Other sc-bb  245Leu 44Ile Other bb-sc  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "9995                        0.0                       0.0   \n",
       "9996                        0.0                       0.0   \n",
       "9997                        0.0                       0.0   \n",
       "9998                        0.0                       0.0   \n",
       "9999                        0.0                       0.0   \n",
       "\n",
       "      242Ile 48Ile Other sc-bb  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "...                        ...  \n",
       "9995                       0.0  \n",
       "9996                       0.0  \n",
       "9997                       0.0  \n",
       "9998                       0.0  \n",
       "9999                       0.0  \n",
       "\n",
       "[10000 rows x 3056 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As outputted above, we can inspect the newly prepared dataset by accessing the '.prepared_df' class attribute as follows:\n",
    "pycontact_dataset.prepared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Prepare the Dataset for Statistical Analysis with the data_preperation.py module. \n",
    "\n",
    "In this step, we take our dataframe and merge our per frame classifications file to it.\n",
    "We can also optionally perform several forms of filtering to select what types of interactions we\n",
    "would like to study.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your features and class datasets have been succesufully merged.\n",
      "You can access this dataset through the class attribute: '.df_feat_class'.\n"
     ]
    }
   ],
   "source": [
    "# First we generate an instance of the SupervisedFeatureData class (because we have per frame class labels).\n",
    "\n",
    "classifications_file = \"datasets/retrol_aldolase_data/4a2s_RA95_5_Classifications.txt\"\n",
    "\n",
    "supervised_dataset = data_preperation.SupervisedFeatureData(\n",
    "    input_df=pycontact_dataset.prepared_df,\n",
    "    classifications_file=classifications_file,\n",
    "    header_present=True # If your classifications_file has a header present, set to True.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>1Pro 140Glu Hbond bb-sc</th>\n",
       "      <th>1Pro 135Ile Hbond bb-bb</th>\n",
       "      <th>1Pro 136Leu Hbond bb-bb</th>\n",
       "      <th>1Pro 113Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 12Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 137Thr Hbond bb-sc</th>\n",
       "      <th>1Pro 3Tyr Hbond bb-bb</th>\n",
       "      <th>2Arg 137Thr Hbond sc-bb</th>\n",
       "      <th>2Arg 140Glu Hbond bb-sc</th>\n",
       "      <th>...</th>\n",
       "      <th>242Ile 212Ile Other bb-sc</th>\n",
       "      <th>246Ile 46Ala Other sc-bb</th>\n",
       "      <th>242Ile 234Ser Other sc-bb</th>\n",
       "      <th>244Glu 222Arg Other bb-sc</th>\n",
       "      <th>241Lys 211Gly Other sc-bb</th>\n",
       "      <th>241Lys 71Phe Other bb-sc</th>\n",
       "      <th>246Ile 77Val Other sc-bb</th>\n",
       "      <th>242Ile 237Arg Other sc-bb</th>\n",
       "      <th>245Leu 44Ile Other bb-sc</th>\n",
       "      <th>242Ile 48Ile Other sc-bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>10.69070</td>\n",
       "      <td>2.69143</td>\n",
       "      <td>3.20350</td>\n",
       "      <td>3.28620</td>\n",
       "      <td>1.36506</td>\n",
       "      <td>0.74495</td>\n",
       "      <td>0.64727</td>\n",
       "      <td>3.34225</td>\n",
       "      <td>0.87675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>11.47441</td>\n",
       "      <td>3.23497</td>\n",
       "      <td>4.82080</td>\n",
       "      <td>1.07496</td>\n",
       "      <td>0.25386</td>\n",
       "      <td>2.58459</td>\n",
       "      <td>0.45446</td>\n",
       "      <td>2.34583</td>\n",
       "      <td>0.45081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>10.11200</td>\n",
       "      <td>1.66876</td>\n",
       "      <td>1.58322</td>\n",
       "      <td>2.21242</td>\n",
       "      <td>0.02944</td>\n",
       "      <td>1.15886</td>\n",
       "      <td>0.81023</td>\n",
       "      <td>2.03891</td>\n",
       "      <td>0.84995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>9.28064</td>\n",
       "      <td>3.30286</td>\n",
       "      <td>1.54644</td>\n",
       "      <td>0.05986</td>\n",
       "      <td>0.96466</td>\n",
       "      <td>2.25997</td>\n",
       "      <td>0.43410</td>\n",
       "      <td>1.61199</td>\n",
       "      <td>0.36436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>8.54559</td>\n",
       "      <td>2.78183</td>\n",
       "      <td>1.79891</td>\n",
       "      <td>0.27192</td>\n",
       "      <td>0.44629</td>\n",
       "      <td>1.13325</td>\n",
       "      <td>0.74145</td>\n",
       "      <td>0.25292</td>\n",
       "      <td>0.07107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>10.43428</td>\n",
       "      <td>2.87244</td>\n",
       "      <td>0.37792</td>\n",
       "      <td>0.84401</td>\n",
       "      <td>1.36240</td>\n",
       "      <td>0.45684</td>\n",
       "      <td>0.79760</td>\n",
       "      <td>4.82421</td>\n",
       "      <td>0.83238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>7.96627</td>\n",
       "      <td>3.38587</td>\n",
       "      <td>0.16006</td>\n",
       "      <td>0.06228</td>\n",
       "      <td>0.51337</td>\n",
       "      <td>4.56594</td>\n",
       "      <td>0.10768</td>\n",
       "      <td>4.04402</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>7.35284</td>\n",
       "      <td>3.23050</td>\n",
       "      <td>0.00974</td>\n",
       "      <td>0.76542</td>\n",
       "      <td>0.93003</td>\n",
       "      <td>0.90531</td>\n",
       "      <td>0.45525</td>\n",
       "      <td>3.65877</td>\n",
       "      <td>0.09956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>7.92164</td>\n",
       "      <td>2.47504</td>\n",
       "      <td>0.27218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10206</td>\n",
       "      <td>2.02611</td>\n",
       "      <td>0.10234</td>\n",
       "      <td>1.57470</td>\n",
       "      <td>0.01281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>8.05632</td>\n",
       "      <td>3.65106</td>\n",
       "      <td>0.13702</td>\n",
       "      <td>0.81143</td>\n",
       "      <td>1.85742</td>\n",
       "      <td>2.68653</td>\n",
       "      <td>0.22565</td>\n",
       "      <td>2.16886</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3057 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classes  1Pro 140Glu Hbond bb-sc  1Pro 135Ile Hbond bb-bb  \\\n",
       "0     NotCatComp                 10.69070                  2.69143   \n",
       "1     NotCatComp                 11.47441                  3.23497   \n",
       "2     NotCatComp                 10.11200                  1.66876   \n",
       "3     NotCatComp                  9.28064                  3.30286   \n",
       "4     NotCatComp                  8.54559                  2.78183   \n",
       "...          ...                      ...                      ...   \n",
       "9995     CatComp                 10.43428                  2.87244   \n",
       "9996     CatComp                  7.96627                  3.38587   \n",
       "9997     CatComp                  7.35284                  3.23050   \n",
       "9998     CatComp                  7.92164                  2.47504   \n",
       "9999     CatComp                  8.05632                  3.65106   \n",
       "\n",
       "      1Pro 136Leu Hbond bb-bb  1Pro 113Val Hydrophobic sc-sc  \\\n",
       "0                     3.20350                        3.28620   \n",
       "1                     4.82080                        1.07496   \n",
       "2                     1.58322                        2.21242   \n",
       "3                     1.54644                        0.05986   \n",
       "4                     1.79891                        0.27192   \n",
       "...                       ...                            ...   \n",
       "9995                  0.37792                        0.84401   \n",
       "9996                  0.16006                        0.06228   \n",
       "9997                  0.00974                        0.76542   \n",
       "9998                  0.27218                        0.00000   \n",
       "9999                  0.13702                        0.81143   \n",
       "\n",
       "      1Pro 12Val Hydrophobic sc-sc  1Pro 137Thr Hbond bb-sc  \\\n",
       "0                          1.36506                  0.74495   \n",
       "1                          0.25386                  2.58459   \n",
       "2                          0.02944                  1.15886   \n",
       "3                          0.96466                  2.25997   \n",
       "4                          0.44629                  1.13325   \n",
       "...                            ...                      ...   \n",
       "9995                       1.36240                  0.45684   \n",
       "9996                       0.51337                  4.56594   \n",
       "9997                       0.93003                  0.90531   \n",
       "9998                       0.10206                  2.02611   \n",
       "9999                       1.85742                  2.68653   \n",
       "\n",
       "      1Pro 3Tyr Hbond bb-bb  2Arg 137Thr Hbond sc-bb  2Arg 140Glu Hbond bb-sc  \\\n",
       "0                   0.64727                  3.34225                  0.87675   \n",
       "1                   0.45446                  2.34583                  0.45081   \n",
       "2                   0.81023                  2.03891                  0.84995   \n",
       "3                   0.43410                  1.61199                  0.36436   \n",
       "4                   0.74145                  0.25292                  0.07107   \n",
       "...                     ...                      ...                      ...   \n",
       "9995                0.79760                  4.82421                  0.83238   \n",
       "9996                0.10768                  4.04402                  0.00000   \n",
       "9997                0.45525                  3.65877                  0.09956   \n",
       "9998                0.10234                  1.57470                  0.01281   \n",
       "9999                0.22565                  2.16886                  0.03367   \n",
       "\n",
       "      ...  242Ile 212Ile Other bb-sc  246Ile 46Ala Other sc-bb  \\\n",
       "0     ...                        0.0                       0.0   \n",
       "1     ...                        0.0                       0.0   \n",
       "2     ...                        0.0                       0.0   \n",
       "3     ...                        0.0                       0.0   \n",
       "4     ...                        0.0                       0.0   \n",
       "...   ...                        ...                       ...   \n",
       "9995  ...                        0.0                       0.0   \n",
       "9996  ...                        0.0                       0.0   \n",
       "9997  ...                        0.0                       0.0   \n",
       "9998  ...                        0.0                       0.0   \n",
       "9999  ...                        0.0                       0.0   \n",
       "\n",
       "      242Ile 234Ser Other sc-bb  244Glu 222Arg Other bb-sc  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "9995                        0.0                        0.0   \n",
       "9996                        0.0                        0.0   \n",
       "9997                        0.0                        0.0   \n",
       "9998                        0.0                        0.0   \n",
       "9999                        0.0                        0.0   \n",
       "\n",
       "      241Lys 211Gly Other sc-bb  241Lys 71Phe Other bb-sc  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "9995                        0.0                       0.0   \n",
       "9996                        0.0                       0.0   \n",
       "9997                        0.0                       0.0   \n",
       "9998                        0.0                       0.0   \n",
       "9999                        0.0                       0.0   \n",
       "\n",
       "      246Ile 77Val Other sc-bb  242Ile 237Arg Other sc-bb  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "9995                       0.0                        0.0   \n",
       "9996                       0.0                        0.0   \n",
       "9997                       0.0                        0.0   \n",
       "9998                       0.0                        0.0   \n",
       "9999                       0.0                        0.0   \n",
       "\n",
       "      245Leu 44Ile Other bb-sc  242Ile 48Ile Other sc-bb  \n",
       "0                          0.0                       0.0  \n",
       "1                          0.0                       0.0  \n",
       "2                          0.0                       0.0  \n",
       "3                          0.0                       0.0  \n",
       "4                          0.0                       0.0  \n",
       "...                        ...                       ...  \n",
       "9995                       0.0                       0.0  \n",
       "9996                       0.0                       0.0  \n",
       "9997                       0.0                       0.0  \n",
       "9998                       0.0                       0.0  \n",
       "9999                       0.0                       0.0  \n",
       "\n",
       "[10000 rows x 3057 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As stated above to access the newly generated dataframe we can use the class attribute as follows\n",
    "supervised_dataset.df_feat_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional Feature Filtering\n",
    "\n",
    "In the above dataframe we have 3057 columns (so 3057 features). We can take all of these forward for the stastical analysis or we can perform some filtering in advance (the choice is yours). \n",
    "There are four built in filtering methods available to you:\n",
    "\n",
    "1. filter_by_occupancy(min_occupancy) - Remove features that have an %occupancy less than the provided cut-off. %Occupancy is the % of frames with a non 0 value, i.e. the interaction is present in that frame.\n",
    "\n",
    "2. filter_by_interaction_type(interaction_types_included). - PyContact defines four types of interactions (\"Hbond\", \"Saltbr\", \"Hydrophobic\", \"Other\"). You select the interactions your want to INCLUDE.\n",
    "\n",
    "3. filter_by_main_or_side_chain(main_side_chain_types_included) PyContact can also define if each interaction is primarily from the backbone or side-chain for each residue. You select the interaction combinations you want to INCLUDE. Options are: \"bb-bb\", \"sc-sc\", \"bb-sc\", \"sc-bb\". Where bb = backbone and sc = sidechain.\n",
    "\n",
    "4. filter_by_avg_strength(average_strength_cut_off) - PyContact calculates a per frame contact score/strength for each interaction. You can filter features by the average score. Values below the cut-off are removed. \n",
    "\n",
    "5. reset_filtering() - This method allows you to reset any filtering commands you have already called. (i.e. resets the filtered dataframe back to the unfiltered dataframe.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before any filtering: 3057\n",
      "Number of features after filtering by occupancy: 1413\n",
      "Number of features after NOT filtering by interaction type: 1413\n",
      "Number of features after NOT filtering by main or side chain: 1413\n",
      "Number of features after filtering by average interaction scores: 1107\n"
     ]
    }
   ],
   "source": [
    "# An example of filtering the dataset using the 4 available methods. \n",
    "\n",
    "print(f\"Number of features before any filtering: {len(supervised_dataset.df_feat_class.columns)}\")\n",
    "\n",
    "# Features with a %occupancy of less than 25% are removed. \n",
    "supervised_dataset.filter_by_occupancy(min_occupancy=25)\n",
    "print(f\"Number of features after filtering by occupancy: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# No filtering performed here as all possible combinations are included. \n",
    "supervised_dataset.filter_by_interaction_type(\n",
    "    interaction_types_included=[\"Hbond\", \"Saltbr\", \"Hydrophobic\", \"Other\"]) \n",
    "print(f\"Number of features after NOT filtering by interaction type: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# No filtering performed here as all possible combinations are included. \n",
    "supervised_dataset.filter_by_main_or_side_chain(\n",
    "    main_side_chain_types_included=[\"bb-bb\", \"sc-sc\", \"bb-sc\", \"sc-bb\"]  \n",
    ")\n",
    "print(f\"Number of features after NOT filtering by main or side chain: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# Features with average interaction scores less than 0.5 will be removed. \n",
    "supervised_dataset.filter_by_avg_strength(\n",
    "    average_strength_cut_off=0.5,  \n",
    ")\n",
    "print(f\"Number of features after filtering by average interaction scores: {len(supervised_dataset.df_filtered.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the class attributes of our SupervisedFeatureData() instance (we called it: supervised_dataset) using the special \"\\_\\_dict__\" method we can see two dataframes we could use in the machine learning to follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_df', 'classifications_file', 'header_present', 'df_feat_class', 'df_filtered'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are: \n",
    "- 'df_feat_class' - The unfiltered dataframe, 3057 features\n",
    "- 'df_filtered' - The filtered dataframe. Less than 3057 features. \n",
    "\n",
    "In the following section we will use the filtered dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Perform the Machine Learning with the model_building.py module. \n",
    "\n",
    "Now we will setup and run the supervised machine learning (ML) on the retro aldolase enzyme. Here we will apply to ML to distinguish between catalytically active and inactive conformations of the enzyme towards catalysis of XXXX. \n",
    "\n",
    "Describe the ML in more detail TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotCatComp    5571\n",
       "CatComp       3840\n",
       "Neither        589\n",
       "Name: Classes, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered[\"Classes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below is a summary of the machine learning you have planned.\n",
      "You will use 5-fold cross validation and perform 3 repeats.\n",
      "You will use up to 1107 features to build each model, with 85.0% of your data used for training the model, which is 7999 observations. \n",
      "15.0% of your data will be used for evaluating the best models produced by the 5-fold cross validation, which is 1412 observations.\n",
      "You have chosen to build 2 different machine learning models, each with the following hyperparameters: \n",
      " \n",
      "A CatBoost model, with grid search parameters: \n",
      "{'model': <catboost.core.CatBoostClassifier object at 0x000001C4D4B41310>, 'params': {'iterations': [50]}} \n",
      "\n",
      "A Random_Forest model, with grid search parameters: \n",
      "{'model': RandomForestClassifier(), 'params': {'n_estimators': [1]}} \n",
      "\n",
      "If you're happy with the above, lets get model building!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model.\n",
    "ml_model = model_building.SupervisedModel(\n",
    "    dataset=supervised_dataset.df_filtered,\n",
    "    evaluation_split_ratio=0.15,\n",
    "    classes_to_use=[\"CatComp\", \"NotCatComp\"],\n",
    "    models_to_use=[\"CatBoost\", \"Random_Forest\"],\n",
    "    scaling_method=\"min_max\",\n",
    "    out_dir=\"outputs/retro_aldol_ml\",\n",
    "    cross_validation_splits=5,\n",
    "    cross_validation_repeats=3,\n",
    "    search_approach=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4600479\ttotal: 340ms\tremaining: 16.7s\n",
      "1:\tlearn: 0.3509334\ttotal: 625ms\tremaining: 15s\n",
      "2:\tlearn: 0.2700726\ttotal: 941ms\tremaining: 14.7s\n",
      "3:\tlearn: 0.2225716\ttotal: 1.17s\tremaining: 13.5s\n",
      "4:\tlearn: 0.1977456\ttotal: 1.39s\tremaining: 12.5s\n",
      "5:\tlearn: 0.1765933\ttotal: 1.63s\tremaining: 11.9s\n",
      "6:\tlearn: 0.1579441\ttotal: 1.85s\tremaining: 11.4s\n",
      "7:\tlearn: 0.1435274\ttotal: 2.11s\tremaining: 11.1s\n",
      "8:\tlearn: 0.1342142\ttotal: 2.34s\tremaining: 10.7s\n",
      "9:\tlearn: 0.1283445\ttotal: 2.53s\tremaining: 10.1s\n",
      "10:\tlearn: 0.1134234\ttotal: 2.77s\tremaining: 9.83s\n",
      "11:\tlearn: 0.1104939\ttotal: 3.01s\tremaining: 9.54s\n",
      "12:\tlearn: 0.1057285\ttotal: 3.26s\tremaining: 9.28s\n",
      "13:\tlearn: 0.1012767\ttotal: 3.45s\tremaining: 8.87s\n",
      "14:\tlearn: 0.0981949\ttotal: 3.62s\tremaining: 8.44s\n",
      "15:\tlearn: 0.0933659\ttotal: 3.84s\tremaining: 8.15s\n",
      "16:\tlearn: 0.0867578\ttotal: 4.03s\tremaining: 7.82s\n",
      "17:\tlearn: 0.0838931\ttotal: 4.2s\tremaining: 7.47s\n",
      "18:\tlearn: 0.0801753\ttotal: 4.38s\tremaining: 7.15s\n",
      "19:\tlearn: 0.0778612\ttotal: 4.54s\tremaining: 6.82s\n",
      "20:\tlearn: 0.0765300\ttotal: 4.75s\tremaining: 6.55s\n",
      "21:\tlearn: 0.0727769\ttotal: 4.94s\tremaining: 6.29s\n",
      "22:\tlearn: 0.0711384\ttotal: 5.13s\tremaining: 6.03s\n",
      "23:\tlearn: 0.0688422\ttotal: 5.34s\tremaining: 5.78s\n",
      "24:\tlearn: 0.0668071\ttotal: 5.5s\tremaining: 5.5s\n",
      "25:\tlearn: 0.0602771\ttotal: 5.7s\tremaining: 5.26s\n",
      "26:\tlearn: 0.0584312\ttotal: 5.96s\tremaining: 5.07s\n",
      "27:\tlearn: 0.0563852\ttotal: 6.15s\tremaining: 4.83s\n",
      "28:\tlearn: 0.0549464\ttotal: 6.34s\tremaining: 4.59s\n",
      "29:\tlearn: 0.0540795\ttotal: 6.52s\tremaining: 4.35s\n",
      "30:\tlearn: 0.0528843\ttotal: 6.84s\tremaining: 4.19s\n",
      "31:\tlearn: 0.0517282\ttotal: 7s\tremaining: 3.94s\n",
      "32:\tlearn: 0.0492775\ttotal: 7.18s\tremaining: 3.7s\n",
      "33:\tlearn: 0.0466618\ttotal: 7.37s\tremaining: 3.47s\n",
      "34:\tlearn: 0.0458805\ttotal: 7.53s\tremaining: 3.23s\n",
      "35:\tlearn: 0.0449279\ttotal: 7.7s\tremaining: 3s\n",
      "36:\tlearn: 0.0417515\ttotal: 7.88s\tremaining: 2.77s\n",
      "37:\tlearn: 0.0393723\ttotal: 8.04s\tremaining: 2.54s\n",
      "38:\tlearn: 0.0386071\ttotal: 8.19s\tremaining: 2.31s\n",
      "39:\tlearn: 0.0377976\ttotal: 8.34s\tremaining: 2.08s\n",
      "40:\tlearn: 0.0369523\ttotal: 8.48s\tremaining: 1.86s\n",
      "41:\tlearn: 0.0362227\ttotal: 8.66s\tremaining: 1.65s\n",
      "42:\tlearn: 0.0353093\ttotal: 8.81s\tremaining: 1.43s\n",
      "43:\tlearn: 0.0345487\ttotal: 8.96s\tremaining: 1.22s\n",
      "44:\tlearn: 0.0336053\ttotal: 9.11s\tremaining: 1.01s\n",
      "45:\tlearn: 0.0331373\ttotal: 9.26s\tremaining: 805ms\n",
      "46:\tlearn: 0.0311705\ttotal: 9.41s\tremaining: 601ms\n",
      "47:\tlearn: 0.0301717\ttotal: 9.57s\tremaining: 399ms\n",
      "48:\tlearn: 0.0292227\ttotal: 9.73s\tremaining: 199ms\n",
      "49:\tlearn: 0.0279758\ttotal: 9.9s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4555332\ttotal: 183ms\tremaining: 8.96s\n",
      "1:\tlearn: 0.3492810\ttotal: 428ms\tremaining: 10.3s\n",
      "2:\tlearn: 0.2899910\ttotal: 785ms\tremaining: 12.3s\n",
      "3:\tlearn: 0.2423581\ttotal: 985ms\tremaining: 11.3s\n",
      "4:\tlearn: 0.2018378\ttotal: 1.16s\tremaining: 10.5s\n",
      "5:\tlearn: 0.1854671\ttotal: 1.32s\tremaining: 9.66s\n",
      "6:\tlearn: 0.1661331\ttotal: 1.48s\tremaining: 9.07s\n",
      "7:\tlearn: 0.1554685\ttotal: 1.64s\tremaining: 8.63s\n",
      "8:\tlearn: 0.1411337\ttotal: 1.8s\tremaining: 8.22s\n",
      "9:\tlearn: 0.1286583\ttotal: 1.97s\tremaining: 7.88s\n",
      "10:\tlearn: 0.1149157\ttotal: 2.23s\tremaining: 7.91s\n",
      "11:\tlearn: 0.1090742\ttotal: 2.48s\tremaining: 7.84s\n",
      "12:\tlearn: 0.1042665\ttotal: 2.69s\tremaining: 7.67s\n",
      "13:\tlearn: 0.0988731\ttotal: 2.89s\tremaining: 7.44s\n",
      "14:\tlearn: 0.0940901\ttotal: 3.06s\tremaining: 7.14s\n",
      "15:\tlearn: 0.0907885\ttotal: 3.23s\tremaining: 6.87s\n",
      "16:\tlearn: 0.0869871\ttotal: 3.4s\tremaining: 6.6s\n",
      "17:\tlearn: 0.0846675\ttotal: 3.55s\tremaining: 6.32s\n",
      "18:\tlearn: 0.0827233\ttotal: 3.7s\tremaining: 6.04s\n",
      "19:\tlearn: 0.0808788\ttotal: 3.87s\tremaining: 5.8s\n",
      "20:\tlearn: 0.0776999\ttotal: 4.04s\tremaining: 5.59s\n",
      "21:\tlearn: 0.0732562\ttotal: 4.23s\tremaining: 5.38s\n",
      "22:\tlearn: 0.0710030\ttotal: 4.39s\tremaining: 5.15s\n",
      "23:\tlearn: 0.0701067\ttotal: 4.56s\tremaining: 4.94s\n",
      "24:\tlearn: 0.0674206\ttotal: 4.74s\tremaining: 4.74s\n",
      "25:\tlearn: 0.0631564\ttotal: 4.91s\tremaining: 4.53s\n",
      "26:\tlearn: 0.0621124\ttotal: 5.08s\tremaining: 4.32s\n",
      "27:\tlearn: 0.0605931\ttotal: 5.24s\tremaining: 4.11s\n",
      "28:\tlearn: 0.0571934\ttotal: 5.41s\tremaining: 3.91s\n",
      "29:\tlearn: 0.0558876\ttotal: 5.57s\tremaining: 3.71s\n",
      "30:\tlearn: 0.0540459\ttotal: 5.73s\tremaining: 3.51s\n",
      "31:\tlearn: 0.0524483\ttotal: 5.88s\tremaining: 3.31s\n",
      "32:\tlearn: 0.0512147\ttotal: 6.04s\tremaining: 3.11s\n",
      "33:\tlearn: 0.0504217\ttotal: 6.2s\tremaining: 2.92s\n",
      "34:\tlearn: 0.0495618\ttotal: 6.36s\tremaining: 2.73s\n",
      "35:\tlearn: 0.0483902\ttotal: 6.51s\tremaining: 2.53s\n",
      "36:\tlearn: 0.0468840\ttotal: 6.67s\tremaining: 2.34s\n",
      "37:\tlearn: 0.0448082\ttotal: 6.83s\tremaining: 2.16s\n",
      "38:\tlearn: 0.0433171\ttotal: 6.98s\tremaining: 1.97s\n",
      "39:\tlearn: 0.0423913\ttotal: 7.15s\tremaining: 1.79s\n",
      "40:\tlearn: 0.0405351\ttotal: 7.32s\tremaining: 1.61s\n",
      "41:\tlearn: 0.0400511\ttotal: 7.49s\tremaining: 1.43s\n",
      "42:\tlearn: 0.0378550\ttotal: 7.64s\tremaining: 1.24s\n",
      "43:\tlearn: 0.0365787\ttotal: 7.79s\tremaining: 1.06s\n",
      "44:\tlearn: 0.0358023\ttotal: 7.94s\tremaining: 883ms\n",
      "45:\tlearn: 0.0346667\ttotal: 8.12s\tremaining: 706ms\n",
      "46:\tlearn: 0.0334815\ttotal: 8.3s\tremaining: 530ms\n",
      "47:\tlearn: 0.0325291\ttotal: 8.48s\tremaining: 353ms\n",
      "48:\tlearn: 0.0311561\ttotal: 8.63s\tremaining: 176ms\n",
      "49:\tlearn: 0.0296951\ttotal: 8.8s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4549231\ttotal: 195ms\tremaining: 9.57s\n",
      "1:\tlearn: 0.3308939\ttotal: 379ms\tremaining: 9.1s\n",
      "2:\tlearn: 0.2646702\ttotal: 533ms\tremaining: 8.35s\n",
      "3:\tlearn: 0.2250530\ttotal: 706ms\tremaining: 8.11s\n",
      "4:\tlearn: 0.2044726\ttotal: 878ms\tremaining: 7.9s\n",
      "5:\tlearn: 0.1812295\ttotal: 1.05s\tremaining: 7.74s\n",
      "6:\tlearn: 0.1663698\ttotal: 1.23s\tremaining: 7.54s\n",
      "7:\tlearn: 0.1452357\ttotal: 1.42s\tremaining: 7.44s\n",
      "8:\tlearn: 0.1347878\ttotal: 1.6s\tremaining: 7.28s\n",
      "9:\tlearn: 0.1262669\ttotal: 1.8s\tremaining: 7.19s\n",
      "10:\tlearn: 0.1179081\ttotal: 1.97s\tremaining: 6.99s\n",
      "11:\tlearn: 0.1142896\ttotal: 2.15s\tremaining: 6.8s\n",
      "12:\tlearn: 0.1082194\ttotal: 2.32s\tremaining: 6.6s\n",
      "13:\tlearn: 0.0998742\ttotal: 2.49s\tremaining: 6.42s\n",
      "14:\tlearn: 0.0965539\ttotal: 2.69s\tremaining: 6.27s\n",
      "15:\tlearn: 0.0944975\ttotal: 2.85s\tremaining: 6.06s\n",
      "16:\tlearn: 0.0900538\ttotal: 3.01s\tremaining: 5.84s\n",
      "17:\tlearn: 0.0870423\ttotal: 3.16s\tremaining: 5.63s\n",
      "18:\tlearn: 0.0840961\ttotal: 3.34s\tremaining: 5.45s\n",
      "19:\tlearn: 0.0815260\ttotal: 3.5s\tremaining: 5.25s\n",
      "20:\tlearn: 0.0759517\ttotal: 3.67s\tremaining: 5.07s\n",
      "21:\tlearn: 0.0745216\ttotal: 3.84s\tremaining: 4.89s\n",
      "22:\tlearn: 0.0714801\ttotal: 3.99s\tremaining: 4.69s\n",
      "23:\tlearn: 0.0674091\ttotal: 4.17s\tremaining: 4.52s\n",
      "24:\tlearn: 0.0653338\ttotal: 4.34s\tremaining: 4.34s\n",
      "25:\tlearn: 0.0630619\ttotal: 4.51s\tremaining: 4.16s\n",
      "26:\tlearn: 0.0617081\ttotal: 4.68s\tremaining: 3.99s\n",
      "27:\tlearn: 0.0582298\ttotal: 4.85s\tremaining: 3.81s\n",
      "28:\tlearn: 0.0565029\ttotal: 5s\tremaining: 3.62s\n",
      "29:\tlearn: 0.0545755\ttotal: 5.15s\tremaining: 3.43s\n",
      "30:\tlearn: 0.0524429\ttotal: 5.3s\tremaining: 3.25s\n",
      "31:\tlearn: 0.0515419\ttotal: 5.45s\tremaining: 3.06s\n",
      "32:\tlearn: 0.0505050\ttotal: 5.61s\tremaining: 2.89s\n",
      "33:\tlearn: 0.0490313\ttotal: 5.82s\tremaining: 2.74s\n",
      "34:\tlearn: 0.0471165\ttotal: 6s\tremaining: 2.57s\n",
      "35:\tlearn: 0.0448411\ttotal: 6.17s\tremaining: 2.4s\n",
      "36:\tlearn: 0.0442989\ttotal: 6.34s\tremaining: 2.23s\n",
      "37:\tlearn: 0.0428644\ttotal: 6.51s\tremaining: 2.06s\n",
      "38:\tlearn: 0.0421834\ttotal: 6.68s\tremaining: 1.88s\n",
      "39:\tlearn: 0.0408639\ttotal: 6.86s\tremaining: 1.71s\n",
      "40:\tlearn: 0.0399243\ttotal: 7.02s\tremaining: 1.54s\n",
      "41:\tlearn: 0.0393667\ttotal: 7.18s\tremaining: 1.37s\n",
      "42:\tlearn: 0.0375372\ttotal: 7.33s\tremaining: 1.19s\n",
      "43:\tlearn: 0.0338227\ttotal: 7.49s\tremaining: 1.02s\n",
      "44:\tlearn: 0.0332439\ttotal: 7.63s\tremaining: 848ms\n",
      "45:\tlearn: 0.0324244\ttotal: 7.79s\tremaining: 677ms\n",
      "46:\tlearn: 0.0317862\ttotal: 7.96s\tremaining: 508ms\n",
      "47:\tlearn: 0.0306228\ttotal: 8.13s\tremaining: 339ms\n",
      "48:\tlearn: 0.0293467\ttotal: 8.31s\tremaining: 170ms\n",
      "49:\tlearn: 0.0288673\ttotal: 8.47s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4505142\ttotal: 180ms\tremaining: 8.81s\n",
      "1:\tlearn: 0.3262960\ttotal: 364ms\tremaining: 8.74s\n",
      "2:\tlearn: 0.2794464\ttotal: 533ms\tremaining: 8.35s\n",
      "3:\tlearn: 0.2400827\ttotal: 701ms\tremaining: 8.06s\n",
      "4:\tlearn: 0.1990102\ttotal: 892ms\tremaining: 8.03s\n",
      "5:\tlearn: 0.1847190\ttotal: 1.07s\tremaining: 7.88s\n",
      "6:\tlearn: 0.1685140\ttotal: 1.3s\tremaining: 7.97s\n",
      "7:\tlearn: 0.1515611\ttotal: 1.46s\tremaining: 7.64s\n",
      "8:\tlearn: 0.1395223\ttotal: 1.62s\tremaining: 7.39s\n",
      "9:\tlearn: 0.1337152\ttotal: 1.79s\tremaining: 7.16s\n",
      "10:\tlearn: 0.1242947\ttotal: 1.96s\tremaining: 6.95s\n",
      "11:\tlearn: 0.1183094\ttotal: 2.12s\tremaining: 6.73s\n",
      "12:\tlearn: 0.1114382\ttotal: 2.29s\tremaining: 6.51s\n",
      "13:\tlearn: 0.1023798\ttotal: 2.46s\tremaining: 6.32s\n",
      "14:\tlearn: 0.0994865\ttotal: 2.6s\tremaining: 6.07s\n",
      "15:\tlearn: 0.0969182\ttotal: 2.74s\tremaining: 5.83s\n",
      "16:\tlearn: 0.0903937\ttotal: 2.9s\tremaining: 5.64s\n",
      "17:\tlearn: 0.0855786\ttotal: 3.07s\tremaining: 5.46s\n",
      "18:\tlearn: 0.0828549\ttotal: 3.24s\tremaining: 5.28s\n",
      "19:\tlearn: 0.0803419\ttotal: 3.4s\tremaining: 5.09s\n",
      "20:\tlearn: 0.0778994\ttotal: 3.56s\tremaining: 4.92s\n",
      "21:\tlearn: 0.0735156\ttotal: 3.72s\tremaining: 4.74s\n",
      "22:\tlearn: 0.0713353\ttotal: 3.87s\tremaining: 4.55s\n",
      "23:\tlearn: 0.0693673\ttotal: 4.03s\tremaining: 4.37s\n",
      "24:\tlearn: 0.0663512\ttotal: 4.2s\tremaining: 4.2s\n",
      "25:\tlearn: 0.0640812\ttotal: 4.35s\tremaining: 4.01s\n",
      "26:\tlearn: 0.0623820\ttotal: 4.51s\tremaining: 3.85s\n",
      "27:\tlearn: 0.0590637\ttotal: 4.68s\tremaining: 3.67s\n",
      "28:\tlearn: 0.0575010\ttotal: 4.83s\tremaining: 3.5s\n",
      "29:\tlearn: 0.0554602\ttotal: 5s\tremaining: 3.33s\n",
      "30:\tlearn: 0.0523933\ttotal: 5.17s\tremaining: 3.17s\n",
      "31:\tlearn: 0.0503687\ttotal: 5.36s\tremaining: 3.01s\n",
      "32:\tlearn: 0.0481976\ttotal: 5.52s\tremaining: 2.84s\n",
      "33:\tlearn: 0.0466647\ttotal: 5.69s\tremaining: 2.68s\n",
      "34:\tlearn: 0.0454317\ttotal: 5.88s\tremaining: 2.52s\n",
      "35:\tlearn: 0.0433092\ttotal: 6.07s\tremaining: 2.36s\n",
      "36:\tlearn: 0.0419457\ttotal: 6.23s\tremaining: 2.19s\n",
      "37:\tlearn: 0.0409565\ttotal: 6.39s\tremaining: 2.02s\n",
      "38:\tlearn: 0.0396884\ttotal: 6.56s\tremaining: 1.85s\n",
      "39:\tlearn: 0.0387417\ttotal: 6.74s\tremaining: 1.69s\n",
      "40:\tlearn: 0.0376289\ttotal: 6.91s\tremaining: 1.52s\n",
      "41:\tlearn: 0.0368671\ttotal: 7.05s\tremaining: 1.34s\n",
      "42:\tlearn: 0.0360170\ttotal: 7.22s\tremaining: 1.18s\n",
      "43:\tlearn: 0.0352810\ttotal: 7.38s\tremaining: 1.01s\n",
      "44:\tlearn: 0.0345337\ttotal: 7.54s\tremaining: 838ms\n",
      "45:\tlearn: 0.0341158\ttotal: 7.71s\tremaining: 670ms\n",
      "46:\tlearn: 0.0310737\ttotal: 7.89s\tremaining: 503ms\n",
      "47:\tlearn: 0.0300937\ttotal: 8.06s\tremaining: 336ms\n",
      "48:\tlearn: 0.0296074\ttotal: 8.23s\tremaining: 168ms\n",
      "49:\tlearn: 0.0292566\ttotal: 8.41s\tremaining: 0us\n",
      "Learning rate set to 0.354991\n",
      "0:\tlearn: 0.4653642\ttotal: 230ms\tremaining: 11.3s\n",
      "1:\tlearn: 0.3289949\ttotal: 397ms\tremaining: 9.53s\n",
      "2:\tlearn: 0.2812854\ttotal: 553ms\tremaining: 8.66s\n",
      "3:\tlearn: 0.2411831\ttotal: 733ms\tremaining: 8.43s\n",
      "4:\tlearn: 0.2211581\ttotal: 903ms\tremaining: 8.12s\n",
      "5:\tlearn: 0.1923469\ttotal: 1.08s\tremaining: 7.9s\n",
      "6:\tlearn: 0.1709680\ttotal: 1.25s\tremaining: 7.7s\n",
      "7:\tlearn: 0.1523747\ttotal: 1.42s\tremaining: 7.48s\n",
      "8:\tlearn: 0.1412689\ttotal: 1.58s\tremaining: 7.2s\n",
      "9:\tlearn: 0.1334282\ttotal: 1.76s\tremaining: 7.03s\n",
      "10:\tlearn: 0.1255417\ttotal: 1.96s\tremaining: 6.96s\n",
      "11:\tlearn: 0.1194745\ttotal: 2.12s\tremaining: 6.7s\n",
      "12:\tlearn: 0.1155025\ttotal: 2.27s\tremaining: 6.46s\n",
      "13:\tlearn: 0.1079285\ttotal: 2.44s\tremaining: 6.27s\n",
      "14:\tlearn: 0.1033863\ttotal: 2.59s\tremaining: 6.04s\n",
      "15:\tlearn: 0.1010787\ttotal: 2.75s\tremaining: 5.84s\n",
      "16:\tlearn: 0.0959570\ttotal: 2.94s\tremaining: 5.7s\n",
      "17:\tlearn: 0.0889192\ttotal: 3.1s\tremaining: 5.51s\n",
      "18:\tlearn: 0.0820901\ttotal: 3.26s\tremaining: 5.32s\n",
      "19:\tlearn: 0.0794554\ttotal: 3.42s\tremaining: 5.13s\n",
      "20:\tlearn: 0.0763877\ttotal: 3.59s\tremaining: 4.96s\n",
      "21:\tlearn: 0.0743999\ttotal: 3.77s\tremaining: 4.79s\n",
      "22:\tlearn: 0.0719214\ttotal: 3.94s\tremaining: 4.63s\n",
      "23:\tlearn: 0.0700685\ttotal: 4.11s\tremaining: 4.46s\n",
      "24:\tlearn: 0.0675461\ttotal: 4.3s\tremaining: 4.3s\n",
      "25:\tlearn: 0.0644589\ttotal: 4.46s\tremaining: 4.12s\n",
      "26:\tlearn: 0.0627442\ttotal: 4.66s\tremaining: 3.97s\n",
      "27:\tlearn: 0.0617524\ttotal: 4.85s\tremaining: 3.81s\n",
      "28:\tlearn: 0.0608696\ttotal: 5.01s\tremaining: 3.63s\n",
      "29:\tlearn: 0.0593585\ttotal: 5.17s\tremaining: 3.44s\n",
      "30:\tlearn: 0.0572674\ttotal: 5.32s\tremaining: 3.26s\n",
      "31:\tlearn: 0.0543941\ttotal: 5.49s\tremaining: 3.08s\n",
      "32:\tlearn: 0.0507329\ttotal: 5.65s\tremaining: 2.91s\n",
      "33:\tlearn: 0.0502747\ttotal: 5.8s\tremaining: 2.73s\n",
      "34:\tlearn: 0.0480656\ttotal: 5.97s\tremaining: 2.56s\n",
      "35:\tlearn: 0.0455972\ttotal: 6.14s\tremaining: 2.39s\n",
      "36:\tlearn: 0.0450045\ttotal: 6.3s\tremaining: 2.21s\n",
      "37:\tlearn: 0.0443964\ttotal: 6.44s\tremaining: 2.04s\n",
      "38:\tlearn: 0.0427599\ttotal: 6.61s\tremaining: 1.86s\n",
      "39:\tlearn: 0.0419242\ttotal: 6.82s\tremaining: 1.7s\n",
      "40:\tlearn: 0.0413861\ttotal: 7s\tremaining: 1.54s\n",
      "41:\tlearn: 0.0408812\ttotal: 7.17s\tremaining: 1.37s\n",
      "42:\tlearn: 0.0400770\ttotal: 7.34s\tremaining: 1.19s\n",
      "43:\tlearn: 0.0392352\ttotal: 7.5s\tremaining: 1.02s\n",
      "44:\tlearn: 0.0385204\ttotal: 7.68s\tremaining: 853ms\n",
      "45:\tlearn: 0.0366639\ttotal: 7.87s\tremaining: 684ms\n",
      "46:\tlearn: 0.0358991\ttotal: 8.06s\tremaining: 514ms\n",
      "47:\tlearn: 0.0343023\ttotal: 8.24s\tremaining: 343ms\n",
      "48:\tlearn: 0.0331474\ttotal: 8.42s\tremaining: 172ms\n",
      "49:\tlearn: 0.0316914\ttotal: 8.58s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4246204\ttotal: 248ms\tremaining: 12.2s\n",
      "1:\tlearn: 0.3340946\ttotal: 424ms\tremaining: 10.2s\n",
      "2:\tlearn: 0.2670064\ttotal: 633ms\tremaining: 9.92s\n",
      "3:\tlearn: 0.2263019\ttotal: 816ms\tremaining: 9.38s\n",
      "4:\tlearn: 0.1810205\ttotal: 1s\tremaining: 9.03s\n",
      "5:\tlearn: 0.1632300\ttotal: 1.18s\tremaining: 8.64s\n",
      "6:\tlearn: 0.1491064\ttotal: 1.35s\tremaining: 8.31s\n",
      "7:\tlearn: 0.1404325\ttotal: 1.52s\tremaining: 7.98s\n",
      "8:\tlearn: 0.1301322\ttotal: 1.69s\tremaining: 7.69s\n",
      "9:\tlearn: 0.1224163\ttotal: 1.87s\tremaining: 7.49s\n",
      "10:\tlearn: 0.1173897\ttotal: 2.04s\tremaining: 7.22s\n",
      "11:\tlearn: 0.1116649\ttotal: 2.2s\tremaining: 6.97s\n",
      "12:\tlearn: 0.1057235\ttotal: 2.36s\tremaining: 6.72s\n",
      "13:\tlearn: 0.1033001\ttotal: 2.52s\tremaining: 6.49s\n",
      "14:\tlearn: 0.0997686\ttotal: 2.69s\tremaining: 6.28s\n",
      "15:\tlearn: 0.0975590\ttotal: 2.84s\tremaining: 6.04s\n",
      "16:\tlearn: 0.0912683\ttotal: 3s\tremaining: 5.81s\n",
      "17:\tlearn: 0.0875600\ttotal: 3.16s\tremaining: 5.61s\n",
      "18:\tlearn: 0.0853243\ttotal: 3.32s\tremaining: 5.41s\n",
      "19:\tlearn: 0.0831310\ttotal: 3.47s\tremaining: 5.2s\n",
      "20:\tlearn: 0.0803060\ttotal: 3.63s\tremaining: 5.01s\n",
      "21:\tlearn: 0.0762996\ttotal: 3.78s\tremaining: 4.81s\n",
      "22:\tlearn: 0.0738804\ttotal: 3.93s\tremaining: 4.61s\n",
      "23:\tlearn: 0.0716338\ttotal: 4.08s\tremaining: 4.42s\n",
      "24:\tlearn: 0.0702429\ttotal: 4.25s\tremaining: 4.25s\n",
      "25:\tlearn: 0.0681178\ttotal: 4.42s\tremaining: 4.08s\n",
      "26:\tlearn: 0.0654170\ttotal: 4.58s\tremaining: 3.9s\n",
      "27:\tlearn: 0.0628586\ttotal: 4.73s\tremaining: 3.72s\n",
      "28:\tlearn: 0.0579664\ttotal: 4.89s\tremaining: 3.54s\n",
      "29:\tlearn: 0.0563407\ttotal: 5.05s\tremaining: 3.37s\n",
      "30:\tlearn: 0.0549518\ttotal: 5.22s\tremaining: 3.2s\n",
      "31:\tlearn: 0.0534883\ttotal: 5.38s\tremaining: 3.03s\n",
      "32:\tlearn: 0.0510275\ttotal: 5.57s\tremaining: 2.87s\n",
      "33:\tlearn: 0.0486522\ttotal: 5.76s\tremaining: 2.71s\n",
      "34:\tlearn: 0.0473175\ttotal: 5.93s\tremaining: 2.54s\n",
      "35:\tlearn: 0.0462134\ttotal: 6.09s\tremaining: 2.37s\n",
      "36:\tlearn: 0.0444830\ttotal: 6.26s\tremaining: 2.2s\n",
      "37:\tlearn: 0.0427668\ttotal: 6.42s\tremaining: 2.03s\n",
      "38:\tlearn: 0.0415347\ttotal: 6.59s\tremaining: 1.86s\n",
      "39:\tlearn: 0.0407073\ttotal: 6.74s\tremaining: 1.69s\n",
      "40:\tlearn: 0.0395971\ttotal: 6.91s\tremaining: 1.52s\n",
      "41:\tlearn: 0.0381968\ttotal: 7.06s\tremaining: 1.34s\n",
      "42:\tlearn: 0.0373119\ttotal: 7.22s\tremaining: 1.18s\n",
      "43:\tlearn: 0.0352272\ttotal: 7.38s\tremaining: 1.01s\n",
      "44:\tlearn: 0.0343894\ttotal: 7.53s\tremaining: 837ms\n",
      "45:\tlearn: 0.0331953\ttotal: 7.69s\tremaining: 669ms\n",
      "46:\tlearn: 0.0322612\ttotal: 7.85s\tremaining: 501ms\n",
      "47:\tlearn: 0.0314332\ttotal: 8s\tremaining: 333ms\n",
      "48:\tlearn: 0.0303287\ttotal: 8.19s\tremaining: 167ms\n",
      "49:\tlearn: 0.0297418\ttotal: 8.36s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4450935\ttotal: 199ms\tremaining: 9.77s\n",
      "1:\tlearn: 0.3317138\ttotal: 361ms\tremaining: 8.65s\n",
      "2:\tlearn: 0.2623158\ttotal: 553ms\tremaining: 8.66s\n",
      "3:\tlearn: 0.2254946\ttotal: 714ms\tremaining: 8.21s\n",
      "4:\tlearn: 0.1920338\ttotal: 921ms\tremaining: 8.29s\n",
      "5:\tlearn: 0.1716142\ttotal: 1.12s\tremaining: 8.23s\n",
      "6:\tlearn: 0.1558882\ttotal: 1.31s\tremaining: 8.07s\n",
      "7:\tlearn: 0.1394502\ttotal: 1.51s\tremaining: 7.96s\n",
      "8:\tlearn: 0.1297884\ttotal: 1.69s\tremaining: 7.69s\n",
      "9:\tlearn: 0.1250515\ttotal: 1.84s\tremaining: 7.37s\n",
      "10:\tlearn: 0.1169078\ttotal: 2.02s\tremaining: 7.15s\n",
      "11:\tlearn: 0.1123348\ttotal: 2.21s\tremaining: 6.99s\n",
      "12:\tlearn: 0.1061889\ttotal: 2.38s\tremaining: 6.78s\n",
      "13:\tlearn: 0.1022333\ttotal: 2.55s\tremaining: 6.56s\n",
      "14:\tlearn: 0.0995787\ttotal: 2.74s\tremaining: 6.4s\n",
      "15:\tlearn: 0.0977312\ttotal: 2.9s\tremaining: 6.16s\n",
      "16:\tlearn: 0.0925229\ttotal: 3.1s\tremaining: 6.02s\n",
      "17:\tlearn: 0.0900982\ttotal: 3.27s\tremaining: 5.81s\n",
      "18:\tlearn: 0.0861604\ttotal: 3.45s\tremaining: 5.63s\n",
      "19:\tlearn: 0.0831599\ttotal: 3.62s\tremaining: 5.43s\n",
      "20:\tlearn: 0.0786574\ttotal: 3.79s\tremaining: 5.23s\n",
      "21:\tlearn: 0.0764494\ttotal: 3.95s\tremaining: 5.02s\n",
      "22:\tlearn: 0.0740773\ttotal: 4.12s\tremaining: 4.84s\n",
      "23:\tlearn: 0.0715045\ttotal: 4.3s\tremaining: 4.65s\n",
      "24:\tlearn: 0.0692857\ttotal: 4.46s\tremaining: 4.46s\n",
      "25:\tlearn: 0.0665674\ttotal: 4.63s\tremaining: 4.27s\n",
      "26:\tlearn: 0.0647990\ttotal: 4.78s\tremaining: 4.07s\n",
      "27:\tlearn: 0.0624183\ttotal: 4.97s\tremaining: 3.91s\n",
      "28:\tlearn: 0.0603599\ttotal: 5.15s\tremaining: 3.73s\n",
      "29:\tlearn: 0.0587383\ttotal: 5.3s\tremaining: 3.53s\n",
      "30:\tlearn: 0.0570472\ttotal: 5.44s\tremaining: 3.33s\n",
      "31:\tlearn: 0.0548050\ttotal: 5.61s\tremaining: 3.15s\n",
      "32:\tlearn: 0.0518779\ttotal: 5.79s\tremaining: 2.98s\n",
      "33:\tlearn: 0.0462574\ttotal: 5.98s\tremaining: 2.81s\n",
      "34:\tlearn: 0.0452016\ttotal: 6.15s\tremaining: 2.64s\n",
      "35:\tlearn: 0.0443013\ttotal: 6.33s\tremaining: 2.46s\n",
      "36:\tlearn: 0.0423020\ttotal: 6.5s\tremaining: 2.28s\n",
      "37:\tlearn: 0.0410677\ttotal: 6.68s\tremaining: 2.11s\n",
      "38:\tlearn: 0.0399400\ttotal: 7s\tremaining: 1.97s\n",
      "39:\tlearn: 0.0389196\ttotal: 7.25s\tremaining: 1.81s\n",
      "40:\tlearn: 0.0381244\ttotal: 7.45s\tremaining: 1.64s\n",
      "41:\tlearn: 0.0371998\ttotal: 7.63s\tremaining: 1.45s\n",
      "42:\tlearn: 0.0358807\ttotal: 7.84s\tremaining: 1.27s\n",
      "43:\tlearn: 0.0349965\ttotal: 8.02s\tremaining: 1.09s\n",
      "44:\tlearn: 0.0343743\ttotal: 8.19s\tremaining: 910ms\n",
      "45:\tlearn: 0.0329746\ttotal: 8.38s\tremaining: 728ms\n",
      "46:\tlearn: 0.0323403\ttotal: 8.55s\tremaining: 546ms\n",
      "47:\tlearn: 0.0313855\ttotal: 8.73s\tremaining: 364ms\n",
      "48:\tlearn: 0.0307893\ttotal: 8.9s\tremaining: 182ms\n",
      "49:\tlearn: 0.0296524\ttotal: 9.09s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4457674\ttotal: 197ms\tremaining: 9.65s\n",
      "1:\tlearn: 0.3325768\ttotal: 356ms\tremaining: 8.55s\n",
      "2:\tlearn: 0.2638233\ttotal: 544ms\tremaining: 8.52s\n",
      "3:\tlearn: 0.2385037\ttotal: 708ms\tremaining: 8.14s\n",
      "4:\tlearn: 0.2152698\ttotal: 866ms\tremaining: 7.8s\n",
      "5:\tlearn: 0.1940716\ttotal: 1.03s\tremaining: 7.56s\n",
      "6:\tlearn: 0.1820043\ttotal: 1.19s\tremaining: 7.31s\n",
      "7:\tlearn: 0.1670184\ttotal: 1.35s\tremaining: 7.07s\n",
      "8:\tlearn: 0.1528156\ttotal: 1.55s\tremaining: 7.06s\n",
      "9:\tlearn: 0.1383879\ttotal: 1.75s\tremaining: 7.02s\n",
      "10:\tlearn: 0.1284004\ttotal: 1.93s\tremaining: 6.84s\n",
      "11:\tlearn: 0.1202206\ttotal: 2.12s\tremaining: 6.72s\n",
      "12:\tlearn: 0.1117777\ttotal: 2.34s\tremaining: 6.66s\n",
      "13:\tlearn: 0.1039534\ttotal: 2.52s\tremaining: 6.47s\n",
      "14:\tlearn: 0.1008891\ttotal: 2.72s\tremaining: 6.34s\n",
      "15:\tlearn: 0.0987667\ttotal: 2.91s\tremaining: 6.18s\n",
      "16:\tlearn: 0.0961784\ttotal: 3.09s\tremaining: 6s\n",
      "17:\tlearn: 0.0931766\ttotal: 3.35s\tremaining: 5.96s\n",
      "18:\tlearn: 0.0907303\ttotal: 3.61s\tremaining: 5.89s\n",
      "19:\tlearn: 0.0874676\ttotal: 3.88s\tremaining: 5.81s\n",
      "20:\tlearn: 0.0818715\ttotal: 4.05s\tremaining: 5.6s\n",
      "21:\tlearn: 0.0794601\ttotal: 4.24s\tremaining: 5.4s\n",
      "22:\tlearn: 0.0765691\ttotal: 4.39s\tremaining: 5.16s\n",
      "23:\tlearn: 0.0745279\ttotal: 4.56s\tremaining: 4.94s\n",
      "24:\tlearn: 0.0714794\ttotal: 4.74s\tremaining: 4.74s\n",
      "25:\tlearn: 0.0690610\ttotal: 4.91s\tremaining: 4.53s\n",
      "26:\tlearn: 0.0661549\ttotal: 5.09s\tremaining: 4.34s\n",
      "27:\tlearn: 0.0640666\ttotal: 5.27s\tremaining: 4.14s\n",
      "28:\tlearn: 0.0626137\ttotal: 5.46s\tremaining: 3.96s\n",
      "29:\tlearn: 0.0611162\ttotal: 5.64s\tremaining: 3.76s\n",
      "30:\tlearn: 0.0584108\ttotal: 5.81s\tremaining: 3.56s\n",
      "31:\tlearn: 0.0567076\ttotal: 5.99s\tremaining: 3.37s\n",
      "32:\tlearn: 0.0548394\ttotal: 6.16s\tremaining: 3.17s\n",
      "33:\tlearn: 0.0528175\ttotal: 6.34s\tremaining: 2.98s\n",
      "34:\tlearn: 0.0517897\ttotal: 6.51s\tremaining: 2.79s\n",
      "35:\tlearn: 0.0505620\ttotal: 6.71s\tremaining: 2.61s\n",
      "36:\tlearn: 0.0496816\ttotal: 6.88s\tremaining: 2.42s\n",
      "37:\tlearn: 0.0487773\ttotal: 7.09s\tremaining: 2.24s\n",
      "38:\tlearn: 0.0462836\ttotal: 7.33s\tremaining: 2.07s\n",
      "39:\tlearn: 0.0429548\ttotal: 7.5s\tremaining: 1.87s\n",
      "40:\tlearn: 0.0423777\ttotal: 7.7s\tremaining: 1.69s\n",
      "41:\tlearn: 0.0411036\ttotal: 7.89s\tremaining: 1.5s\n",
      "42:\tlearn: 0.0386672\ttotal: 8.07s\tremaining: 1.31s\n",
      "43:\tlearn: 0.0376350\ttotal: 8.22s\tremaining: 1.12s\n",
      "44:\tlearn: 0.0365195\ttotal: 8.39s\tremaining: 933ms\n",
      "45:\tlearn: 0.0358413\ttotal: 8.57s\tremaining: 745ms\n",
      "46:\tlearn: 0.0347184\ttotal: 8.74s\tremaining: 558ms\n",
      "47:\tlearn: 0.0338699\ttotal: 8.92s\tremaining: 372ms\n",
      "48:\tlearn: 0.0327392\ttotal: 9.16s\tremaining: 187ms\n",
      "49:\tlearn: 0.0323877\ttotal: 9.37s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4720177\ttotal: 194ms\tremaining: 9.49s\n",
      "1:\tlearn: 0.3358863\ttotal: 375ms\tremaining: 8.99s\n",
      "2:\tlearn: 0.2774080\ttotal: 537ms\tremaining: 8.41s\n",
      "3:\tlearn: 0.2291383\ttotal: 733ms\tremaining: 8.43s\n",
      "4:\tlearn: 0.1931181\ttotal: 893ms\tremaining: 8.04s\n",
      "5:\tlearn: 0.1704420\ttotal: 1.06s\tremaining: 7.78s\n",
      "6:\tlearn: 0.1582363\ttotal: 1.24s\tremaining: 7.62s\n",
      "7:\tlearn: 0.1398828\ttotal: 1.4s\tremaining: 7.36s\n",
      "8:\tlearn: 0.1281350\ttotal: 1.56s\tremaining: 7.11s\n",
      "9:\tlearn: 0.1222836\ttotal: 1.75s\tremaining: 6.99s\n",
      "10:\tlearn: 0.1160817\ttotal: 1.9s\tremaining: 6.73s\n",
      "11:\tlearn: 0.1117149\ttotal: 2.07s\tremaining: 6.54s\n",
      "12:\tlearn: 0.1042635\ttotal: 2.22s\tremaining: 6.33s\n",
      "13:\tlearn: 0.1005955\ttotal: 2.45s\tremaining: 6.29s\n",
      "14:\tlearn: 0.0969321\ttotal: 2.64s\tremaining: 6.16s\n",
      "15:\tlearn: 0.0946105\ttotal: 2.83s\tremaining: 6s\n",
      "16:\tlearn: 0.0891857\ttotal: 3s\tremaining: 5.83s\n",
      "17:\tlearn: 0.0839995\ttotal: 3.18s\tremaining: 5.66s\n",
      "18:\tlearn: 0.0820333\ttotal: 3.34s\tremaining: 5.45s\n",
      "19:\tlearn: 0.0793421\ttotal: 3.5s\tremaining: 5.26s\n",
      "20:\tlearn: 0.0755897\ttotal: 3.66s\tremaining: 5.06s\n",
      "21:\tlearn: 0.0716913\ttotal: 3.83s\tremaining: 4.88s\n",
      "22:\tlearn: 0.0689726\ttotal: 3.99s\tremaining: 4.68s\n",
      "23:\tlearn: 0.0653334\ttotal: 4.15s\tremaining: 4.49s\n",
      "24:\tlearn: 0.0639285\ttotal: 4.3s\tremaining: 4.3s\n",
      "25:\tlearn: 0.0618843\ttotal: 4.46s\tremaining: 4.12s\n",
      "26:\tlearn: 0.0600909\ttotal: 4.61s\tremaining: 3.93s\n",
      "27:\tlearn: 0.0575569\ttotal: 4.77s\tremaining: 3.75s\n",
      "28:\tlearn: 0.0553061\ttotal: 4.93s\tremaining: 3.57s\n",
      "29:\tlearn: 0.0538217\ttotal: 5.09s\tremaining: 3.39s\n",
      "30:\tlearn: 0.0518629\ttotal: 5.25s\tremaining: 3.22s\n",
      "31:\tlearn: 0.0504549\ttotal: 5.43s\tremaining: 3.06s\n",
      "32:\tlearn: 0.0491399\ttotal: 5.58s\tremaining: 2.88s\n",
      "33:\tlearn: 0.0477048\ttotal: 5.74s\tremaining: 2.7s\n",
      "34:\tlearn: 0.0460700\ttotal: 5.9s\tremaining: 2.53s\n",
      "35:\tlearn: 0.0447288\ttotal: 6.07s\tremaining: 2.36s\n",
      "36:\tlearn: 0.0433397\ttotal: 6.21s\tremaining: 2.18s\n",
      "37:\tlearn: 0.0421974\ttotal: 6.36s\tremaining: 2.01s\n",
      "38:\tlearn: 0.0406639\ttotal: 6.52s\tremaining: 1.84s\n",
      "39:\tlearn: 0.0398862\ttotal: 6.67s\tremaining: 1.67s\n",
      "40:\tlearn: 0.0367746\ttotal: 6.84s\tremaining: 1.5s\n",
      "41:\tlearn: 0.0356290\ttotal: 7.01s\tremaining: 1.33s\n",
      "42:\tlearn: 0.0339337\ttotal: 7.16s\tremaining: 1.17s\n",
      "43:\tlearn: 0.0332190\ttotal: 7.31s\tremaining: 997ms\n",
      "44:\tlearn: 0.0328344\ttotal: 7.46s\tremaining: 829ms\n",
      "45:\tlearn: 0.0322947\ttotal: 7.61s\tremaining: 662ms\n",
      "46:\tlearn: 0.0318056\ttotal: 7.78s\tremaining: 497ms\n",
      "47:\tlearn: 0.0311687\ttotal: 7.96s\tremaining: 332ms\n",
      "48:\tlearn: 0.0305691\ttotal: 8.13s\tremaining: 166ms\n",
      "49:\tlearn: 0.0300327\ttotal: 8.3s\tremaining: 0us\n",
      "Learning rate set to 0.354991\n",
      "0:\tlearn: 0.4418746\ttotal: 194ms\tremaining: 9.53s\n",
      "1:\tlearn: 0.3254000\ttotal: 351ms\tremaining: 8.43s\n",
      "2:\tlearn: 0.2611153\ttotal: 514ms\tremaining: 8.05s\n",
      "3:\tlearn: 0.2192971\ttotal: 676ms\tremaining: 7.77s\n",
      "4:\tlearn: 0.1933303\ttotal: 863ms\tremaining: 7.77s\n",
      "5:\tlearn: 0.1788958\ttotal: 1.04s\tremaining: 7.65s\n",
      "6:\tlearn: 0.1570692\ttotal: 1.22s\tremaining: 7.51s\n",
      "7:\tlearn: 0.1478095\ttotal: 1.39s\tremaining: 7.31s\n",
      "8:\tlearn: 0.1365503\ttotal: 1.56s\tremaining: 7.11s\n",
      "9:\tlearn: 0.1275394\ttotal: 1.72s\tremaining: 6.87s\n",
      "10:\tlearn: 0.1233696\ttotal: 1.88s\tremaining: 6.66s\n",
      "11:\tlearn: 0.1167182\ttotal: 2.05s\tremaining: 6.49s\n",
      "12:\tlearn: 0.1128194\ttotal: 2.22s\tremaining: 6.32s\n",
      "13:\tlearn: 0.1053507\ttotal: 2.4s\tremaining: 6.17s\n",
      "14:\tlearn: 0.1014471\ttotal: 2.56s\tremaining: 5.97s\n",
      "15:\tlearn: 0.0963561\ttotal: 2.75s\tremaining: 5.84s\n",
      "16:\tlearn: 0.0918241\ttotal: 2.96s\tremaining: 5.75s\n",
      "17:\tlearn: 0.0878893\ttotal: 3.15s\tremaining: 5.59s\n",
      "18:\tlearn: 0.0805381\ttotal: 3.32s\tremaining: 5.42s\n",
      "19:\tlearn: 0.0784268\ttotal: 3.49s\tremaining: 5.24s\n",
      "20:\tlearn: 0.0759307\ttotal: 3.7s\tremaining: 5.11s\n",
      "21:\tlearn: 0.0738042\ttotal: 3.89s\tremaining: 4.95s\n",
      "22:\tlearn: 0.0722880\ttotal: 4.05s\tremaining: 4.75s\n",
      "23:\tlearn: 0.0704985\ttotal: 4.21s\tremaining: 4.56s\n",
      "24:\tlearn: 0.0693266\ttotal: 4.41s\tremaining: 4.41s\n",
      "25:\tlearn: 0.0667671\ttotal: 4.6s\tremaining: 4.25s\n",
      "26:\tlearn: 0.0641321\ttotal: 4.79s\tremaining: 4.08s\n",
      "27:\tlearn: 0.0603423\ttotal: 5s\tremaining: 3.93s\n",
      "28:\tlearn: 0.0581980\ttotal: 5.17s\tremaining: 3.74s\n",
      "29:\tlearn: 0.0572071\ttotal: 5.34s\tremaining: 3.56s\n",
      "30:\tlearn: 0.0544053\ttotal: 5.52s\tremaining: 3.38s\n",
      "31:\tlearn: 0.0536971\ttotal: 5.69s\tremaining: 3.2s\n",
      "32:\tlearn: 0.0522098\ttotal: 5.86s\tremaining: 3.02s\n",
      "33:\tlearn: 0.0509527\ttotal: 6.03s\tremaining: 2.84s\n",
      "34:\tlearn: 0.0488178\ttotal: 6.2s\tremaining: 2.66s\n",
      "35:\tlearn: 0.0476260\ttotal: 6.36s\tremaining: 2.47s\n",
      "36:\tlearn: 0.0464970\ttotal: 6.54s\tremaining: 2.3s\n",
      "37:\tlearn: 0.0458072\ttotal: 6.71s\tremaining: 2.12s\n",
      "38:\tlearn: 0.0444693\ttotal: 6.87s\tremaining: 1.94s\n",
      "39:\tlearn: 0.0437953\ttotal: 7.05s\tremaining: 1.76s\n",
      "40:\tlearn: 0.0428918\ttotal: 7.24s\tremaining: 1.59s\n",
      "41:\tlearn: 0.0408146\ttotal: 7.42s\tremaining: 1.41s\n",
      "42:\tlearn: 0.0399127\ttotal: 7.58s\tremaining: 1.23s\n",
      "43:\tlearn: 0.0392596\ttotal: 7.77s\tremaining: 1.06s\n",
      "44:\tlearn: 0.0385566\ttotal: 7.96s\tremaining: 884ms\n",
      "45:\tlearn: 0.0372708\ttotal: 8.13s\tremaining: 707ms\n",
      "46:\tlearn: 0.0362759\ttotal: 8.28s\tremaining: 528ms\n",
      "47:\tlearn: 0.0351350\ttotal: 8.44s\tremaining: 352ms\n",
      "48:\tlearn: 0.0342331\ttotal: 8.59s\tremaining: 175ms\n",
      "49:\tlearn: 0.0333245\ttotal: 8.75s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4446812\ttotal: 198ms\tremaining: 9.68s\n",
      "1:\tlearn: 0.3259072\ttotal: 362ms\tremaining: 8.7s\n",
      "2:\tlearn: 0.2704183\ttotal: 537ms\tremaining: 8.41s\n",
      "3:\tlearn: 0.2313042\ttotal: 693ms\tremaining: 7.96s\n",
      "4:\tlearn: 0.2031205\ttotal: 856ms\tremaining: 7.71s\n",
      "5:\tlearn: 0.1816734\ttotal: 1.03s\tremaining: 7.59s\n",
      "6:\tlearn: 0.1646693\ttotal: 1.2s\tremaining: 7.39s\n",
      "7:\tlearn: 0.1436491\ttotal: 1.36s\tremaining: 7.13s\n",
      "8:\tlearn: 0.1305472\ttotal: 1.53s\tremaining: 7s\n",
      "9:\tlearn: 0.1233841\ttotal: 1.71s\tremaining: 6.83s\n",
      "10:\tlearn: 0.1179410\ttotal: 1.87s\tremaining: 6.64s\n",
      "11:\tlearn: 0.1131836\ttotal: 2.03s\tremaining: 6.42s\n",
      "12:\tlearn: 0.1052389\ttotal: 2.18s\tremaining: 6.21s\n",
      "13:\tlearn: 0.0997789\ttotal: 2.33s\tremaining: 6s\n",
      "14:\tlearn: 0.0972492\ttotal: 2.49s\tremaining: 5.81s\n",
      "15:\tlearn: 0.0937597\ttotal: 2.64s\tremaining: 5.62s\n",
      "16:\tlearn: 0.0903085\ttotal: 2.8s\tremaining: 5.44s\n",
      "17:\tlearn: 0.0831266\ttotal: 2.97s\tremaining: 5.28s\n",
      "18:\tlearn: 0.0801383\ttotal: 3.12s\tremaining: 5.1s\n",
      "19:\tlearn: 0.0772361\ttotal: 3.28s\tremaining: 4.93s\n",
      "20:\tlearn: 0.0736167\ttotal: 3.44s\tremaining: 4.74s\n",
      "21:\tlearn: 0.0713863\ttotal: 3.58s\tremaining: 4.56s\n",
      "22:\tlearn: 0.0688041\ttotal: 3.77s\tremaining: 4.42s\n",
      "23:\tlearn: 0.0666076\ttotal: 3.92s\tremaining: 4.25s\n",
      "24:\tlearn: 0.0646575\ttotal: 4.08s\tremaining: 4.08s\n",
      "25:\tlearn: 0.0634318\ttotal: 4.24s\tremaining: 3.91s\n",
      "26:\tlearn: 0.0602497\ttotal: 4.4s\tremaining: 3.75s\n",
      "27:\tlearn: 0.0583373\ttotal: 4.58s\tremaining: 3.6s\n",
      "28:\tlearn: 0.0555543\ttotal: 4.76s\tremaining: 3.45s\n",
      "29:\tlearn: 0.0545668\ttotal: 4.92s\tremaining: 3.28s\n",
      "30:\tlearn: 0.0525312\ttotal: 5.12s\tremaining: 3.14s\n",
      "31:\tlearn: 0.0510051\ttotal: 5.29s\tremaining: 2.98s\n",
      "32:\tlearn: 0.0496639\ttotal: 5.46s\tremaining: 2.81s\n",
      "33:\tlearn: 0.0487071\ttotal: 5.62s\tremaining: 2.65s\n",
      "34:\tlearn: 0.0477693\ttotal: 5.79s\tremaining: 2.48s\n",
      "35:\tlearn: 0.0470542\ttotal: 6s\tremaining: 2.33s\n",
      "36:\tlearn: 0.0460456\ttotal: 6.17s\tremaining: 2.17s\n",
      "37:\tlearn: 0.0448793\ttotal: 6.33s\tremaining: 2s\n",
      "38:\tlearn: 0.0438449\ttotal: 6.49s\tremaining: 1.83s\n",
      "39:\tlearn: 0.0428297\ttotal: 6.64s\tremaining: 1.66s\n",
      "40:\tlearn: 0.0413941\ttotal: 6.8s\tremaining: 1.49s\n",
      "41:\tlearn: 0.0404531\ttotal: 6.97s\tremaining: 1.33s\n",
      "42:\tlearn: 0.0397303\ttotal: 7.12s\tremaining: 1.16s\n",
      "43:\tlearn: 0.0389214\ttotal: 7.27s\tremaining: 991ms\n",
      "44:\tlearn: 0.0373580\ttotal: 7.46s\tremaining: 829ms\n",
      "45:\tlearn: 0.0349101\ttotal: 7.67s\tremaining: 667ms\n",
      "46:\tlearn: 0.0341664\ttotal: 7.86s\tremaining: 501ms\n",
      "47:\tlearn: 0.0338535\ttotal: 8.18s\tremaining: 341ms\n",
      "48:\tlearn: 0.0329262\ttotal: 8.5s\tremaining: 173ms\n",
      "49:\tlearn: 0.0309479\ttotal: 8.72s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4436496\ttotal: 198ms\tremaining: 9.71s\n",
      "1:\tlearn: 0.3312582\ttotal: 371ms\tremaining: 8.91s\n",
      "2:\tlearn: 0.2640065\ttotal: 572ms\tremaining: 8.96s\n",
      "3:\tlearn: 0.2265472\ttotal: 808ms\tremaining: 9.29s\n",
      "4:\tlearn: 0.1953985\ttotal: 979ms\tremaining: 8.81s\n",
      "5:\tlearn: 0.1744401\ttotal: 1.16s\tremaining: 8.49s\n",
      "6:\tlearn: 0.1587427\ttotal: 1.35s\tremaining: 8.32s\n",
      "7:\tlearn: 0.1434210\ttotal: 1.53s\tremaining: 8.04s\n",
      "8:\tlearn: 0.1332335\ttotal: 1.69s\tremaining: 7.69s\n",
      "9:\tlearn: 0.1276192\ttotal: 1.9s\tremaining: 7.61s\n",
      "10:\tlearn: 0.1222956\ttotal: 2.1s\tremaining: 7.46s\n",
      "11:\tlearn: 0.1176511\ttotal: 2.27s\tremaining: 7.18s\n",
      "12:\tlearn: 0.1125261\ttotal: 2.44s\tremaining: 6.96s\n",
      "13:\tlearn: 0.1079745\ttotal: 2.62s\tremaining: 6.73s\n",
      "14:\tlearn: 0.1040045\ttotal: 2.79s\tremaining: 6.5s\n",
      "15:\tlearn: 0.1011630\ttotal: 2.95s\tremaining: 6.26s\n",
      "16:\tlearn: 0.0973476\ttotal: 3.13s\tremaining: 6.07s\n",
      "17:\tlearn: 0.0902554\ttotal: 3.3s\tremaining: 5.87s\n",
      "18:\tlearn: 0.0835294\ttotal: 3.46s\tremaining: 5.65s\n",
      "19:\tlearn: 0.0813336\ttotal: 3.62s\tremaining: 5.42s\n",
      "20:\tlearn: 0.0785255\ttotal: 3.78s\tremaining: 5.21s\n",
      "21:\tlearn: 0.0746192\ttotal: 3.94s\tremaining: 5.02s\n",
      "22:\tlearn: 0.0719866\ttotal: 4.11s\tremaining: 4.83s\n",
      "23:\tlearn: 0.0702707\ttotal: 4.29s\tremaining: 4.65s\n",
      "24:\tlearn: 0.0658956\ttotal: 4.47s\tremaining: 4.47s\n",
      "25:\tlearn: 0.0632001\ttotal: 4.63s\tremaining: 4.27s\n",
      "26:\tlearn: 0.0605023\ttotal: 4.78s\tremaining: 4.07s\n",
      "27:\tlearn: 0.0593205\ttotal: 4.94s\tremaining: 3.88s\n",
      "28:\tlearn: 0.0571549\ttotal: 5.1s\tremaining: 3.69s\n",
      "29:\tlearn: 0.0558918\ttotal: 5.27s\tremaining: 3.52s\n",
      "30:\tlearn: 0.0542088\ttotal: 5.46s\tremaining: 3.35s\n",
      "31:\tlearn: 0.0526528\ttotal: 5.63s\tremaining: 3.16s\n",
      "32:\tlearn: 0.0515390\ttotal: 5.79s\tremaining: 2.98s\n",
      "33:\tlearn: 0.0479172\ttotal: 5.95s\tremaining: 2.8s\n",
      "34:\tlearn: 0.0470541\ttotal: 6.13s\tremaining: 2.63s\n",
      "35:\tlearn: 0.0456255\ttotal: 6.3s\tremaining: 2.45s\n",
      "36:\tlearn: 0.0444651\ttotal: 6.46s\tremaining: 2.27s\n",
      "37:\tlearn: 0.0434355\ttotal: 6.62s\tremaining: 2.09s\n",
      "38:\tlearn: 0.0426266\ttotal: 6.79s\tremaining: 1.92s\n",
      "39:\tlearn: 0.0419386\ttotal: 6.95s\tremaining: 1.74s\n",
      "40:\tlearn: 0.0411278\ttotal: 7.11s\tremaining: 1.56s\n",
      "41:\tlearn: 0.0401896\ttotal: 7.28s\tremaining: 1.39s\n",
      "42:\tlearn: 0.0393077\ttotal: 7.43s\tremaining: 1.21s\n",
      "43:\tlearn: 0.0374413\ttotal: 7.6s\tremaining: 1.04s\n",
      "44:\tlearn: 0.0367213\ttotal: 7.78s\tremaining: 865ms\n",
      "45:\tlearn: 0.0364394\ttotal: 7.93s\tremaining: 690ms\n",
      "46:\tlearn: 0.0347390\ttotal: 8.09s\tremaining: 516ms\n",
      "47:\tlearn: 0.0335136\ttotal: 8.26s\tremaining: 344ms\n",
      "48:\tlearn: 0.0324949\ttotal: 8.41s\tremaining: 172ms\n",
      "49:\tlearn: 0.0321282\ttotal: 8.57s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4538408\ttotal: 196ms\tremaining: 9.6s\n",
      "1:\tlearn: 0.3371217\ttotal: 358ms\tremaining: 8.6s\n",
      "2:\tlearn: 0.2835816\ttotal: 523ms\tremaining: 8.2s\n",
      "3:\tlearn: 0.2360441\ttotal: 673ms\tremaining: 7.74s\n",
      "4:\tlearn: 0.2103572\ttotal: 853ms\tremaining: 7.68s\n",
      "5:\tlearn: 0.1858104\ttotal: 1.02s\tremaining: 7.46s\n",
      "6:\tlearn: 0.1733237\ttotal: 1.18s\tremaining: 7.25s\n",
      "7:\tlearn: 0.1510405\ttotal: 1.34s\tremaining: 7.07s\n",
      "8:\tlearn: 0.1410507\ttotal: 1.51s\tremaining: 6.86s\n",
      "9:\tlearn: 0.1305136\ttotal: 1.67s\tremaining: 6.67s\n",
      "10:\tlearn: 0.1240444\ttotal: 1.82s\tremaining: 6.47s\n",
      "11:\tlearn: 0.1135418\ttotal: 1.98s\tremaining: 6.28s\n",
      "12:\tlearn: 0.1089119\ttotal: 2.14s\tremaining: 6.08s\n",
      "13:\tlearn: 0.1046553\ttotal: 2.29s\tremaining: 5.89s\n",
      "14:\tlearn: 0.1013022\ttotal: 2.45s\tremaining: 5.71s\n",
      "15:\tlearn: 0.1002436\ttotal: 2.6s\tremaining: 5.53s\n",
      "16:\tlearn: 0.0949118\ttotal: 2.76s\tremaining: 5.36s\n",
      "17:\tlearn: 0.0899682\ttotal: 2.92s\tremaining: 5.19s\n",
      "18:\tlearn: 0.0871111\ttotal: 3.08s\tremaining: 5.02s\n",
      "19:\tlearn: 0.0843796\ttotal: 3.23s\tremaining: 4.84s\n",
      "20:\tlearn: 0.0822179\ttotal: 3.38s\tremaining: 4.67s\n",
      "21:\tlearn: 0.0795021\ttotal: 3.55s\tremaining: 4.51s\n",
      "22:\tlearn: 0.0772625\ttotal: 3.7s\tremaining: 4.34s\n",
      "23:\tlearn: 0.0744541\ttotal: 3.85s\tremaining: 4.17s\n",
      "24:\tlearn: 0.0721158\ttotal: 4.01s\tremaining: 4.01s\n",
      "25:\tlearn: 0.0699438\ttotal: 4.17s\tremaining: 3.85s\n",
      "26:\tlearn: 0.0674611\ttotal: 4.34s\tremaining: 3.69s\n",
      "27:\tlearn: 0.0643201\ttotal: 4.5s\tremaining: 3.54s\n",
      "28:\tlearn: 0.0599103\ttotal: 4.66s\tremaining: 3.37s\n",
      "29:\tlearn: 0.0581177\ttotal: 4.82s\tremaining: 3.21s\n",
      "30:\tlearn: 0.0557203\ttotal: 4.99s\tremaining: 3.06s\n",
      "31:\tlearn: 0.0535824\ttotal: 5.16s\tremaining: 2.9s\n",
      "32:\tlearn: 0.0528347\ttotal: 5.3s\tremaining: 2.73s\n",
      "33:\tlearn: 0.0512612\ttotal: 5.46s\tremaining: 2.57s\n",
      "34:\tlearn: 0.0501646\ttotal: 5.62s\tremaining: 2.41s\n",
      "35:\tlearn: 0.0484056\ttotal: 5.77s\tremaining: 2.24s\n",
      "36:\tlearn: 0.0469035\ttotal: 5.93s\tremaining: 2.08s\n",
      "37:\tlearn: 0.0455089\ttotal: 6.1s\tremaining: 1.93s\n",
      "38:\tlearn: 0.0440282\ttotal: 6.25s\tremaining: 1.76s\n",
      "39:\tlearn: 0.0430188\ttotal: 6.4s\tremaining: 1.6s\n",
      "40:\tlearn: 0.0409621\ttotal: 6.56s\tremaining: 1.44s\n",
      "41:\tlearn: 0.0400675\ttotal: 6.71s\tremaining: 1.28s\n",
      "42:\tlearn: 0.0392215\ttotal: 6.86s\tremaining: 1.12s\n",
      "43:\tlearn: 0.0385816\ttotal: 7.01s\tremaining: 956ms\n",
      "44:\tlearn: 0.0364132\ttotal: 7.19s\tremaining: 798ms\n",
      "45:\tlearn: 0.0357563\ttotal: 7.34s\tremaining: 638ms\n",
      "46:\tlearn: 0.0347216\ttotal: 7.49s\tremaining: 478ms\n",
      "47:\tlearn: 0.0337944\ttotal: 7.64s\tremaining: 319ms\n",
      "48:\tlearn: 0.0326812\ttotal: 7.82s\tremaining: 160ms\n",
      "49:\tlearn: 0.0321041\ttotal: 7.97s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4571678\ttotal: 210ms\tremaining: 10.3s\n",
      "1:\tlearn: 0.3353683\ttotal: 380ms\tremaining: 9.13s\n",
      "2:\tlearn: 0.2826183\ttotal: 561ms\tremaining: 8.79s\n",
      "3:\tlearn: 0.2263994\ttotal: 719ms\tremaining: 8.27s\n",
      "4:\tlearn: 0.1912627\ttotal: 897ms\tremaining: 8.07s\n",
      "5:\tlearn: 0.1758912\ttotal: 1.06s\tremaining: 7.8s\n",
      "6:\tlearn: 0.1654990\ttotal: 1.24s\tremaining: 7.59s\n",
      "7:\tlearn: 0.1535473\ttotal: 1.4s\tremaining: 7.37s\n",
      "8:\tlearn: 0.1412947\ttotal: 1.57s\tremaining: 7.14s\n",
      "9:\tlearn: 0.1325493\ttotal: 1.74s\tremaining: 6.94s\n",
      "10:\tlearn: 0.1217935\ttotal: 1.89s\tremaining: 6.72s\n",
      "11:\tlearn: 0.1159085\ttotal: 2.07s\tremaining: 6.55s\n",
      "12:\tlearn: 0.1082270\ttotal: 2.23s\tremaining: 6.33s\n",
      "13:\tlearn: 0.1045369\ttotal: 2.38s\tremaining: 6.11s\n",
      "14:\tlearn: 0.1008763\ttotal: 2.55s\tremaining: 5.95s\n",
      "15:\tlearn: 0.0985380\ttotal: 2.7s\tremaining: 5.74s\n",
      "16:\tlearn: 0.0941326\ttotal: 2.86s\tremaining: 5.56s\n",
      "17:\tlearn: 0.0896139\ttotal: 3.02s\tremaining: 5.37s\n",
      "18:\tlearn: 0.0864273\ttotal: 3.19s\tremaining: 5.2s\n",
      "19:\tlearn: 0.0831124\ttotal: 3.35s\tremaining: 5.03s\n",
      "20:\tlearn: 0.0800353\ttotal: 3.51s\tremaining: 4.85s\n",
      "21:\tlearn: 0.0770836\ttotal: 3.67s\tremaining: 4.67s\n",
      "22:\tlearn: 0.0755158\ttotal: 3.82s\tremaining: 4.49s\n",
      "23:\tlearn: 0.0720770\ttotal: 3.98s\tremaining: 4.31s\n",
      "24:\tlearn: 0.0692419\ttotal: 4.13s\tremaining: 4.13s\n",
      "25:\tlearn: 0.0666379\ttotal: 4.28s\tremaining: 3.95s\n",
      "26:\tlearn: 0.0644548\ttotal: 4.45s\tremaining: 3.79s\n",
      "27:\tlearn: 0.0622578\ttotal: 4.61s\tremaining: 3.62s\n",
      "28:\tlearn: 0.0610170\ttotal: 4.77s\tremaining: 3.45s\n",
      "29:\tlearn: 0.0596109\ttotal: 4.92s\tremaining: 3.28s\n",
      "30:\tlearn: 0.0546613\ttotal: 5.07s\tremaining: 3.1s\n",
      "31:\tlearn: 0.0529196\ttotal: 5.22s\tremaining: 2.94s\n",
      "32:\tlearn: 0.0517769\ttotal: 5.38s\tremaining: 2.77s\n",
      "33:\tlearn: 0.0494405\ttotal: 5.55s\tremaining: 2.61s\n",
      "34:\tlearn: 0.0478636\ttotal: 5.72s\tremaining: 2.45s\n",
      "35:\tlearn: 0.0467900\ttotal: 5.87s\tremaining: 2.28s\n",
      "36:\tlearn: 0.0455389\ttotal: 6.03s\tremaining: 2.12s\n",
      "37:\tlearn: 0.0447545\ttotal: 6.19s\tremaining: 1.95s\n",
      "38:\tlearn: 0.0434660\ttotal: 6.34s\tremaining: 1.79s\n",
      "39:\tlearn: 0.0416059\ttotal: 6.5s\tremaining: 1.63s\n",
      "40:\tlearn: 0.0401444\ttotal: 6.66s\tremaining: 1.46s\n",
      "41:\tlearn: 0.0390828\ttotal: 6.82s\tremaining: 1.3s\n",
      "42:\tlearn: 0.0375184\ttotal: 7s\tremaining: 1.14s\n",
      "43:\tlearn: 0.0361744\ttotal: 7.16s\tremaining: 976ms\n",
      "44:\tlearn: 0.0334570\ttotal: 7.34s\tremaining: 816ms\n",
      "45:\tlearn: 0.0324232\ttotal: 7.54s\tremaining: 656ms\n",
      "46:\tlearn: 0.0314616\ttotal: 7.7s\tremaining: 491ms\n",
      "47:\tlearn: 0.0309523\ttotal: 7.84s\tremaining: 327ms\n",
      "48:\tlearn: 0.0306393\ttotal: 8s\tremaining: 163ms\n",
      "49:\tlearn: 0.0301620\ttotal: 8.16s\tremaining: 0us\n",
      "Learning rate set to 0.354991\n",
      "0:\tlearn: 0.4693647\ttotal: 384ms\tremaining: 18.8s\n",
      "1:\tlearn: 0.3433767\ttotal: 571ms\tremaining: 13.7s\n",
      "2:\tlearn: 0.2731609\ttotal: 749ms\tremaining: 11.7s\n",
      "3:\tlearn: 0.2249162\ttotal: 963ms\tremaining: 11.1s\n",
      "4:\tlearn: 0.2002076\ttotal: 1.12s\tremaining: 10.1s\n",
      "5:\tlearn: 0.1887517\ttotal: 1.29s\tremaining: 9.43s\n",
      "6:\tlearn: 0.1726308\ttotal: 1.46s\tremaining: 8.95s\n",
      "7:\tlearn: 0.1521450\ttotal: 1.65s\tremaining: 8.67s\n",
      "8:\tlearn: 0.1419208\ttotal: 1.88s\tremaining: 8.57s\n",
      "9:\tlearn: 0.1347483\ttotal: 2.04s\tremaining: 8.14s\n",
      "10:\tlearn: 0.1293344\ttotal: 2.24s\tremaining: 7.95s\n",
      "11:\tlearn: 0.1230817\ttotal: 2.41s\tremaining: 7.63s\n",
      "12:\tlearn: 0.1182776\ttotal: 2.58s\tremaining: 7.35s\n",
      "13:\tlearn: 0.1095192\ttotal: 2.85s\tremaining: 7.32s\n",
      "14:\tlearn: 0.1055015\ttotal: 3.02s\tremaining: 7.06s\n",
      "15:\tlearn: 0.1017528\ttotal: 3.19s\tremaining: 6.78s\n",
      "16:\tlearn: 0.0964493\ttotal: 3.35s\tremaining: 6.51s\n",
      "17:\tlearn: 0.0915865\ttotal: 3.52s\tremaining: 6.27s\n",
      "18:\tlearn: 0.0870503\ttotal: 3.69s\tremaining: 6.01s\n",
      "19:\tlearn: 0.0845205\ttotal: 3.86s\tremaining: 5.79s\n",
      "20:\tlearn: 0.0816892\ttotal: 4.02s\tremaining: 5.55s\n",
      "21:\tlearn: 0.0805772\ttotal: 4.2s\tremaining: 5.34s\n",
      "22:\tlearn: 0.0779520\ttotal: 4.37s\tremaining: 5.13s\n",
      "23:\tlearn: 0.0734310\ttotal: 4.59s\tremaining: 4.97s\n",
      "24:\tlearn: 0.0714348\ttotal: 4.78s\tremaining: 4.78s\n",
      "25:\tlearn: 0.0695038\ttotal: 4.92s\tremaining: 4.54s\n",
      "26:\tlearn: 0.0658976\ttotal: 5.1s\tremaining: 4.34s\n",
      "27:\tlearn: 0.0625345\ttotal: 5.26s\tremaining: 4.14s\n",
      "28:\tlearn: 0.0604306\ttotal: 5.43s\tremaining: 3.93s\n",
      "29:\tlearn: 0.0579023\ttotal: 5.62s\tremaining: 3.75s\n",
      "30:\tlearn: 0.0567368\ttotal: 5.78s\tremaining: 3.54s\n",
      "31:\tlearn: 0.0551625\ttotal: 5.95s\tremaining: 3.35s\n",
      "32:\tlearn: 0.0539339\ttotal: 6.1s\tremaining: 3.14s\n",
      "33:\tlearn: 0.0522602\ttotal: 6.28s\tremaining: 2.95s\n",
      "34:\tlearn: 0.0503537\ttotal: 6.43s\tremaining: 2.75s\n",
      "35:\tlearn: 0.0490238\ttotal: 6.58s\tremaining: 2.56s\n",
      "36:\tlearn: 0.0479201\ttotal: 6.75s\tremaining: 2.37s\n",
      "37:\tlearn: 0.0455464\ttotal: 6.91s\tremaining: 2.18s\n",
      "38:\tlearn: 0.0445487\ttotal: 7.07s\tremaining: 1.99s\n",
      "39:\tlearn: 0.0440352\ttotal: 7.22s\tremaining: 1.8s\n",
      "40:\tlearn: 0.0429982\ttotal: 7.39s\tremaining: 1.62s\n",
      "41:\tlearn: 0.0417776\ttotal: 7.57s\tremaining: 1.44s\n",
      "42:\tlearn: 0.0410502\ttotal: 7.77s\tremaining: 1.26s\n",
      "43:\tlearn: 0.0392410\ttotal: 8.03s\tremaining: 1.09s\n",
      "44:\tlearn: 0.0386312\ttotal: 8.26s\tremaining: 918ms\n",
      "45:\tlearn: 0.0373392\ttotal: 8.44s\tremaining: 734ms\n",
      "46:\tlearn: 0.0365788\ttotal: 8.62s\tremaining: 550ms\n",
      "47:\tlearn: 0.0356606\ttotal: 8.83s\tremaining: 368ms\n",
      "48:\tlearn: 0.0353623\ttotal: 9.01s\tremaining: 184ms\n",
      "49:\tlearn: 0.0330051\ttotal: 9.19s\tremaining: 0us\n",
      "Learning rate set to 0.390458\n",
      "0:\tlearn: 0.4351847\ttotal: 214ms\tremaining: 10.5s\n",
      "1:\tlearn: 0.3060675\ttotal: 384ms\tremaining: 9.22s\n",
      "2:\tlearn: 0.2517539\ttotal: 544ms\tremaining: 8.53s\n",
      "3:\tlearn: 0.2169163\ttotal: 730ms\tremaining: 8.39s\n",
      "4:\tlearn: 0.1809018\ttotal: 930ms\tremaining: 8.37s\n",
      "5:\tlearn: 0.1653412\ttotal: 1.14s\tremaining: 8.36s\n",
      "6:\tlearn: 0.1538079\ttotal: 1.34s\tremaining: 8.27s\n",
      "7:\tlearn: 0.1424972\ttotal: 1.55s\tremaining: 8.17s\n",
      "8:\tlearn: 0.1314580\ttotal: 1.74s\tremaining: 7.91s\n",
      "9:\tlearn: 0.1273361\ttotal: 1.89s\tremaining: 7.57s\n",
      "10:\tlearn: 0.1102982\ttotal: 2.06s\tremaining: 7.31s\n",
      "11:\tlearn: 0.1049125\ttotal: 2.23s\tremaining: 7.05s\n",
      "12:\tlearn: 0.0986745\ttotal: 2.4s\tremaining: 6.83s\n",
      "13:\tlearn: 0.0949790\ttotal: 2.59s\tremaining: 6.67s\n",
      "14:\tlearn: 0.0916126\ttotal: 2.78s\tremaining: 6.49s\n",
      "15:\tlearn: 0.0896065\ttotal: 2.98s\tremaining: 6.33s\n",
      "16:\tlearn: 0.0864177\ttotal: 3.15s\tremaining: 6.11s\n",
      "17:\tlearn: 0.0823826\ttotal: 3.31s\tremaining: 5.89s\n",
      "18:\tlearn: 0.0803489\ttotal: 3.55s\tremaining: 5.79s\n",
      "19:\tlearn: 0.0773858\ttotal: 3.77s\tremaining: 5.66s\n",
      "20:\tlearn: 0.0714126\ttotal: 4.03s\tremaining: 5.56s\n",
      "21:\tlearn: 0.0687569\ttotal: 4.21s\tremaining: 5.36s\n",
      "22:\tlearn: 0.0664688\ttotal: 4.37s\tremaining: 5.13s\n",
      "23:\tlearn: 0.0650268\ttotal: 4.53s\tremaining: 4.91s\n",
      "24:\tlearn: 0.0631916\ttotal: 4.73s\tremaining: 4.73s\n",
      "25:\tlearn: 0.0616862\ttotal: 4.94s\tremaining: 4.56s\n",
      "26:\tlearn: 0.0596691\ttotal: 5.11s\tremaining: 4.35s\n",
      "27:\tlearn: 0.0579327\ttotal: 5.29s\tremaining: 4.16s\n",
      "28:\tlearn: 0.0563567\ttotal: 5.46s\tremaining: 3.96s\n",
      "29:\tlearn: 0.0541409\ttotal: 5.79s\tremaining: 3.86s\n",
      "30:\tlearn: 0.0526420\ttotal: 6.05s\tremaining: 3.71s\n",
      "31:\tlearn: 0.0511054\ttotal: 6.22s\tremaining: 3.5s\n",
      "32:\tlearn: 0.0497017\ttotal: 6.39s\tremaining: 3.29s\n",
      "33:\tlearn: 0.0475608\ttotal: 6.54s\tremaining: 3.08s\n",
      "34:\tlearn: 0.0446141\ttotal: 6.71s\tremaining: 2.88s\n",
      "35:\tlearn: 0.0439322\ttotal: 6.87s\tremaining: 2.67s\n",
      "36:\tlearn: 0.0431829\ttotal: 7.02s\tremaining: 2.47s\n",
      "37:\tlearn: 0.0423298\ttotal: 7.2s\tremaining: 2.27s\n",
      "38:\tlearn: 0.0414292\ttotal: 7.4s\tremaining: 2.09s\n",
      "39:\tlearn: 0.0406129\ttotal: 7.56s\tremaining: 1.89s\n",
      "40:\tlearn: 0.0390369\ttotal: 7.72s\tremaining: 1.7s\n",
      "41:\tlearn: 0.0383045\ttotal: 7.89s\tremaining: 1.5s\n",
      "42:\tlearn: 0.0371744\ttotal: 8.08s\tremaining: 1.31s\n",
      "43:\tlearn: 0.0365461\ttotal: 8.24s\tremaining: 1.12s\n",
      "44:\tlearn: 0.0352915\ttotal: 8.41s\tremaining: 935ms\n",
      "45:\tlearn: 0.0346671\ttotal: 8.56s\tremaining: 745ms\n",
      "46:\tlearn: 0.0334469\ttotal: 8.72s\tremaining: 557ms\n",
      "47:\tlearn: 0.0319473\ttotal: 8.88s\tremaining: 370ms\n",
      "48:\tlearn: 0.0313053\ttotal: 9.04s\tremaining: 185ms\n",
      "49:\tlearn: 0.0308499\ttotal: 9.19s\tremaining: 0us\n",
      "Model saved to disk at: temporary_files/CatBoost_Model.pickle\n",
      "Model saved to disk at: temporary_files/Random_Forest_Model.pickle\n",
      "Model building complete, final results with train/test datasets below:\n",
      "\n",
      "           model          best_params  best_score  best_standard_deviation\n",
      "0       CatBoost   {'iterations': 50}    0.970705                 0.005185\n",
      "1  Random_Forest  {'n_estimators': 1}    0.790431                 0.022776\n"
     ]
    }
   ],
   "source": [
    "# Build the models.\n",
    "# TODO - EXPLAIN SAVE OPTION....\n",
    "ml_model.build_models(save_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the models now built, we can see the models seem to be xxxxx\n",
    "\n",
    "We can now evaluate the quality of the models on the validation dataset. Again, thankfully the accuracy is quite high.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the CatBoost model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CatComp       0.95      0.97      0.96       566\n",
      "  NotCatComp       0.98      0.97      0.97       846\n",
      "\n",
      "    accuracy                           0.97      1412\n",
      "   macro avg       0.96      0.97      0.97      1412\n",
      "weighted avg       0.97      0.97      0.97      1412\n",
      "\n",
      "Classification report for the Random_Forest model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CatComp       0.75      0.73      0.74       566\n",
      "  NotCatComp       0.82      0.83      0.83       846\n",
      "\n",
      "    accuracy                           0.79      1412\n",
      "   macro avg       0.78      0.78      0.78      1412\n",
      "weighted avg       0.79      0.79      0.79      1412\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model quality\n",
    "print(ml_model.evaluate_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular way to evaluate model quality is to generate confusion matrices. \n",
    "\n",
    "We can do that as well as shown below. \n",
    "You can easily plot these confusion matrices in whatever graphing program you like, but in this case, I will use seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = ml_model.generate_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion_matrices[\"CatBoost\"], annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(confusion_matrices[\"Random_Forest\"], annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Work up the Machine Learning with the post_proccessing.py module. \n",
    "\n",
    "With this module, we can analyse our results in more detail to understand what features each model determined where important for distignugshing between each state. \n",
    "\n",
    "In order to perform the analysis we will need to load in the models previously generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will make an instance of the SupervisedPostProcessor class.\n",
    "post_proc = post_proccessing.SupervisedPostProcessor(\n",
    "    out_dir=\"outputs/retro_aldol_ml\",\n",
    ")\n",
    "\n",
    "# Option 1 - Load models from the instance of the SupervisedModel class. \n",
    "post_proc.load_models_from_instance(supervised_model=ml_model)\n",
    "\n",
    "# Option 2 - Load models from disk.\n",
    "post_proc.load_models_from_disk(models_to_use=[\"CatBoost\", \"Random_Forest\"]) # \"Ada_Boost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/retro_aldol_ml/CatBoost_Feature_Importances.csv written to disk.\n",
      "outputs/retro_aldol_ml/Random_Forest_Feature_Importances.csv written to disk.\n",
      "All feature importances written to disk.\n"
     ]
    }
   ],
   "source": [
    "# After preparing the class we can now determine the feature importances for each model.\n",
    "post_proc.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/retro_aldol_ml/CatBoost_Per_Residue_Importances.csv written to disk.\n",
      "outputs/retro_aldol_ml/Random_Forest_Per_Residue_Importances.csv written to disk.\n",
      "All per residue feature importance scores were saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# We can also project these per feature importances onto the per-residue level. \n",
    "# This is done by summing each residues features importances and normalising so that the residue\n",
    "#  with the greatest overall  \n",
    "post_proc.get_per_res_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['out_dir', 'feat_names', 'best_models', 'all_feature_importances', 'all_per_residue_scores'])\n"
     ]
    }
   ],
   "source": [
    "# Again, if we take a look at the class attributes we can see the per feature and \n",
    "# per residue importances were not just saved to disk, but are also now stored in the class\n",
    "# meaning you can analyse them here if you wish. \n",
    "print(post_proc.__dict__.keys())\n",
    "all_per_res_scores = post_proc.all_per_residue_scores\n",
    "all_feature_scores = post_proc.all_feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 Projecting the Results onto Protein Structures with the pymol_projections.py module. \n",
    " \n",
    "Naturally, we may want to visualise some of the results we have generated above onto a protein structure. We can take advantage of the functions provided in the pymol_projections.py module to do this. \n",
    "\n",
    "As the name suggests this will output [PyMOL](https://pymol.org/) compatible python scripts which can be run to represent the results at either the: \n",
    "\n",
    "1. Per feature level. (Cylinders are drawn between both residues in each feature, with the cylinder radii marking how large the relative importance is. \n",
    "2. Per residue level. The carbon alpha of each residue will be depicted as a sphere, with the sphere radii depicting the relative importance of the residue for the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: outputs/retro_aldol_ml/CatBoost_Pymol_Per_Res_Scores.py was written to disk.\n",
      "The file: outputs/retro_aldol_ml/Random_Forest_Pymol_Per_Res_Scores.py was written to disk.\n"
     ]
    }
   ],
   "source": [
    "pymol_projections.project_multiple_per_res_scores(\n",
    "    all_per_res_scores=all_per_res_scores,\n",
    "    out_dir=\"outputs/retro_aldol_ml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: outputs/retro_aldol_ml/CatBoost_Pymol_Per_Feature_Scores.py was written to disk.\n",
      "The file: outputs/retro_aldol_ml/Random_Forest_Pymol_Per_Feature_Scores.py was written to disk.\n"
     ]
    }
   ],
   "source": [
    "pymol_projections.project_multiple_per_feature_scores(\n",
    "    all_feature_scores=all_feature_scores,\n",
    "    numb_features=\"all\",\n",
    "    out_dir=\"outputs/retro_aldol_ml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ADD Picture of the outputs here as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "add0b5d4ce7b8e8a859fa0dda4e7913231effb3978a57212389923662b8875fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('ML_Py3_8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
