{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for Supervised and Unsupervised Learning on Simulations of a Retro Aldolase\n",
    "\n",
    "In this jupyter notebook we will use the model_building.py module to identify differences in the molecular interactions for a retro aldolase when it is in a catatlytically competent state and when it is \n",
    "\n",
    "\n",
    "across PTP1B\n",
    "when the WPD-loop of PTP1B is in the Closed state, versus when the WPD-loop is in the Open state.\n",
    "This notebook will also cover all the pre- and post-processing steps requireds to prepare, analyse and visualise the results.\n",
    "\n",
    "The dataset used here is for PTP1B is the same as what we used in the manuscript. \n",
    "\n",
    "<center><img src=\"miscellaneous/TODO.png\" alt=\"Drawing\" style=\"width: 70%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # note temporary... \n",
    "sys.path.append(\"..\") # note temporary...\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from key_interactions_finder import pycontact_processing\n",
    "from key_interactions_finder import data_preperation\n",
    "from key_interactions_finder import model_building\n",
    "from key_interactions_finder import post_proccessing\n",
    "from key_interactions_finder import pymol_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Process PyContact files with the pycontact_processing.py module \n",
    "\n",
    "In this section we will work with the PyContact output files generated. \n",
    "Here we will merge our seperate runs together and remove any false interactions that can be generated by the PyContact library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your PyContact file(s) have been succefully processed.\n",
      "You have 3056 features and 10000 observations.\n",
      "The fully processed dataframe is accesible from the '.prepared_df' class attribute.\n"
     ]
    }
   ],
   "source": [
    "pycontact_files_horizontal = [\"PyContact_Per_Frame_Interactions_Block1.csv\", \"PyContact_Per_Frame_Interactions_Block2.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block3.csv\", \"PyContact_Per_Frame_Interactions_Block4.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block5.csv\", \"PyContact_Per_Frame_Interactions_Block6.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block7.csv\", \"PyContact_Per_Frame_Interactions_Block8.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block9.csv\", \"PyContact_Per_Frame_Interactions_Block10.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block11.csv\", \"PyContact_Per_Frame_Interactions_Block12.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block13.csv\", \"PyContact_Per_Frame_Interactions_Block14.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block15.csv\", \"PyContact_Per_Frame_Interactions_Block16.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block17.csv\"]\n",
    "\n",
    "pycontact_dataset = pycontact_processing.PyContactInitializer(\n",
    "    pycontact_files=pycontact_files_horizontal,\n",
    "    multiple_files=True,\n",
    "    merge_files_method=\"horizontal\",  \n",
    "    remove_false_interactions=True,\n",
    "    in_dir=\"datasets/retrol_aldolase_data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1Pro 140Glu Hbond bb-sc</th>\n",
       "      <th>1Pro 135Ile Hbond bb-bb</th>\n",
       "      <th>1Pro 136Leu Hbond bb-bb</th>\n",
       "      <th>1Pro 113Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 12Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 137Thr Hbond bb-sc</th>\n",
       "      <th>1Pro 3Tyr Hbond bb-bb</th>\n",
       "      <th>2Arg 137Thr Hbond sc-bb</th>\n",
       "      <th>2Arg 140Glu Hbond bb-sc</th>\n",
       "      <th>2Arg 136Leu Hbond sc-bb</th>\n",
       "      <th>...</th>\n",
       "      <th>242Ile 212Ile Other bb-sc</th>\n",
       "      <th>246Ile 46Ala Other sc-bb</th>\n",
       "      <th>242Ile 234Ser Other sc-bb</th>\n",
       "      <th>244Glu 222Arg Other bb-sc</th>\n",
       "      <th>241Lys 211Gly Other sc-bb</th>\n",
       "      <th>241Lys 71Phe Other bb-sc</th>\n",
       "      <th>246Ile 77Val Other sc-bb</th>\n",
       "      <th>242Ile 237Arg Other sc-bb</th>\n",
       "      <th>245Leu 44Ile Other bb-sc</th>\n",
       "      <th>242Ile 48Ile Other sc-bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.69070</td>\n",
       "      <td>2.69143</td>\n",
       "      <td>3.20350</td>\n",
       "      <td>3.28620</td>\n",
       "      <td>1.36506</td>\n",
       "      <td>0.74495</td>\n",
       "      <td>0.64727</td>\n",
       "      <td>3.34225</td>\n",
       "      <td>0.87675</td>\n",
       "      <td>9.87756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.47441</td>\n",
       "      <td>3.23497</td>\n",
       "      <td>4.82080</td>\n",
       "      <td>1.07496</td>\n",
       "      <td>0.25386</td>\n",
       "      <td>2.58459</td>\n",
       "      <td>0.45446</td>\n",
       "      <td>2.34583</td>\n",
       "      <td>0.45081</td>\n",
       "      <td>9.17317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.11200</td>\n",
       "      <td>1.66876</td>\n",
       "      <td>1.58322</td>\n",
       "      <td>2.21242</td>\n",
       "      <td>0.02944</td>\n",
       "      <td>1.15886</td>\n",
       "      <td>0.81023</td>\n",
       "      <td>2.03891</td>\n",
       "      <td>0.84995</td>\n",
       "      <td>6.66903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.28064</td>\n",
       "      <td>3.30286</td>\n",
       "      <td>1.54644</td>\n",
       "      <td>0.05986</td>\n",
       "      <td>0.96466</td>\n",
       "      <td>2.25997</td>\n",
       "      <td>0.43410</td>\n",
       "      <td>1.61199</td>\n",
       "      <td>0.36436</td>\n",
       "      <td>7.82080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.54559</td>\n",
       "      <td>2.78183</td>\n",
       "      <td>1.79891</td>\n",
       "      <td>0.27192</td>\n",
       "      <td>0.44629</td>\n",
       "      <td>1.13325</td>\n",
       "      <td>0.74145</td>\n",
       "      <td>0.25292</td>\n",
       "      <td>0.07107</td>\n",
       "      <td>2.40651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>10.43428</td>\n",
       "      <td>2.87244</td>\n",
       "      <td>0.37792</td>\n",
       "      <td>0.84401</td>\n",
       "      <td>1.36240</td>\n",
       "      <td>0.45684</td>\n",
       "      <td>0.79760</td>\n",
       "      <td>4.82421</td>\n",
       "      <td>0.83238</td>\n",
       "      <td>8.17372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7.96627</td>\n",
       "      <td>3.38587</td>\n",
       "      <td>0.16006</td>\n",
       "      <td>0.06228</td>\n",
       "      <td>0.51337</td>\n",
       "      <td>4.56594</td>\n",
       "      <td>0.10768</td>\n",
       "      <td>4.04402</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.07718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7.35284</td>\n",
       "      <td>3.23050</td>\n",
       "      <td>0.00974</td>\n",
       "      <td>0.76542</td>\n",
       "      <td>0.93003</td>\n",
       "      <td>0.90531</td>\n",
       "      <td>0.45525</td>\n",
       "      <td>3.65877</td>\n",
       "      <td>0.09956</td>\n",
       "      <td>10.29806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7.92164</td>\n",
       "      <td>2.47504</td>\n",
       "      <td>0.27218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10206</td>\n",
       "      <td>2.02611</td>\n",
       "      <td>0.10234</td>\n",
       "      <td>1.57470</td>\n",
       "      <td>0.01281</td>\n",
       "      <td>5.87328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>8.05632</td>\n",
       "      <td>3.65106</td>\n",
       "      <td>0.13702</td>\n",
       "      <td>0.81143</td>\n",
       "      <td>1.85742</td>\n",
       "      <td>2.68653</td>\n",
       "      <td>0.22565</td>\n",
       "      <td>2.16886</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>5.60869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3056 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1Pro 140Glu Hbond bb-sc  1Pro 135Ile Hbond bb-bb  \\\n",
       "0                    10.69070                  2.69143   \n",
       "1                    11.47441                  3.23497   \n",
       "2                    10.11200                  1.66876   \n",
       "3                     9.28064                  3.30286   \n",
       "4                     8.54559                  2.78183   \n",
       "...                       ...                      ...   \n",
       "9995                 10.43428                  2.87244   \n",
       "9996                  7.96627                  3.38587   \n",
       "9997                  7.35284                  3.23050   \n",
       "9998                  7.92164                  2.47504   \n",
       "9999                  8.05632                  3.65106   \n",
       "\n",
       "      1Pro 136Leu Hbond bb-bb  1Pro 113Val Hydrophobic sc-sc  \\\n",
       "0                     3.20350                        3.28620   \n",
       "1                     4.82080                        1.07496   \n",
       "2                     1.58322                        2.21242   \n",
       "3                     1.54644                        0.05986   \n",
       "4                     1.79891                        0.27192   \n",
       "...                       ...                            ...   \n",
       "9995                  0.37792                        0.84401   \n",
       "9996                  0.16006                        0.06228   \n",
       "9997                  0.00974                        0.76542   \n",
       "9998                  0.27218                        0.00000   \n",
       "9999                  0.13702                        0.81143   \n",
       "\n",
       "      1Pro 12Val Hydrophobic sc-sc  1Pro 137Thr Hbond bb-sc  \\\n",
       "0                          1.36506                  0.74495   \n",
       "1                          0.25386                  2.58459   \n",
       "2                          0.02944                  1.15886   \n",
       "3                          0.96466                  2.25997   \n",
       "4                          0.44629                  1.13325   \n",
       "...                            ...                      ...   \n",
       "9995                       1.36240                  0.45684   \n",
       "9996                       0.51337                  4.56594   \n",
       "9997                       0.93003                  0.90531   \n",
       "9998                       0.10206                  2.02611   \n",
       "9999                       1.85742                  2.68653   \n",
       "\n",
       "      1Pro 3Tyr Hbond bb-bb  2Arg 137Thr Hbond sc-bb  2Arg 140Glu Hbond bb-sc  \\\n",
       "0                   0.64727                  3.34225                  0.87675   \n",
       "1                   0.45446                  2.34583                  0.45081   \n",
       "2                   0.81023                  2.03891                  0.84995   \n",
       "3                   0.43410                  1.61199                  0.36436   \n",
       "4                   0.74145                  0.25292                  0.07107   \n",
       "...                     ...                      ...                      ...   \n",
       "9995                0.79760                  4.82421                  0.83238   \n",
       "9996                0.10768                  4.04402                  0.00000   \n",
       "9997                0.45525                  3.65877                  0.09956   \n",
       "9998                0.10234                  1.57470                  0.01281   \n",
       "9999                0.22565                  2.16886                  0.03367   \n",
       "\n",
       "      2Arg 136Leu Hbond sc-bb  ...  242Ile 212Ile Other bb-sc  \\\n",
       "0                     9.87756  ...                        0.0   \n",
       "1                     9.17317  ...                        0.0   \n",
       "2                     6.66903  ...                        0.0   \n",
       "3                     7.82080  ...                        0.0   \n",
       "4                     2.40651  ...                        0.0   \n",
       "...                       ...  ...                        ...   \n",
       "9995                  8.17372  ...                        0.0   \n",
       "9996                  5.07718  ...                        0.0   \n",
       "9997                 10.29806  ...                        0.0   \n",
       "9998                  5.87328  ...                        0.0   \n",
       "9999                  5.60869  ...                        0.0   \n",
       "\n",
       "      246Ile 46Ala Other sc-bb  242Ile 234Ser Other sc-bb  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "9995                       0.0                        0.0   \n",
       "9996                       0.0                        0.0   \n",
       "9997                       0.0                        0.0   \n",
       "9998                       0.0                        0.0   \n",
       "9999                       0.0                        0.0   \n",
       "\n",
       "      244Glu 222Arg Other bb-sc  241Lys 211Gly Other sc-bb  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "9995                        0.0                        0.0   \n",
       "9996                        0.0                        0.0   \n",
       "9997                        0.0                        0.0   \n",
       "9998                        0.0                        0.0   \n",
       "9999                        0.0                        0.0   \n",
       "\n",
       "      241Lys 71Phe Other bb-sc  246Ile 77Val Other sc-bb  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                       0.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "9995                       0.0                       0.0   \n",
       "9996                       0.0                       0.0   \n",
       "9997                       0.0                       0.0   \n",
       "9998                       0.0                       0.0   \n",
       "9999                       0.0                       0.0   \n",
       "\n",
       "      242Ile 237Arg Other sc-bb  245Leu 44Ile Other bb-sc  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "9995                        0.0                       0.0   \n",
       "9996                        0.0                       0.0   \n",
       "9997                        0.0                       0.0   \n",
       "9998                        0.0                       0.0   \n",
       "9999                        0.0                       0.0   \n",
       "\n",
       "      242Ile 48Ile Other sc-bb  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  \n",
       "...                        ...  \n",
       "9995                       0.0  \n",
       "9996                       0.0  \n",
       "9997                       0.0  \n",
       "9998                       0.0  \n",
       "9999                       0.0  \n",
       "\n",
       "[10000 rows x 3056 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As outputted above, we can inspect the newly prepared dataset by accessing the '.prepared_df' class attribute as follows:\n",
    "pycontact_dataset.prepared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Prepare the Dataset for Statistical Analysis with the data_preperation.py module. \n",
    "\n",
    "In this step, we take our dataframe and merge our per frame classifications file to it.\n",
    "We can also optionally perform several forms of filtering to select what types of interactions we\n",
    "would like to study.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your features and class datasets have been succesufully merged.\n",
      "You can access this dataset through the class attribute: '.df_feat_class'.\n"
     ]
    }
   ],
   "source": [
    "# First we generate an instance of the SupervisedFeatureData class (because we have per frame class labels).\n",
    "\n",
    "classifications_file = \"datasets/retrol_aldolase_data/4a2s_RA95_5_Classifications.txt\"\n",
    "\n",
    "supervised_dataset = data_preperation.SupervisedFeatureData(\n",
    "    input_df=pycontact_dataset.prepared_df,\n",
    "    classifications_file=classifications_file,\n",
    "    header_present=True # If your classifications_file has a header present, set to True.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>1Pro 140Glu Hbond bb-sc</th>\n",
       "      <th>1Pro 135Ile Hbond bb-bb</th>\n",
       "      <th>1Pro 136Leu Hbond bb-bb</th>\n",
       "      <th>1Pro 113Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 12Val Hydrophobic sc-sc</th>\n",
       "      <th>1Pro 137Thr Hbond bb-sc</th>\n",
       "      <th>1Pro 3Tyr Hbond bb-bb</th>\n",
       "      <th>2Arg 137Thr Hbond sc-bb</th>\n",
       "      <th>2Arg 140Glu Hbond bb-sc</th>\n",
       "      <th>...</th>\n",
       "      <th>242Ile 212Ile Other bb-sc</th>\n",
       "      <th>246Ile 46Ala Other sc-bb</th>\n",
       "      <th>242Ile 234Ser Other sc-bb</th>\n",
       "      <th>244Glu 222Arg Other bb-sc</th>\n",
       "      <th>241Lys 211Gly Other sc-bb</th>\n",
       "      <th>241Lys 71Phe Other bb-sc</th>\n",
       "      <th>246Ile 77Val Other sc-bb</th>\n",
       "      <th>242Ile 237Arg Other sc-bb</th>\n",
       "      <th>245Leu 44Ile Other bb-sc</th>\n",
       "      <th>242Ile 48Ile Other sc-bb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>10.69070</td>\n",
       "      <td>2.69143</td>\n",
       "      <td>3.20350</td>\n",
       "      <td>3.28620</td>\n",
       "      <td>1.36506</td>\n",
       "      <td>0.74495</td>\n",
       "      <td>0.64727</td>\n",
       "      <td>3.34225</td>\n",
       "      <td>0.87675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>11.47441</td>\n",
       "      <td>3.23497</td>\n",
       "      <td>4.82080</td>\n",
       "      <td>1.07496</td>\n",
       "      <td>0.25386</td>\n",
       "      <td>2.58459</td>\n",
       "      <td>0.45446</td>\n",
       "      <td>2.34583</td>\n",
       "      <td>0.45081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>10.11200</td>\n",
       "      <td>1.66876</td>\n",
       "      <td>1.58322</td>\n",
       "      <td>2.21242</td>\n",
       "      <td>0.02944</td>\n",
       "      <td>1.15886</td>\n",
       "      <td>0.81023</td>\n",
       "      <td>2.03891</td>\n",
       "      <td>0.84995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>9.28064</td>\n",
       "      <td>3.30286</td>\n",
       "      <td>1.54644</td>\n",
       "      <td>0.05986</td>\n",
       "      <td>0.96466</td>\n",
       "      <td>2.25997</td>\n",
       "      <td>0.43410</td>\n",
       "      <td>1.61199</td>\n",
       "      <td>0.36436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NotCatComp</td>\n",
       "      <td>8.54559</td>\n",
       "      <td>2.78183</td>\n",
       "      <td>1.79891</td>\n",
       "      <td>0.27192</td>\n",
       "      <td>0.44629</td>\n",
       "      <td>1.13325</td>\n",
       "      <td>0.74145</td>\n",
       "      <td>0.25292</td>\n",
       "      <td>0.07107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>10.43428</td>\n",
       "      <td>2.87244</td>\n",
       "      <td>0.37792</td>\n",
       "      <td>0.84401</td>\n",
       "      <td>1.36240</td>\n",
       "      <td>0.45684</td>\n",
       "      <td>0.79760</td>\n",
       "      <td>4.82421</td>\n",
       "      <td>0.83238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>7.96627</td>\n",
       "      <td>3.38587</td>\n",
       "      <td>0.16006</td>\n",
       "      <td>0.06228</td>\n",
       "      <td>0.51337</td>\n",
       "      <td>4.56594</td>\n",
       "      <td>0.10768</td>\n",
       "      <td>4.04402</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>7.35284</td>\n",
       "      <td>3.23050</td>\n",
       "      <td>0.00974</td>\n",
       "      <td>0.76542</td>\n",
       "      <td>0.93003</td>\n",
       "      <td>0.90531</td>\n",
       "      <td>0.45525</td>\n",
       "      <td>3.65877</td>\n",
       "      <td>0.09956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>7.92164</td>\n",
       "      <td>2.47504</td>\n",
       "      <td>0.27218</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10206</td>\n",
       "      <td>2.02611</td>\n",
       "      <td>0.10234</td>\n",
       "      <td>1.57470</td>\n",
       "      <td>0.01281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>CatComp</td>\n",
       "      <td>8.05632</td>\n",
       "      <td>3.65106</td>\n",
       "      <td>0.13702</td>\n",
       "      <td>0.81143</td>\n",
       "      <td>1.85742</td>\n",
       "      <td>2.68653</td>\n",
       "      <td>0.22565</td>\n",
       "      <td>2.16886</td>\n",
       "      <td>0.03367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3057 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classes  1Pro 140Glu Hbond bb-sc  1Pro 135Ile Hbond bb-bb  \\\n",
       "0     NotCatComp                 10.69070                  2.69143   \n",
       "1     NotCatComp                 11.47441                  3.23497   \n",
       "2     NotCatComp                 10.11200                  1.66876   \n",
       "3     NotCatComp                  9.28064                  3.30286   \n",
       "4     NotCatComp                  8.54559                  2.78183   \n",
       "...          ...                      ...                      ...   \n",
       "9995     CatComp                 10.43428                  2.87244   \n",
       "9996     CatComp                  7.96627                  3.38587   \n",
       "9997     CatComp                  7.35284                  3.23050   \n",
       "9998     CatComp                  7.92164                  2.47504   \n",
       "9999     CatComp                  8.05632                  3.65106   \n",
       "\n",
       "      1Pro 136Leu Hbond bb-bb  1Pro 113Val Hydrophobic sc-sc  \\\n",
       "0                     3.20350                        3.28620   \n",
       "1                     4.82080                        1.07496   \n",
       "2                     1.58322                        2.21242   \n",
       "3                     1.54644                        0.05986   \n",
       "4                     1.79891                        0.27192   \n",
       "...                       ...                            ...   \n",
       "9995                  0.37792                        0.84401   \n",
       "9996                  0.16006                        0.06228   \n",
       "9997                  0.00974                        0.76542   \n",
       "9998                  0.27218                        0.00000   \n",
       "9999                  0.13702                        0.81143   \n",
       "\n",
       "      1Pro 12Val Hydrophobic sc-sc  1Pro 137Thr Hbond bb-sc  \\\n",
       "0                          1.36506                  0.74495   \n",
       "1                          0.25386                  2.58459   \n",
       "2                          0.02944                  1.15886   \n",
       "3                          0.96466                  2.25997   \n",
       "4                          0.44629                  1.13325   \n",
       "...                            ...                      ...   \n",
       "9995                       1.36240                  0.45684   \n",
       "9996                       0.51337                  4.56594   \n",
       "9997                       0.93003                  0.90531   \n",
       "9998                       0.10206                  2.02611   \n",
       "9999                       1.85742                  2.68653   \n",
       "\n",
       "      1Pro 3Tyr Hbond bb-bb  2Arg 137Thr Hbond sc-bb  2Arg 140Glu Hbond bb-sc  \\\n",
       "0                   0.64727                  3.34225                  0.87675   \n",
       "1                   0.45446                  2.34583                  0.45081   \n",
       "2                   0.81023                  2.03891                  0.84995   \n",
       "3                   0.43410                  1.61199                  0.36436   \n",
       "4                   0.74145                  0.25292                  0.07107   \n",
       "...                     ...                      ...                      ...   \n",
       "9995                0.79760                  4.82421                  0.83238   \n",
       "9996                0.10768                  4.04402                  0.00000   \n",
       "9997                0.45525                  3.65877                  0.09956   \n",
       "9998                0.10234                  1.57470                  0.01281   \n",
       "9999                0.22565                  2.16886                  0.03367   \n",
       "\n",
       "      ...  242Ile 212Ile Other bb-sc  246Ile 46Ala Other sc-bb  \\\n",
       "0     ...                        0.0                       0.0   \n",
       "1     ...                        0.0                       0.0   \n",
       "2     ...                        0.0                       0.0   \n",
       "3     ...                        0.0                       0.0   \n",
       "4     ...                        0.0                       0.0   \n",
       "...   ...                        ...                       ...   \n",
       "9995  ...                        0.0                       0.0   \n",
       "9996  ...                        0.0                       0.0   \n",
       "9997  ...                        0.0                       0.0   \n",
       "9998  ...                        0.0                       0.0   \n",
       "9999  ...                        0.0                       0.0   \n",
       "\n",
       "      242Ile 234Ser Other sc-bb  244Glu 222Arg Other bb-sc  \\\n",
       "0                           0.0                        0.0   \n",
       "1                           0.0                        0.0   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           0.0                        0.0   \n",
       "...                         ...                        ...   \n",
       "9995                        0.0                        0.0   \n",
       "9996                        0.0                        0.0   \n",
       "9997                        0.0                        0.0   \n",
       "9998                        0.0                        0.0   \n",
       "9999                        0.0                        0.0   \n",
       "\n",
       "      241Lys 211Gly Other sc-bb  241Lys 71Phe Other bb-sc  \\\n",
       "0                           0.0                       0.0   \n",
       "1                           0.0                       0.0   \n",
       "2                           0.0                       0.0   \n",
       "3                           0.0                       0.0   \n",
       "4                           0.0                       0.0   \n",
       "...                         ...                       ...   \n",
       "9995                        0.0                       0.0   \n",
       "9996                        0.0                       0.0   \n",
       "9997                        0.0                       0.0   \n",
       "9998                        0.0                       0.0   \n",
       "9999                        0.0                       0.0   \n",
       "\n",
       "      246Ile 77Val Other sc-bb  242Ile 237Arg Other sc-bb  \\\n",
       "0                          0.0                        0.0   \n",
       "1                          0.0                        0.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        0.0   \n",
       "...                        ...                        ...   \n",
       "9995                       0.0                        0.0   \n",
       "9996                       0.0                        0.0   \n",
       "9997                       0.0                        0.0   \n",
       "9998                       0.0                        0.0   \n",
       "9999                       0.0                        0.0   \n",
       "\n",
       "      245Leu 44Ile Other bb-sc  242Ile 48Ile Other sc-bb  \n",
       "0                          0.0                       0.0  \n",
       "1                          0.0                       0.0  \n",
       "2                          0.0                       0.0  \n",
       "3                          0.0                       0.0  \n",
       "4                          0.0                       0.0  \n",
       "...                        ...                       ...  \n",
       "9995                       0.0                       0.0  \n",
       "9996                       0.0                       0.0  \n",
       "9997                       0.0                       0.0  \n",
       "9998                       0.0                       0.0  \n",
       "9999                       0.0                       0.0  \n",
       "\n",
       "[10000 rows x 3057 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As stated above to access the newly generated dataframe we can use the class attribute as follows\n",
    "supervised_dataset.df_feat_class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional Feature Filtering\n",
    "\n",
    "In the above dataframe we have 3057 columns (so 3057 features). We can take all of these forward for the stastical analysis or we can perform some filtering in advance (the choice is yours). \n",
    "There are four built in filtering methods available to you:\n",
    "\n",
    "1. filter_by_occupancy(min_occupancy) - Remove features that have an %occupancy less than the provided cut-off. %Occupancy is the % of frames with a non 0 value, i.e. the interaction is present in that frame.\n",
    "\n",
    "2. filter_by_interaction_type(interaction_types_included). - PyContact defines four types of interactions (\"Hbond\", \"Saltbr\", \"Hydrophobic\", \"Other\"). You select the interactions your want to INCLUDE.\n",
    "\n",
    "3. filter_by_main_or_side_chain(main_side_chain_types_included) PyContact can also define if each interaction is primarily from the backbone or side-chain for each residue. You select the interaction combinations you want to INCLUDE. Options are: \"bb-bb\", \"sc-sc\", \"bb-sc\", \"sc-bb\". Where bb = backbone and sc = sidechain.\n",
    "\n",
    "4. filter_by_avg_strength(average_strength_cut_off) - PyContact calculates a per frame contact score/strength for each interaction. You can filter features by the average score. Values below the cut-off are removed. \n",
    "\n",
    "5. reset_filtering() - This method allows you to reset any filtering commands you have already called. (i.e. resets the filtered dataframe back to the unfiltered dataframe.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before any filtering: 3057\n",
      "Number of features after filtering by occupancy: 1413\n",
      "Number of features after NOT filtering by interaction type: 796\n",
      "Number of features after NOT filtering by main or side chain: 796\n",
      "Number of features after filtering by average interaction scores: 717\n"
     ]
    }
   ],
   "source": [
    "# An example of filtering the dataset using the 4 available methods. \n",
    "\n",
    "print(f\"Number of features before any filtering: {len(supervised_dataset.df_feat_class.columns)}\")\n",
    "\n",
    "# Features with a %occupancy of less than 25% are removed. \n",
    "supervised_dataset.filter_by_occupancy(min_occupancy=25)\n",
    "print(f\"Number of features after filtering by occupancy: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# No filtering performed here as all possible combinations are included. \n",
    "supervised_dataset.filter_by_interaction_type(\n",
    "    interaction_types_included=[\"Hbond\"]) # \"Saltbr\", \"Hydrophobic\", \"Other\" #TODO put back\n",
    "print(f\"Number of features after NOT filtering by interaction type: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# No filtering performed here as all possible combinations are included. \n",
    "supervised_dataset.filter_by_main_or_side_chain(\n",
    "    main_side_chain_types_included=[\"bb-bb\", \"sc-sc\", \"bb-sc\", \"sc-bb\"]  \n",
    ")\n",
    "print(f\"Number of features after NOT filtering by main or side chain: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# Features with average interaction scores less than 0.5 will be removed. \n",
    "supervised_dataset.filter_by_avg_strength(\n",
    "    average_strength_cut_off=0.5,  \n",
    ")\n",
    "print(f\"Number of features after filtering by average interaction scores: {len(supervised_dataset.df_filtered.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the class attributes of our SupervisedFeatureData() instance (we called it: supervised_dataset) using the special \"\\_\\_dict__\" method we can see two dataframes we could use in the machine learning to follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_df', 'classifications_file', 'header_present', 'df_feat_class', 'df_filtered'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are: \n",
    "- 'df_feat_class' - The unfiltered dataframe, 3057 features\n",
    "- 'df_filtered' - The filtered dataframe. Less than 3057 features. \n",
    "\n",
    "In the following section we will use the filtered dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Perform the Machine Learning with the model_building.py module. \n",
    "\n",
    "Now we will setup and run the supervised machine learning (ML) on the retro aldolase enzyme. Here we will apply to ML to distinguish between catalytically active and inactive conformations of the enzyme towards catalysis of XXXX. \n",
    "\n",
    "Describe the ML in more detail TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NotCatComp    5571\n",
       "CatComp       3840\n",
       "Neither        589\n",
       "Name: Classes, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_dataset.df_filtered[\"Classes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Below is a summary of the machine learning you have planned.\n",
      "You will use 5-fold cross validation and perform 3 repeats.\n",
      "You will use up to 717 features to build each model, with 85.0% of your data used for training the model, which is 7999 observations. \n",
      "15.0% of your data will be used for evaluating the best models produced by the 5-fold cross validation, which is 1412 observations.\n",
      "You have chosen to build 2 different machine learning models, each with the following hyperparameters: \n",
      " \n",
      "A CatBoost model, with grid search parameters: \n",
      "{'model': <catboost.core.CatBoostClassifier object at 0x0000011F7C52A340>, 'params': {'iterations': [50]}} \n",
      "\n",
      "A Random_Forest model, with grid search parameters: \n",
      "{'model': RandomForestClassifier(), 'params': {'n_estimators': [1]}} \n",
      "\n",
      "If you're happy with the above, lets get model building!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model.\n",
    "ml_model = model_building.SupervisedModel(\n",
    "    dataset=supervised_dataset.df_filtered,\n",
    "    evaluation_split_ratio=0.15,\n",
    "    classes_to_use=[\"CatComp\", \"NotCatComp\"],\n",
    "    models_to_use=[\"CatBoost\", \"Random_Forest\"],\n",
    "    scaling_method=\"min_max\",\n",
    "    out_dir=\"outputs/retro_aldol_ml\",\n",
    "    cross_validation_splits=5,\n",
    "    cross_validation_repeats=3,\n",
    "    search_approach=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4901096\ttotal: 238ms\tremaining: 11.7s\n",
      "1:\tlearn: 0.3965163\ttotal: 338ms\tremaining: 8.12s\n",
      "2:\tlearn: 0.3322211\ttotal: 417ms\tremaining: 6.53s\n",
      "3:\tlearn: 0.3036592\ttotal: 505ms\tremaining: 5.8s\n",
      "4:\tlearn: 0.2642576\ttotal: 588ms\tremaining: 5.3s\n",
      "5:\tlearn: 0.2437502\ttotal: 680ms\tremaining: 4.99s\n",
      "6:\tlearn: 0.2271037\ttotal: 773ms\tremaining: 4.75s\n",
      "7:\tlearn: 0.2145043\ttotal: 867ms\tremaining: 4.55s\n",
      "8:\tlearn: 0.2001881\ttotal: 960ms\tremaining: 4.37s\n",
      "9:\tlearn: 0.1844874\ttotal: 1.05s\tremaining: 4.2s\n",
      "10:\tlearn: 0.1779808\ttotal: 1.16s\tremaining: 4.12s\n",
      "11:\tlearn: 0.1716954\ttotal: 1.27s\tremaining: 4.02s\n",
      "12:\tlearn: 0.1665962\ttotal: 1.38s\tremaining: 3.92s\n",
      "13:\tlearn: 0.1628801\ttotal: 1.47s\tremaining: 3.77s\n",
      "14:\tlearn: 0.1575246\ttotal: 1.56s\tremaining: 3.65s\n",
      "15:\tlearn: 0.1538033\ttotal: 1.65s\tremaining: 3.52s\n",
      "16:\tlearn: 0.1488929\ttotal: 1.76s\tremaining: 3.42s\n",
      "17:\tlearn: 0.1444806\ttotal: 1.85s\tremaining: 3.29s\n",
      "18:\tlearn: 0.1403445\ttotal: 1.94s\tremaining: 3.17s\n",
      "19:\tlearn: 0.1363015\ttotal: 2.06s\tremaining: 3.09s\n",
      "20:\tlearn: 0.1331219\ttotal: 2.16s\tremaining: 2.98s\n",
      "21:\tlearn: 0.1282946\ttotal: 2.25s\tremaining: 2.86s\n",
      "22:\tlearn: 0.1256699\ttotal: 2.34s\tremaining: 2.75s\n",
      "23:\tlearn: 0.1216980\ttotal: 2.43s\tremaining: 2.63s\n",
      "24:\tlearn: 0.1162779\ttotal: 2.52s\tremaining: 2.52s\n",
      "25:\tlearn: 0.1122452\ttotal: 2.6s\tremaining: 2.4s\n",
      "26:\tlearn: 0.1105106\ttotal: 2.68s\tremaining: 2.28s\n",
      "27:\tlearn: 0.1083994\ttotal: 2.77s\tremaining: 2.17s\n",
      "28:\tlearn: 0.1035063\ttotal: 2.85s\tremaining: 2.07s\n",
      "29:\tlearn: 0.1009153\ttotal: 2.95s\tremaining: 1.97s\n",
      "30:\tlearn: 0.0943492\ttotal: 3.05s\tremaining: 1.87s\n",
      "31:\tlearn: 0.0903827\ttotal: 3.15s\tremaining: 1.77s\n",
      "32:\tlearn: 0.0872768\ttotal: 3.23s\tremaining: 1.66s\n",
      "33:\tlearn: 0.0859369\ttotal: 3.32s\tremaining: 1.56s\n",
      "34:\tlearn: 0.0838712\ttotal: 3.4s\tremaining: 1.46s\n",
      "35:\tlearn: 0.0815410\ttotal: 3.48s\tremaining: 1.35s\n",
      "36:\tlearn: 0.0781443\ttotal: 3.57s\tremaining: 1.25s\n",
      "37:\tlearn: 0.0750827\ttotal: 3.67s\tremaining: 1.16s\n",
      "38:\tlearn: 0.0729110\ttotal: 3.76s\tremaining: 1.06s\n",
      "39:\tlearn: 0.0715465\ttotal: 3.88s\tremaining: 969ms\n",
      "40:\tlearn: 0.0699908\ttotal: 3.96s\tremaining: 870ms\n",
      "41:\tlearn: 0.0686838\ttotal: 4.08s\tremaining: 777ms\n",
      "42:\tlearn: 0.0674091\ttotal: 4.17s\tremaining: 680ms\n",
      "43:\tlearn: 0.0662555\ttotal: 4.28s\tremaining: 583ms\n",
      "44:\tlearn: 0.0653028\ttotal: 4.37s\tremaining: 485ms\n",
      "45:\tlearn: 0.0636697\ttotal: 4.46s\tremaining: 388ms\n",
      "46:\tlearn: 0.0612196\ttotal: 4.55s\tremaining: 290ms\n",
      "47:\tlearn: 0.0594595\ttotal: 4.64s\tremaining: 194ms\n",
      "48:\tlearn: 0.0576262\ttotal: 4.75s\tremaining: 97ms\n",
      "49:\tlearn: 0.0562198\ttotal: 4.85s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4848849\ttotal: 92.3ms\tremaining: 4.52s\n",
      "1:\tlearn: 0.3886968\ttotal: 194ms\tremaining: 4.65s\n",
      "2:\tlearn: 0.3395943\ttotal: 282ms\tremaining: 4.42s\n",
      "3:\tlearn: 0.3055707\ttotal: 367ms\tremaining: 4.22s\n",
      "4:\tlearn: 0.2730914\ttotal: 478ms\tremaining: 4.3s\n",
      "5:\tlearn: 0.2474015\ttotal: 566ms\tremaining: 4.15s\n",
      "6:\tlearn: 0.2279482\ttotal: 647ms\tremaining: 3.97s\n",
      "7:\tlearn: 0.2159305\ttotal: 762ms\tremaining: 4s\n",
      "8:\tlearn: 0.2050728\ttotal: 886ms\tremaining: 4.04s\n",
      "9:\tlearn: 0.1939679\ttotal: 996ms\tremaining: 3.98s\n",
      "10:\tlearn: 0.1820501\ttotal: 1.1s\tremaining: 3.89s\n",
      "11:\tlearn: 0.1760063\ttotal: 1.18s\tremaining: 3.75s\n",
      "12:\tlearn: 0.1680463\ttotal: 1.27s\tremaining: 3.61s\n",
      "13:\tlearn: 0.1601943\ttotal: 1.37s\tremaining: 3.53s\n",
      "14:\tlearn: 0.1557454\ttotal: 1.46s\tremaining: 3.41s\n",
      "15:\tlearn: 0.1502012\ttotal: 1.55s\tremaining: 3.3s\n",
      "16:\tlearn: 0.1467182\ttotal: 1.64s\tremaining: 3.19s\n",
      "17:\tlearn: 0.1404689\ttotal: 1.72s\tremaining: 3.06s\n",
      "18:\tlearn: 0.1367790\ttotal: 1.8s\tremaining: 2.93s\n",
      "19:\tlearn: 0.1301791\ttotal: 1.92s\tremaining: 2.88s\n",
      "20:\tlearn: 0.1269473\ttotal: 2.01s\tremaining: 2.78s\n",
      "21:\tlearn: 0.1241222\ttotal: 2.1s\tremaining: 2.68s\n",
      "22:\tlearn: 0.1197560\ttotal: 2.19s\tremaining: 2.58s\n",
      "23:\tlearn: 0.1166372\ttotal: 2.29s\tremaining: 2.48s\n",
      "24:\tlearn: 0.1104775\ttotal: 2.37s\tremaining: 2.37s\n",
      "25:\tlearn: 0.1031203\ttotal: 2.46s\tremaining: 2.27s\n",
      "26:\tlearn: 0.1007374\ttotal: 2.55s\tremaining: 2.17s\n",
      "27:\tlearn: 0.0975267\ttotal: 2.67s\tremaining: 2.1s\n",
      "28:\tlearn: 0.0943100\ttotal: 2.78s\tremaining: 2.02s\n",
      "29:\tlearn: 0.0919620\ttotal: 2.89s\tremaining: 1.93s\n",
      "30:\tlearn: 0.0870250\ttotal: 2.97s\tremaining: 1.82s\n",
      "31:\tlearn: 0.0828503\ttotal: 3.07s\tremaining: 1.73s\n",
      "32:\tlearn: 0.0792859\ttotal: 3.17s\tremaining: 1.63s\n",
      "33:\tlearn: 0.0729214\ttotal: 3.28s\tremaining: 1.54s\n",
      "34:\tlearn: 0.0718703\ttotal: 3.36s\tremaining: 1.44s\n",
      "35:\tlearn: 0.0693359\ttotal: 3.45s\tremaining: 1.34s\n",
      "36:\tlearn: 0.0671420\ttotal: 3.53s\tremaining: 1.24s\n",
      "37:\tlearn: 0.0646905\ttotal: 3.64s\tremaining: 1.15s\n",
      "38:\tlearn: 0.0634413\ttotal: 3.73s\tremaining: 1.05s\n",
      "39:\tlearn: 0.0614449\ttotal: 3.81s\tremaining: 951ms\n",
      "40:\tlearn: 0.0602276\ttotal: 3.9s\tremaining: 856ms\n",
      "41:\tlearn: 0.0586537\ttotal: 3.99s\tremaining: 760ms\n",
      "42:\tlearn: 0.0577728\ttotal: 4.08s\tremaining: 664ms\n",
      "43:\tlearn: 0.0567804\ttotal: 4.17s\tremaining: 568ms\n",
      "44:\tlearn: 0.0556221\ttotal: 4.27s\tremaining: 475ms\n",
      "45:\tlearn: 0.0539103\ttotal: 4.35s\tremaining: 378ms\n",
      "46:\tlearn: 0.0529358\ttotal: 4.44s\tremaining: 283ms\n",
      "47:\tlearn: 0.0518656\ttotal: 4.52s\tremaining: 188ms\n",
      "48:\tlearn: 0.0511167\ttotal: 4.6s\tremaining: 93.9ms\n",
      "49:\tlearn: 0.0503181\ttotal: 4.67s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4922209\ttotal: 91.6ms\tremaining: 4.49s\n",
      "1:\tlearn: 0.4008690\ttotal: 207ms\tremaining: 4.97s\n",
      "2:\tlearn: 0.3451235\ttotal: 290ms\tremaining: 4.54s\n",
      "3:\tlearn: 0.2942468\ttotal: 410ms\tremaining: 4.71s\n",
      "4:\tlearn: 0.2726316\ttotal: 503ms\tremaining: 4.53s\n",
      "5:\tlearn: 0.2430545\ttotal: 599ms\tremaining: 4.39s\n",
      "6:\tlearn: 0.2245373\ttotal: 700ms\tremaining: 4.3s\n",
      "7:\tlearn: 0.2147545\ttotal: 794ms\tremaining: 4.17s\n",
      "8:\tlearn: 0.2065087\ttotal: 895ms\tremaining: 4.08s\n",
      "9:\tlearn: 0.1956308\ttotal: 1.01s\tremaining: 4.04s\n",
      "10:\tlearn: 0.1824312\ttotal: 1.12s\tremaining: 3.96s\n",
      "11:\tlearn: 0.1701989\ttotal: 1.22s\tremaining: 3.86s\n",
      "12:\tlearn: 0.1635165\ttotal: 1.31s\tremaining: 3.73s\n",
      "13:\tlearn: 0.1585611\ttotal: 1.42s\tremaining: 3.65s\n",
      "14:\tlearn: 0.1531596\ttotal: 1.52s\tremaining: 3.54s\n",
      "15:\tlearn: 0.1488982\ttotal: 1.62s\tremaining: 3.44s\n",
      "16:\tlearn: 0.1444728\ttotal: 1.71s\tremaining: 3.32s\n",
      "17:\tlearn: 0.1345341\ttotal: 1.8s\tremaining: 3.2s\n",
      "18:\tlearn: 0.1300748\ttotal: 1.89s\tremaining: 3.08s\n",
      "19:\tlearn: 0.1250320\ttotal: 1.99s\tremaining: 2.98s\n",
      "20:\tlearn: 0.1201455\ttotal: 2.09s\tremaining: 2.89s\n",
      "21:\tlearn: 0.1157218\ttotal: 2.21s\tremaining: 2.81s\n",
      "22:\tlearn: 0.1134445\ttotal: 2.3s\tremaining: 2.7s\n",
      "23:\tlearn: 0.1115461\ttotal: 2.4s\tremaining: 2.6s\n",
      "24:\tlearn: 0.1086805\ttotal: 2.5s\tremaining: 2.5s\n",
      "25:\tlearn: 0.1047286\ttotal: 2.58s\tremaining: 2.38s\n",
      "26:\tlearn: 0.1018345\ttotal: 2.69s\tremaining: 2.29s\n",
      "27:\tlearn: 0.0999831\ttotal: 2.78s\tremaining: 2.19s\n",
      "28:\tlearn: 0.0936412\ttotal: 2.88s\tremaining: 2.09s\n",
      "29:\tlearn: 0.0884799\ttotal: 2.99s\tremaining: 1.99s\n",
      "30:\tlearn: 0.0867401\ttotal: 3.09s\tremaining: 1.89s\n",
      "31:\tlearn: 0.0840159\ttotal: 3.21s\tremaining: 1.8s\n",
      "32:\tlearn: 0.0825613\ttotal: 3.3s\tremaining: 1.7s\n",
      "33:\tlearn: 0.0812127\ttotal: 3.41s\tremaining: 1.6s\n",
      "34:\tlearn: 0.0789950\ttotal: 3.49s\tremaining: 1.5s\n",
      "35:\tlearn: 0.0766851\ttotal: 3.6s\tremaining: 1.4s\n",
      "36:\tlearn: 0.0747318\ttotal: 3.7s\tremaining: 1.3s\n",
      "37:\tlearn: 0.0738578\ttotal: 3.81s\tremaining: 1.2s\n",
      "38:\tlearn: 0.0701819\ttotal: 3.91s\tremaining: 1.1s\n",
      "39:\tlearn: 0.0693794\ttotal: 3.99s\tremaining: 997ms\n",
      "40:\tlearn: 0.0663558\ttotal: 4.07s\tremaining: 893ms\n",
      "41:\tlearn: 0.0652731\ttotal: 4.16s\tremaining: 793ms\n",
      "42:\tlearn: 0.0639787\ttotal: 4.29s\tremaining: 698ms\n",
      "43:\tlearn: 0.0630563\ttotal: 4.43s\tremaining: 605ms\n",
      "44:\tlearn: 0.0616636\ttotal: 4.56s\tremaining: 507ms\n",
      "45:\tlearn: 0.0583716\ttotal: 4.66s\tremaining: 405ms\n",
      "46:\tlearn: 0.0561527\ttotal: 4.74s\tremaining: 302ms\n",
      "47:\tlearn: 0.0552363\ttotal: 4.85s\tremaining: 202ms\n",
      "48:\tlearn: 0.0524763\ttotal: 4.95s\tremaining: 101ms\n",
      "49:\tlearn: 0.0515365\ttotal: 5.06s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4831463\ttotal: 93.8ms\tremaining: 4.6s\n",
      "1:\tlearn: 0.3843449\ttotal: 210ms\tremaining: 5.04s\n",
      "2:\tlearn: 0.3268645\ttotal: 289ms\tremaining: 4.53s\n",
      "3:\tlearn: 0.2869494\ttotal: 388ms\tremaining: 4.46s\n",
      "4:\tlearn: 0.2619730\ttotal: 498ms\tremaining: 4.48s\n",
      "5:\tlearn: 0.2403179\ttotal: 613ms\tremaining: 4.49s\n",
      "6:\tlearn: 0.2275605\ttotal: 693ms\tremaining: 4.25s\n",
      "7:\tlearn: 0.2109916\ttotal: 786ms\tremaining: 4.13s\n",
      "8:\tlearn: 0.1966214\ttotal: 878ms\tremaining: 4s\n",
      "9:\tlearn: 0.1871183\ttotal: 978ms\tremaining: 3.91s\n",
      "10:\tlearn: 0.1813478\ttotal: 1.09s\tremaining: 3.86s\n",
      "11:\tlearn: 0.1756481\ttotal: 1.17s\tremaining: 3.71s\n",
      "12:\tlearn: 0.1702635\ttotal: 1.27s\tremaining: 3.6s\n",
      "13:\tlearn: 0.1620779\ttotal: 1.36s\tremaining: 3.49s\n",
      "14:\tlearn: 0.1579165\ttotal: 1.47s\tremaining: 3.42s\n",
      "15:\tlearn: 0.1516395\ttotal: 1.58s\tremaining: 3.35s\n",
      "16:\tlearn: 0.1467904\ttotal: 1.68s\tremaining: 3.26s\n",
      "17:\tlearn: 0.1439639\ttotal: 1.78s\tremaining: 3.17s\n",
      "18:\tlearn: 0.1374152\ttotal: 1.88s\tremaining: 3.07s\n",
      "19:\tlearn: 0.1323658\ttotal: 1.97s\tremaining: 2.95s\n",
      "20:\tlearn: 0.1255957\ttotal: 2.07s\tremaining: 2.86s\n",
      "21:\tlearn: 0.1210657\ttotal: 2.15s\tremaining: 2.74s\n",
      "22:\tlearn: 0.1189254\ttotal: 2.25s\tremaining: 2.64s\n",
      "23:\tlearn: 0.1165990\ttotal: 2.35s\tremaining: 2.54s\n",
      "24:\tlearn: 0.1107074\ttotal: 2.44s\tremaining: 2.44s\n",
      "25:\tlearn: 0.1065416\ttotal: 2.53s\tremaining: 2.33s\n",
      "26:\tlearn: 0.1028492\ttotal: 2.64s\tremaining: 2.25s\n",
      "27:\tlearn: 0.0999015\ttotal: 2.75s\tremaining: 2.16s\n",
      "28:\tlearn: 0.0934247\ttotal: 2.88s\tremaining: 2.08s\n",
      "29:\tlearn: 0.0912665\ttotal: 2.98s\tremaining: 1.99s\n",
      "30:\tlearn: 0.0880660\ttotal: 3.07s\tremaining: 1.88s\n",
      "31:\tlearn: 0.0829116\ttotal: 3.19s\tremaining: 1.79s\n",
      "32:\tlearn: 0.0813616\ttotal: 3.29s\tremaining: 1.7s\n",
      "33:\tlearn: 0.0796761\ttotal: 3.38s\tremaining: 1.59s\n",
      "34:\tlearn: 0.0765541\ttotal: 3.49s\tremaining: 1.49s\n",
      "35:\tlearn: 0.0752212\ttotal: 3.59s\tremaining: 1.39s\n",
      "36:\tlearn: 0.0741390\ttotal: 3.67s\tremaining: 1.29s\n",
      "37:\tlearn: 0.0730258\ttotal: 3.77s\tremaining: 1.19s\n",
      "38:\tlearn: 0.0674494\ttotal: 3.87s\tremaining: 1.09s\n",
      "39:\tlearn: 0.0637895\ttotal: 3.95s\tremaining: 988ms\n",
      "40:\tlearn: 0.0604043\ttotal: 4.05s\tremaining: 890ms\n",
      "41:\tlearn: 0.0592207\ttotal: 4.18s\tremaining: 797ms\n",
      "42:\tlearn: 0.0580443\ttotal: 4.3s\tremaining: 700ms\n",
      "43:\tlearn: 0.0557602\ttotal: 4.38s\tremaining: 598ms\n",
      "44:\tlearn: 0.0541457\ttotal: 4.47s\tremaining: 497ms\n",
      "45:\tlearn: 0.0532591\ttotal: 4.57s\tremaining: 397ms\n",
      "46:\tlearn: 0.0523106\ttotal: 4.66s\tremaining: 298ms\n",
      "47:\tlearn: 0.0516355\ttotal: 4.78s\tremaining: 199ms\n",
      "48:\tlearn: 0.0496535\ttotal: 4.87s\tremaining: 99.5ms\n",
      "49:\tlearn: 0.0487748\ttotal: 4.95s\tremaining: 0us\n",
      "Learning rate set to 0.354991\n",
      "0:\tlearn: 0.4766784\ttotal: 109ms\tremaining: 5.36s\n",
      "1:\tlearn: 0.3804951\ttotal: 205ms\tremaining: 4.91s\n",
      "2:\tlearn: 0.3371043\ttotal: 311ms\tremaining: 4.87s\n",
      "3:\tlearn: 0.2973735\ttotal: 398ms\tremaining: 4.57s\n",
      "4:\tlearn: 0.2728452\ttotal: 485ms\tremaining: 4.37s\n",
      "5:\tlearn: 0.2545152\ttotal: 575ms\tremaining: 4.22s\n",
      "6:\tlearn: 0.2279920\ttotal: 664ms\tremaining: 4.08s\n",
      "7:\tlearn: 0.2095048\ttotal: 767ms\tremaining: 4.03s\n",
      "8:\tlearn: 0.1987334\ttotal: 874ms\tremaining: 3.98s\n",
      "9:\tlearn: 0.1852661\ttotal: 1000ms\tremaining: 4s\n",
      "10:\tlearn: 0.1748384\ttotal: 1.11s\tremaining: 3.92s\n",
      "11:\tlearn: 0.1659516\ttotal: 1.26s\tremaining: 3.99s\n",
      "12:\tlearn: 0.1604727\ttotal: 1.35s\tremaining: 3.85s\n",
      "13:\tlearn: 0.1551532\ttotal: 1.43s\tremaining: 3.69s\n",
      "14:\tlearn: 0.1492694\ttotal: 1.52s\tremaining: 3.54s\n",
      "15:\tlearn: 0.1455505\ttotal: 1.6s\tremaining: 3.4s\n",
      "16:\tlearn: 0.1400747\ttotal: 1.68s\tremaining: 3.25s\n",
      "17:\tlearn: 0.1322527\ttotal: 1.78s\tremaining: 3.17s\n",
      "18:\tlearn: 0.1264987\ttotal: 1.89s\tremaining: 3.09s\n",
      "19:\tlearn: 0.1218480\ttotal: 1.97s\tremaining: 2.96s\n",
      "20:\tlearn: 0.1174275\ttotal: 2.08s\tremaining: 2.88s\n",
      "21:\tlearn: 0.1149428\ttotal: 2.22s\tremaining: 2.83s\n",
      "22:\tlearn: 0.1107357\ttotal: 2.34s\tremaining: 2.75s\n",
      "23:\tlearn: 0.1075913\ttotal: 2.43s\tremaining: 2.63s\n",
      "24:\tlearn: 0.1050181\ttotal: 2.53s\tremaining: 2.53s\n",
      "25:\tlearn: 0.1034165\ttotal: 2.64s\tremaining: 2.43s\n",
      "26:\tlearn: 0.0995114\ttotal: 2.74s\tremaining: 2.33s\n",
      "27:\tlearn: 0.0943841\ttotal: 2.83s\tremaining: 2.23s\n",
      "28:\tlearn: 0.0902094\ttotal: 2.92s\tremaining: 2.12s\n",
      "29:\tlearn: 0.0885133\ttotal: 3.03s\tremaining: 2.02s\n",
      "30:\tlearn: 0.0867231\ttotal: 3.11s\tremaining: 1.91s\n",
      "31:\tlearn: 0.0831057\ttotal: 3.22s\tremaining: 1.81s\n",
      "32:\tlearn: 0.0771455\ttotal: 3.35s\tremaining: 1.72s\n",
      "33:\tlearn: 0.0728209\ttotal: 3.45s\tremaining: 1.63s\n",
      "34:\tlearn: 0.0703019\ttotal: 3.58s\tremaining: 1.53s\n",
      "35:\tlearn: 0.0691336\ttotal: 3.75s\tremaining: 1.46s\n",
      "36:\tlearn: 0.0679875\ttotal: 3.84s\tremaining: 1.35s\n",
      "37:\tlearn: 0.0667552\ttotal: 3.97s\tremaining: 1.25s\n",
      "38:\tlearn: 0.0648084\ttotal: 4.09s\tremaining: 1.15s\n",
      "39:\tlearn: 0.0637991\ttotal: 4.2s\tremaining: 1.05s\n",
      "40:\tlearn: 0.0620103\ttotal: 4.29s\tremaining: 942ms\n",
      "41:\tlearn: 0.0608185\ttotal: 4.41s\tremaining: 841ms\n",
      "42:\tlearn: 0.0588251\ttotal: 4.51s\tremaining: 734ms\n",
      "43:\tlearn: 0.0575877\ttotal: 4.62s\tremaining: 630ms\n",
      "44:\tlearn: 0.0557492\ttotal: 4.72s\tremaining: 524ms\n",
      "45:\tlearn: 0.0549805\ttotal: 4.81s\tremaining: 418ms\n",
      "46:\tlearn: 0.0541850\ttotal: 4.92s\tremaining: 314ms\n",
      "47:\tlearn: 0.0530707\ttotal: 5.03s\tremaining: 210ms\n",
      "48:\tlearn: 0.0511911\ttotal: 5.14s\tremaining: 105ms\n",
      "49:\tlearn: 0.0503059\ttotal: 5.23s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4928103\ttotal: 108ms\tremaining: 5.31s\n",
      "1:\tlearn: 0.3892101\ttotal: 196ms\tremaining: 4.71s\n",
      "2:\tlearn: 0.3378463\ttotal: 283ms\tremaining: 4.44s\n",
      "3:\tlearn: 0.2983253\ttotal: 386ms\tremaining: 4.44s\n",
      "4:\tlearn: 0.2634282\ttotal: 523ms\tremaining: 4.71s\n",
      "5:\tlearn: 0.2374003\ttotal: 668ms\tremaining: 4.9s\n",
      "6:\tlearn: 0.2234082\ttotal: 753ms\tremaining: 4.62s\n",
      "7:\tlearn: 0.2103493\ttotal: 842ms\tremaining: 4.42s\n",
      "8:\tlearn: 0.1965064\ttotal: 938ms\tremaining: 4.27s\n",
      "9:\tlearn: 0.1804973\ttotal: 1.02s\tremaining: 4.1s\n",
      "10:\tlearn: 0.1724202\ttotal: 1.17s\tremaining: 4.13s\n",
      "11:\tlearn: 0.1663031\ttotal: 1.26s\tremaining: 3.99s\n",
      "12:\tlearn: 0.1604450\ttotal: 1.35s\tremaining: 3.85s\n",
      "13:\tlearn: 0.1547850\ttotal: 1.48s\tremaining: 3.8s\n",
      "14:\tlearn: 0.1515793\ttotal: 1.56s\tremaining: 3.65s\n",
      "15:\tlearn: 0.1463042\ttotal: 1.66s\tremaining: 3.53s\n",
      "16:\tlearn: 0.1412957\ttotal: 1.79s\tremaining: 3.47s\n",
      "17:\tlearn: 0.1367780\ttotal: 1.89s\tremaining: 3.36s\n",
      "18:\tlearn: 0.1312410\ttotal: 2.03s\tremaining: 3.31s\n",
      "19:\tlearn: 0.1277290\ttotal: 2.13s\tremaining: 3.19s\n",
      "20:\tlearn: 0.1254744\ttotal: 2.25s\tremaining: 3.11s\n",
      "21:\tlearn: 0.1211837\ttotal: 2.37s\tremaining: 3.02s\n",
      "22:\tlearn: 0.1189433\ttotal: 2.48s\tremaining: 2.92s\n",
      "23:\tlearn: 0.1153780\ttotal: 2.58s\tremaining: 2.8s\n",
      "24:\tlearn: 0.1115887\ttotal: 2.68s\tremaining: 2.68s\n",
      "25:\tlearn: 0.1091355\ttotal: 2.78s\tremaining: 2.56s\n",
      "26:\tlearn: 0.1015098\ttotal: 2.9s\tremaining: 2.47s\n",
      "27:\tlearn: 0.0992211\ttotal: 2.99s\tremaining: 2.35s\n",
      "28:\tlearn: 0.0960913\ttotal: 3.11s\tremaining: 2.25s\n",
      "29:\tlearn: 0.0918549\ttotal: 3.22s\tremaining: 2.14s\n",
      "30:\tlearn: 0.0897372\ttotal: 3.31s\tremaining: 2.03s\n",
      "31:\tlearn: 0.0876486\ttotal: 3.4s\tremaining: 1.91s\n",
      "32:\tlearn: 0.0856200\ttotal: 3.48s\tremaining: 1.79s\n",
      "33:\tlearn: 0.0829333\ttotal: 3.61s\tremaining: 1.7s\n",
      "34:\tlearn: 0.0784184\ttotal: 3.71s\tremaining: 1.59s\n",
      "35:\tlearn: 0.0765039\ttotal: 3.79s\tremaining: 1.47s\n",
      "36:\tlearn: 0.0752743\ttotal: 3.89s\tremaining: 1.37s\n",
      "37:\tlearn: 0.0745942\ttotal: 3.99s\tremaining: 1.26s\n",
      "38:\tlearn: 0.0729587\ttotal: 4.09s\tremaining: 1.15s\n",
      "39:\tlearn: 0.0708394\ttotal: 4.18s\tremaining: 1.04s\n",
      "40:\tlearn: 0.0689858\ttotal: 4.27s\tremaining: 937ms\n",
      "41:\tlearn: 0.0674976\ttotal: 4.36s\tremaining: 831ms\n",
      "42:\tlearn: 0.0649392\ttotal: 4.47s\tremaining: 728ms\n",
      "43:\tlearn: 0.0630632\ttotal: 4.54s\tremaining: 620ms\n",
      "44:\tlearn: 0.0587719\ttotal: 4.65s\tremaining: 516ms\n",
      "45:\tlearn: 0.0579861\ttotal: 4.74s\tremaining: 412ms\n",
      "46:\tlearn: 0.0566846\ttotal: 4.87s\tremaining: 311ms\n",
      "47:\tlearn: 0.0555033\ttotal: 4.96s\tremaining: 207ms\n",
      "48:\tlearn: 0.0547315\ttotal: 5.07s\tremaining: 103ms\n",
      "49:\tlearn: 0.0535958\ttotal: 5.17s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.5092544\ttotal: 98.1ms\tremaining: 4.81s\n",
      "1:\tlearn: 0.3981433\ttotal: 205ms\tremaining: 4.91s\n",
      "2:\tlearn: 0.3465896\ttotal: 282ms\tremaining: 4.41s\n",
      "3:\tlearn: 0.2888341\ttotal: 383ms\tremaining: 4.4s\n",
      "4:\tlearn: 0.2558906\ttotal: 470ms\tremaining: 4.23s\n",
      "5:\tlearn: 0.2361519\ttotal: 561ms\tremaining: 4.11s\n",
      "6:\tlearn: 0.2210931\ttotal: 676ms\tremaining: 4.15s\n",
      "7:\tlearn: 0.2081192\ttotal: 770ms\tremaining: 4.04s\n",
      "8:\tlearn: 0.1930198\ttotal: 896ms\tremaining: 4.08s\n",
      "9:\tlearn: 0.1807858\ttotal: 1.04s\tremaining: 4.16s\n",
      "10:\tlearn: 0.1740851\ttotal: 1.15s\tremaining: 4.07s\n",
      "11:\tlearn: 0.1653996\ttotal: 1.27s\tremaining: 4.03s\n",
      "12:\tlearn: 0.1602559\ttotal: 1.37s\tremaining: 3.89s\n",
      "13:\tlearn: 0.1559085\ttotal: 1.45s\tremaining: 3.74s\n",
      "14:\tlearn: 0.1507753\ttotal: 1.54s\tremaining: 3.6s\n",
      "15:\tlearn: 0.1451095\ttotal: 1.65s\tremaining: 3.5s\n",
      "16:\tlearn: 0.1396090\ttotal: 1.77s\tremaining: 3.43s\n",
      "17:\tlearn: 0.1358328\ttotal: 1.87s\tremaining: 3.33s\n",
      "18:\tlearn: 0.1291387\ttotal: 1.96s\tremaining: 3.19s\n",
      "19:\tlearn: 0.1254706\ttotal: 2.07s\tremaining: 3.11s\n",
      "20:\tlearn: 0.1220028\ttotal: 2.2s\tremaining: 3.04s\n",
      "21:\tlearn: 0.1179798\ttotal: 2.33s\tremaining: 2.96s\n",
      "22:\tlearn: 0.1153248\ttotal: 2.4s\tremaining: 2.82s\n",
      "23:\tlearn: 0.1129896\ttotal: 2.5s\tremaining: 2.71s\n",
      "24:\tlearn: 0.1060297\ttotal: 2.61s\tremaining: 2.61s\n",
      "25:\tlearn: 0.1028808\ttotal: 2.7s\tremaining: 2.49s\n",
      "26:\tlearn: 0.1003322\ttotal: 2.79s\tremaining: 2.37s\n",
      "27:\tlearn: 0.0990329\ttotal: 2.91s\tremaining: 2.29s\n",
      "28:\tlearn: 0.0970174\ttotal: 3s\tremaining: 2.17s\n",
      "29:\tlearn: 0.0910192\ttotal: 3.09s\tremaining: 2.06s\n",
      "30:\tlearn: 0.0893424\ttotal: 3.19s\tremaining: 1.96s\n",
      "31:\tlearn: 0.0875665\ttotal: 3.3s\tremaining: 1.85s\n",
      "32:\tlearn: 0.0822982\ttotal: 3.38s\tremaining: 1.74s\n",
      "33:\tlearn: 0.0785789\ttotal: 3.54s\tremaining: 1.66s\n",
      "34:\tlearn: 0.0751462\ttotal: 3.67s\tremaining: 1.57s\n",
      "35:\tlearn: 0.0717531\ttotal: 3.79s\tremaining: 1.47s\n",
      "36:\tlearn: 0.0705248\ttotal: 3.9s\tremaining: 1.37s\n",
      "37:\tlearn: 0.0672329\ttotal: 3.99s\tremaining: 1.26s\n",
      "38:\tlearn: 0.0656729\ttotal: 4.1s\tremaining: 1.16s\n",
      "39:\tlearn: 0.0642146\ttotal: 4.19s\tremaining: 1.05s\n",
      "40:\tlearn: 0.0628747\ttotal: 4.31s\tremaining: 946ms\n",
      "41:\tlearn: 0.0620549\ttotal: 4.41s\tremaining: 841ms\n",
      "42:\tlearn: 0.0602974\ttotal: 4.51s\tremaining: 734ms\n",
      "43:\tlearn: 0.0591401\ttotal: 4.6s\tremaining: 627ms\n",
      "44:\tlearn: 0.0583176\ttotal: 4.7s\tremaining: 522ms\n",
      "45:\tlearn: 0.0570182\ttotal: 4.82s\tremaining: 419ms\n",
      "46:\tlearn: 0.0557743\ttotal: 4.92s\tremaining: 314ms\n",
      "47:\tlearn: 0.0535927\ttotal: 5.03s\tremaining: 210ms\n",
      "48:\tlearn: 0.0522093\ttotal: 5.16s\tremaining: 105ms\n",
      "49:\tlearn: 0.0517666\ttotal: 5.26s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4812755\ttotal: 119ms\tremaining: 5.81s\n",
      "1:\tlearn: 0.3857621\ttotal: 241ms\tremaining: 5.78s\n",
      "2:\tlearn: 0.3361102\ttotal: 365ms\tremaining: 5.72s\n",
      "3:\tlearn: 0.2953658\ttotal: 454ms\tremaining: 5.22s\n",
      "4:\tlearn: 0.2708096\ttotal: 572ms\tremaining: 5.15s\n",
      "5:\tlearn: 0.2438046\ttotal: 686ms\tremaining: 5.03s\n",
      "6:\tlearn: 0.2227121\ttotal: 788ms\tremaining: 4.84s\n",
      "7:\tlearn: 0.2133037\ttotal: 909ms\tremaining: 4.77s\n",
      "8:\tlearn: 0.2006828\ttotal: 1.05s\tremaining: 4.77s\n",
      "9:\tlearn: 0.1867895\ttotal: 1.15s\tremaining: 4.59s\n",
      "10:\tlearn: 0.1781273\ttotal: 1.26s\tremaining: 4.47s\n",
      "11:\tlearn: 0.1670095\ttotal: 1.39s\tremaining: 4.39s\n",
      "12:\tlearn: 0.1620016\ttotal: 1.54s\tremaining: 4.38s\n",
      "13:\tlearn: 0.1557142\ttotal: 1.65s\tremaining: 4.23s\n",
      "14:\tlearn: 0.1514626\ttotal: 1.74s\tremaining: 4.05s\n",
      "15:\tlearn: 0.1440248\ttotal: 1.86s\tremaining: 3.95s\n",
      "16:\tlearn: 0.1402076\ttotal: 1.97s\tremaining: 3.83s\n",
      "17:\tlearn: 0.1344060\ttotal: 2.1s\tremaining: 3.73s\n",
      "18:\tlearn: 0.1312838\ttotal: 2.21s\tremaining: 3.6s\n",
      "19:\tlearn: 0.1284048\ttotal: 2.31s\tremaining: 3.47s\n",
      "20:\tlearn: 0.1209613\ttotal: 2.4s\tremaining: 3.31s\n",
      "21:\tlearn: 0.1165668\ttotal: 2.49s\tremaining: 3.17s\n",
      "22:\tlearn: 0.1136966\ttotal: 2.6s\tremaining: 3.05s\n",
      "23:\tlearn: 0.1105297\ttotal: 2.67s\tremaining: 2.9s\n",
      "24:\tlearn: 0.1081426\ttotal: 2.9s\tremaining: 2.9s\n",
      "25:\tlearn: 0.1051240\ttotal: 3.04s\tremaining: 2.81s\n",
      "26:\tlearn: 0.0981939\ttotal: 3.16s\tremaining: 2.69s\n",
      "27:\tlearn: 0.0945447\ttotal: 3.24s\tremaining: 2.54s\n",
      "28:\tlearn: 0.0918632\ttotal: 3.33s\tremaining: 2.41s\n",
      "29:\tlearn: 0.0890179\ttotal: 3.42s\tremaining: 2.28s\n",
      "30:\tlearn: 0.0860047\ttotal: 3.54s\tremaining: 2.17s\n",
      "31:\tlearn: 0.0834014\ttotal: 3.61s\tremaining: 2.03s\n",
      "32:\tlearn: 0.0819565\ttotal: 3.69s\tremaining: 1.9s\n",
      "33:\tlearn: 0.0782771\ttotal: 3.79s\tremaining: 1.78s\n",
      "34:\tlearn: 0.0762054\ttotal: 3.87s\tremaining: 1.66s\n",
      "35:\tlearn: 0.0736347\ttotal: 3.96s\tremaining: 1.54s\n",
      "36:\tlearn: 0.0701762\ttotal: 4.06s\tremaining: 1.43s\n",
      "37:\tlearn: 0.0683121\ttotal: 4.16s\tremaining: 1.31s\n",
      "38:\tlearn: 0.0661227\ttotal: 4.29s\tremaining: 1.21s\n",
      "39:\tlearn: 0.0634697\ttotal: 4.42s\tremaining: 1.1s\n",
      "40:\tlearn: 0.0606875\ttotal: 4.5s\tremaining: 989ms\n",
      "41:\tlearn: 0.0595289\ttotal: 4.6s\tremaining: 876ms\n",
      "42:\tlearn: 0.0565400\ttotal: 4.7s\tremaining: 765ms\n",
      "43:\tlearn: 0.0543562\ttotal: 4.79s\tremaining: 653ms\n",
      "44:\tlearn: 0.0521888\ttotal: 4.88s\tremaining: 542ms\n",
      "45:\tlearn: 0.0510876\ttotal: 4.98s\tremaining: 433ms\n",
      "46:\tlearn: 0.0503621\ttotal: 5.08s\tremaining: 324ms\n",
      "47:\tlearn: 0.0494548\ttotal: 5.19s\tremaining: 216ms\n",
      "48:\tlearn: 0.0485362\ttotal: 5.27s\tremaining: 108ms\n",
      "49:\tlearn: 0.0476380\ttotal: 5.36s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4821265\ttotal: 129ms\tremaining: 6.3s\n",
      "1:\tlearn: 0.3762893\ttotal: 224ms\tremaining: 5.39s\n",
      "2:\tlearn: 0.3305189\ttotal: 324ms\tremaining: 5.08s\n",
      "3:\tlearn: 0.2945918\ttotal: 456ms\tremaining: 5.24s\n",
      "4:\tlearn: 0.2628868\ttotal: 559ms\tremaining: 5.03s\n",
      "5:\tlearn: 0.2434484\ttotal: 711ms\tremaining: 5.21s\n",
      "6:\tlearn: 0.2309492\ttotal: 828ms\tremaining: 5.08s\n",
      "7:\tlearn: 0.2099459\ttotal: 926ms\tremaining: 4.86s\n",
      "8:\tlearn: 0.1970125\ttotal: 1.03s\tremaining: 4.72s\n",
      "9:\tlearn: 0.1834625\ttotal: 1.13s\tremaining: 4.52s\n",
      "10:\tlearn: 0.1741333\ttotal: 1.24s\tremaining: 4.39s\n",
      "11:\tlearn: 0.1691905\ttotal: 1.33s\tremaining: 4.21s\n",
      "12:\tlearn: 0.1581166\ttotal: 1.45s\tremaining: 4.13s\n",
      "13:\tlearn: 0.1532725\ttotal: 1.55s\tremaining: 3.99s\n",
      "14:\tlearn: 0.1505252\ttotal: 1.68s\tremaining: 3.91s\n",
      "15:\tlearn: 0.1453838\ttotal: 1.8s\tremaining: 3.82s\n",
      "16:\tlearn: 0.1398557\ttotal: 1.93s\tremaining: 3.74s\n",
      "17:\tlearn: 0.1354776\ttotal: 2.08s\tremaining: 3.71s\n",
      "18:\tlearn: 0.1321309\ttotal: 2.18s\tremaining: 3.56s\n",
      "19:\tlearn: 0.1275338\ttotal: 2.3s\tremaining: 3.45s\n",
      "20:\tlearn: 0.1216975\ttotal: 2.39s\tremaining: 3.3s\n",
      "21:\tlearn: 0.1178280\ttotal: 2.49s\tremaining: 3.17s\n",
      "22:\tlearn: 0.1148714\ttotal: 2.65s\tremaining: 3.11s\n",
      "23:\tlearn: 0.1120698\ttotal: 2.75s\tremaining: 2.97s\n",
      "24:\tlearn: 0.1095346\ttotal: 2.83s\tremaining: 2.83s\n",
      "25:\tlearn: 0.1055798\ttotal: 2.96s\tremaining: 2.73s\n",
      "26:\tlearn: 0.1022741\ttotal: 3.06s\tremaining: 2.6s\n",
      "27:\tlearn: 0.1001520\ttotal: 3.15s\tremaining: 2.47s\n",
      "28:\tlearn: 0.0936751\ttotal: 3.25s\tremaining: 2.35s\n",
      "29:\tlearn: 0.0926179\ttotal: 3.33s\tremaining: 2.22s\n",
      "30:\tlearn: 0.0883036\ttotal: 3.43s\tremaining: 2.1s\n",
      "31:\tlearn: 0.0853170\ttotal: 3.51s\tremaining: 1.97s\n",
      "32:\tlearn: 0.0840537\ttotal: 3.63s\tremaining: 1.87s\n",
      "33:\tlearn: 0.0821339\ttotal: 3.73s\tremaining: 1.76s\n",
      "34:\tlearn: 0.0794882\ttotal: 3.83s\tremaining: 1.64s\n",
      "35:\tlearn: 0.0779217\ttotal: 3.95s\tremaining: 1.53s\n",
      "36:\tlearn: 0.0737566\ttotal: 4.04s\tremaining: 1.42s\n",
      "37:\tlearn: 0.0722887\ttotal: 4.14s\tremaining: 1.31s\n",
      "38:\tlearn: 0.0702807\ttotal: 4.26s\tremaining: 1.2s\n",
      "39:\tlearn: 0.0680599\ttotal: 4.35s\tremaining: 1.09s\n",
      "40:\tlearn: 0.0666265\ttotal: 4.48s\tremaining: 984ms\n",
      "41:\tlearn: 0.0655781\ttotal: 4.58s\tremaining: 872ms\n",
      "42:\tlearn: 0.0647363\ttotal: 4.67s\tremaining: 759ms\n",
      "43:\tlearn: 0.0612358\ttotal: 4.82s\tremaining: 658ms\n",
      "44:\tlearn: 0.0607132\ttotal: 4.91s\tremaining: 546ms\n",
      "45:\tlearn: 0.0598100\ttotal: 5.04s\tremaining: 438ms\n",
      "46:\tlearn: 0.0567538\ttotal: 5.15s\tremaining: 329ms\n",
      "47:\tlearn: 0.0551716\ttotal: 5.25s\tremaining: 219ms\n",
      "48:\tlearn: 0.0538395\ttotal: 5.36s\tremaining: 109ms\n",
      "49:\tlearn: 0.0531067\ttotal: 5.45s\tremaining: 0us\n",
      "Learning rate set to 0.354991\n",
      "0:\tlearn: 0.4911790\ttotal: 123ms\tremaining: 6.02s\n",
      "1:\tlearn: 0.3977326\ttotal: 242ms\tremaining: 5.8s\n",
      "2:\tlearn: 0.3488842\ttotal: 369ms\tremaining: 5.79s\n",
      "3:\tlearn: 0.3072614\ttotal: 454ms\tremaining: 5.22s\n",
      "4:\tlearn: 0.2741204\ttotal: 539ms\tremaining: 4.85s\n",
      "5:\tlearn: 0.2478301\ttotal: 642ms\tremaining: 4.71s\n",
      "6:\tlearn: 0.2287850\ttotal: 756ms\tremaining: 4.64s\n",
      "7:\tlearn: 0.2182772\ttotal: 880ms\tremaining: 4.62s\n",
      "8:\tlearn: 0.2057655\ttotal: 976ms\tremaining: 4.45s\n",
      "9:\tlearn: 0.1960914\ttotal: 1.09s\tremaining: 4.36s\n",
      "10:\tlearn: 0.1884254\ttotal: 1.2s\tremaining: 4.25s\n",
      "11:\tlearn: 0.1706158\ttotal: 1.29s\tremaining: 4.08s\n",
      "12:\tlearn: 0.1616278\ttotal: 1.4s\tremaining: 3.97s\n",
      "13:\tlearn: 0.1494045\ttotal: 1.52s\tremaining: 3.91s\n",
      "14:\tlearn: 0.1455614\ttotal: 1.64s\tremaining: 3.84s\n",
      "15:\tlearn: 0.1403643\ttotal: 1.74s\tremaining: 3.71s\n",
      "16:\tlearn: 0.1368435\ttotal: 1.84s\tremaining: 3.57s\n",
      "17:\tlearn: 0.1318187\ttotal: 1.93s\tremaining: 3.43s\n",
      "18:\tlearn: 0.1284478\ttotal: 2.02s\tremaining: 3.3s\n",
      "19:\tlearn: 0.1247663\ttotal: 2.14s\tremaining: 3.21s\n",
      "20:\tlearn: 0.1230552\ttotal: 2.27s\tremaining: 3.14s\n",
      "21:\tlearn: 0.1192901\ttotal: 2.38s\tremaining: 3.03s\n",
      "22:\tlearn: 0.1160451\ttotal: 2.5s\tremaining: 2.94s\n",
      "23:\tlearn: 0.1121067\ttotal: 2.64s\tremaining: 2.86s\n",
      "24:\tlearn: 0.1077724\ttotal: 2.74s\tremaining: 2.74s\n",
      "25:\tlearn: 0.1037916\ttotal: 2.84s\tremaining: 2.62s\n",
      "26:\tlearn: 0.1012455\ttotal: 2.94s\tremaining: 2.51s\n",
      "27:\tlearn: 0.0990439\ttotal: 3.04s\tremaining: 2.39s\n",
      "28:\tlearn: 0.0941934\ttotal: 3.14s\tremaining: 2.27s\n",
      "29:\tlearn: 0.0924484\ttotal: 3.23s\tremaining: 2.15s\n",
      "30:\tlearn: 0.0885157\ttotal: 3.32s\tremaining: 2.03s\n",
      "31:\tlearn: 0.0823732\ttotal: 3.43s\tremaining: 1.93s\n",
      "32:\tlearn: 0.0814136\ttotal: 3.54s\tremaining: 1.82s\n",
      "33:\tlearn: 0.0794608\ttotal: 3.65s\tremaining: 1.72s\n",
      "34:\tlearn: 0.0772861\ttotal: 3.76s\tremaining: 1.61s\n",
      "35:\tlearn: 0.0755043\ttotal: 3.86s\tremaining: 1.5s\n",
      "36:\tlearn: 0.0737884\ttotal: 3.98s\tremaining: 1.4s\n",
      "37:\tlearn: 0.0726866\ttotal: 4.06s\tremaining: 1.28s\n",
      "38:\tlearn: 0.0709218\ttotal: 4.18s\tremaining: 1.18s\n",
      "39:\tlearn: 0.0684632\ttotal: 4.28s\tremaining: 1.07s\n",
      "40:\tlearn: 0.0671091\ttotal: 4.37s\tremaining: 960ms\n",
      "41:\tlearn: 0.0635570\ttotal: 4.49s\tremaining: 855ms\n",
      "42:\tlearn: 0.0626578\ttotal: 4.58s\tremaining: 745ms\n",
      "43:\tlearn: 0.0616872\ttotal: 4.67s\tremaining: 637ms\n",
      "44:\tlearn: 0.0591813\ttotal: 4.75s\tremaining: 528ms\n",
      "45:\tlearn: 0.0581844\ttotal: 4.86s\tremaining: 422ms\n",
      "46:\tlearn: 0.0571204\ttotal: 4.95s\tremaining: 316ms\n",
      "47:\tlearn: 0.0558747\ttotal: 5.03s\tremaining: 209ms\n",
      "48:\tlearn: 0.0550442\ttotal: 5.12s\tremaining: 104ms\n",
      "49:\tlearn: 0.0542672\ttotal: 5.21s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4978704\ttotal: 108ms\tremaining: 5.29s\n",
      "1:\tlearn: 0.3925813\ttotal: 216ms\tremaining: 5.19s\n",
      "2:\tlearn: 0.3389360\ttotal: 317ms\tremaining: 4.97s\n",
      "3:\tlearn: 0.2901726\ttotal: 399ms\tremaining: 4.59s\n",
      "4:\tlearn: 0.2677028\ttotal: 485ms\tremaining: 4.37s\n",
      "5:\tlearn: 0.2464637\ttotal: 587ms\tremaining: 4.3s\n",
      "6:\tlearn: 0.2295867\ttotal: 693ms\tremaining: 4.26s\n",
      "7:\tlearn: 0.2168252\ttotal: 785ms\tremaining: 4.12s\n",
      "8:\tlearn: 0.1994998\ttotal: 896ms\tremaining: 4.08s\n",
      "9:\tlearn: 0.1875616\ttotal: 987ms\tremaining: 3.95s\n",
      "10:\tlearn: 0.1772099\ttotal: 1.11s\tremaining: 3.94s\n",
      "11:\tlearn: 0.1696312\ttotal: 1.2s\tremaining: 3.81s\n",
      "12:\tlearn: 0.1610526\ttotal: 1.29s\tremaining: 3.68s\n",
      "13:\tlearn: 0.1516103\ttotal: 1.37s\tremaining: 3.53s\n",
      "14:\tlearn: 0.1484340\ttotal: 1.46s\tremaining: 3.41s\n",
      "15:\tlearn: 0.1441103\ttotal: 1.56s\tremaining: 3.31s\n",
      "16:\tlearn: 0.1392005\ttotal: 1.67s\tremaining: 3.24s\n",
      "17:\tlearn: 0.1356648\ttotal: 1.79s\tremaining: 3.18s\n",
      "18:\tlearn: 0.1309149\ttotal: 1.87s\tremaining: 3.05s\n",
      "19:\tlearn: 0.1259523\ttotal: 1.96s\tremaining: 2.94s\n",
      "20:\tlearn: 0.1231687\ttotal: 2.05s\tremaining: 2.83s\n",
      "21:\tlearn: 0.1200538\ttotal: 2.16s\tremaining: 2.74s\n",
      "22:\tlearn: 0.1167218\ttotal: 2.28s\tremaining: 2.67s\n",
      "23:\tlearn: 0.1133511\ttotal: 2.37s\tremaining: 2.56s\n",
      "24:\tlearn: 0.1105773\ttotal: 2.46s\tremaining: 2.46s\n",
      "25:\tlearn: 0.1084942\ttotal: 2.55s\tremaining: 2.35s\n",
      "26:\tlearn: 0.1064406\ttotal: 2.62s\tremaining: 2.23s\n",
      "27:\tlearn: 0.1008788\ttotal: 2.72s\tremaining: 2.14s\n",
      "28:\tlearn: 0.0980506\ttotal: 2.82s\tremaining: 2.04s\n",
      "29:\tlearn: 0.0955769\ttotal: 2.91s\tremaining: 1.94s\n",
      "30:\tlearn: 0.0928860\ttotal: 3.02s\tremaining: 1.85s\n",
      "31:\tlearn: 0.0907689\ttotal: 3.14s\tremaining: 1.76s\n",
      "32:\tlearn: 0.0862177\ttotal: 3.24s\tremaining: 1.67s\n",
      "33:\tlearn: 0.0847897\ttotal: 3.34s\tremaining: 1.57s\n",
      "34:\tlearn: 0.0824479\ttotal: 3.43s\tremaining: 1.47s\n",
      "35:\tlearn: 0.0787067\ttotal: 3.54s\tremaining: 1.38s\n",
      "36:\tlearn: 0.0770620\ttotal: 3.64s\tremaining: 1.28s\n",
      "37:\tlearn: 0.0756761\ttotal: 3.74s\tremaining: 1.18s\n",
      "38:\tlearn: 0.0733989\ttotal: 3.82s\tremaining: 1.08s\n",
      "39:\tlearn: 0.0721807\ttotal: 3.89s\tremaining: 974ms\n",
      "40:\tlearn: 0.0684287\ttotal: 3.97s\tremaining: 871ms\n",
      "41:\tlearn: 0.0664463\ttotal: 4.08s\tremaining: 777ms\n",
      "42:\tlearn: 0.0651837\ttotal: 4.19s\tremaining: 683ms\n",
      "43:\tlearn: 0.0636280\ttotal: 4.32s\tremaining: 589ms\n",
      "44:\tlearn: 0.0611342\ttotal: 4.46s\tremaining: 496ms\n",
      "45:\tlearn: 0.0585926\ttotal: 4.58s\tremaining: 399ms\n",
      "46:\tlearn: 0.0575999\ttotal: 4.67s\tremaining: 298ms\n",
      "47:\tlearn: 0.0565255\ttotal: 4.77s\tremaining: 199ms\n",
      "48:\tlearn: 0.0540653\ttotal: 4.84s\tremaining: 98.8ms\n",
      "49:\tlearn: 0.0526827\ttotal: 4.94s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4864957\ttotal: 101ms\tremaining: 4.93s\n",
      "1:\tlearn: 0.4010579\ttotal: 196ms\tremaining: 4.7s\n",
      "2:\tlearn: 0.3486181\ttotal: 332ms\tremaining: 5.2s\n",
      "3:\tlearn: 0.2860065\ttotal: 418ms\tremaining: 4.81s\n",
      "4:\tlearn: 0.2610838\ttotal: 511ms\tremaining: 4.6s\n",
      "5:\tlearn: 0.2400956\ttotal: 631ms\tremaining: 4.63s\n",
      "6:\tlearn: 0.2225585\ttotal: 736ms\tremaining: 4.52s\n",
      "7:\tlearn: 0.2118150\ttotal: 837ms\tremaining: 4.39s\n",
      "8:\tlearn: 0.2013288\ttotal: 920ms\tremaining: 4.19s\n",
      "9:\tlearn: 0.1864058\ttotal: 1.01s\tremaining: 4.03s\n",
      "10:\tlearn: 0.1791332\ttotal: 1.1s\tremaining: 3.9s\n",
      "11:\tlearn: 0.1695116\ttotal: 1.19s\tremaining: 3.76s\n",
      "12:\tlearn: 0.1647119\ttotal: 1.27s\tremaining: 3.63s\n",
      "13:\tlearn: 0.1553307\ttotal: 1.38s\tremaining: 3.54s\n",
      "14:\tlearn: 0.1530670\ttotal: 1.47s\tremaining: 3.43s\n",
      "15:\tlearn: 0.1465137\ttotal: 1.58s\tremaining: 3.35s\n",
      "16:\tlearn: 0.1432609\ttotal: 1.67s\tremaining: 3.24s\n",
      "17:\tlearn: 0.1370721\ttotal: 1.75s\tremaining: 3.12s\n",
      "18:\tlearn: 0.1337883\ttotal: 1.87s\tremaining: 3.06s\n",
      "19:\tlearn: 0.1296595\ttotal: 1.96s\tremaining: 2.94s\n",
      "20:\tlearn: 0.1271785\ttotal: 2.06s\tremaining: 2.84s\n",
      "21:\tlearn: 0.1232974\ttotal: 2.17s\tremaining: 2.77s\n",
      "22:\tlearn: 0.1213365\ttotal: 2.27s\tremaining: 2.66s\n",
      "23:\tlearn: 0.1165921\ttotal: 2.38s\tremaining: 2.58s\n",
      "24:\tlearn: 0.1138972\ttotal: 2.5s\tremaining: 2.5s\n",
      "25:\tlearn: 0.1112215\ttotal: 2.58s\tremaining: 2.38s\n",
      "26:\tlearn: 0.1082741\ttotal: 2.7s\tremaining: 2.3s\n",
      "27:\tlearn: 0.1047581\ttotal: 2.81s\tremaining: 2.21s\n",
      "28:\tlearn: 0.1015593\ttotal: 2.92s\tremaining: 2.11s\n",
      "29:\tlearn: 0.0974715\ttotal: 3.01s\tremaining: 2.01s\n",
      "30:\tlearn: 0.0940547\ttotal: 3.1s\tremaining: 1.9s\n",
      "31:\tlearn: 0.0885234\ttotal: 3.2s\tremaining: 1.8s\n",
      "32:\tlearn: 0.0823646\ttotal: 3.32s\tremaining: 1.71s\n",
      "33:\tlearn: 0.0796927\ttotal: 3.41s\tremaining: 1.6s\n",
      "34:\tlearn: 0.0754029\ttotal: 3.51s\tremaining: 1.5s\n",
      "35:\tlearn: 0.0743827\ttotal: 3.59s\tremaining: 1.4s\n",
      "36:\tlearn: 0.0729554\ttotal: 3.71s\tremaining: 1.3s\n",
      "37:\tlearn: 0.0720428\ttotal: 3.79s\tremaining: 1.2s\n",
      "38:\tlearn: 0.0699515\ttotal: 3.89s\tremaining: 1.1s\n",
      "39:\tlearn: 0.0671330\ttotal: 3.98s\tremaining: 996ms\n",
      "40:\tlearn: 0.0659952\ttotal: 4.1s\tremaining: 899ms\n",
      "41:\tlearn: 0.0622463\ttotal: 4.18s\tremaining: 797ms\n",
      "42:\tlearn: 0.0600606\ttotal: 4.28s\tremaining: 696ms\n",
      "43:\tlearn: 0.0587308\ttotal: 4.37s\tremaining: 595ms\n",
      "44:\tlearn: 0.0578762\ttotal: 4.46s\tremaining: 495ms\n",
      "45:\tlearn: 0.0563964\ttotal: 4.55s\tremaining: 396ms\n",
      "46:\tlearn: 0.0548080\ttotal: 4.64s\tremaining: 296ms\n",
      "47:\tlearn: 0.0537973\ttotal: 4.74s\tremaining: 197ms\n",
      "48:\tlearn: 0.0526228\ttotal: 4.86s\tremaining: 99.1ms\n",
      "49:\tlearn: 0.0510309\ttotal: 4.95s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.4793644\ttotal: 108ms\tremaining: 5.28s\n",
      "1:\tlearn: 0.3773207\ttotal: 217ms\tremaining: 5.2s\n",
      "2:\tlearn: 0.3300636\ttotal: 342ms\tremaining: 5.36s\n",
      "3:\tlearn: 0.2909906\ttotal: 432ms\tremaining: 4.97s\n",
      "4:\tlearn: 0.2650521\ttotal: 523ms\tremaining: 4.7s\n",
      "5:\tlearn: 0.2486424\ttotal: 636ms\tremaining: 4.67s\n",
      "6:\tlearn: 0.2316607\ttotal: 750ms\tremaining: 4.61s\n",
      "7:\tlearn: 0.2145347\ttotal: 873ms\tremaining: 4.58s\n",
      "8:\tlearn: 0.2002715\ttotal: 957ms\tremaining: 4.36s\n",
      "9:\tlearn: 0.1830546\ttotal: 1.05s\tremaining: 4.19s\n",
      "10:\tlearn: 0.1753871\ttotal: 1.14s\tremaining: 4.04s\n",
      "11:\tlearn: 0.1688800\ttotal: 1.26s\tremaining: 3.98s\n",
      "12:\tlearn: 0.1645565\ttotal: 1.36s\tremaining: 3.88s\n",
      "13:\tlearn: 0.1594869\ttotal: 1.46s\tremaining: 3.75s\n",
      "14:\tlearn: 0.1549921\ttotal: 1.54s\tremaining: 3.59s\n",
      "15:\tlearn: 0.1506067\ttotal: 1.66s\tremaining: 3.53s\n",
      "16:\tlearn: 0.1462440\ttotal: 1.75s\tremaining: 3.39s\n",
      "17:\tlearn: 0.1402711\ttotal: 1.87s\tremaining: 3.32s\n",
      "18:\tlearn: 0.1361830\ttotal: 1.96s\tremaining: 3.2s\n",
      "19:\tlearn: 0.1280562\ttotal: 2.09s\tremaining: 3.13s\n",
      "20:\tlearn: 0.1223237\ttotal: 2.2s\tremaining: 3.04s\n",
      "21:\tlearn: 0.1182692\ttotal: 2.32s\tremaining: 2.95s\n",
      "22:\tlearn: 0.1165219\ttotal: 2.46s\tremaining: 2.89s\n",
      "23:\tlearn: 0.1128595\ttotal: 2.55s\tremaining: 2.77s\n",
      "24:\tlearn: 0.1088890\ttotal: 2.67s\tremaining: 2.67s\n",
      "25:\tlearn: 0.1058793\ttotal: 2.75s\tremaining: 2.54s\n",
      "26:\tlearn: 0.1012722\ttotal: 2.85s\tremaining: 2.43s\n",
      "27:\tlearn: 0.0991593\ttotal: 2.99s\tremaining: 2.35s\n",
      "28:\tlearn: 0.0951155\ttotal: 3.11s\tremaining: 2.25s\n",
      "29:\tlearn: 0.0923926\ttotal: 3.2s\tremaining: 2.13s\n",
      "30:\tlearn: 0.0877541\ttotal: 3.3s\tremaining: 2.02s\n",
      "31:\tlearn: 0.0860914\ttotal: 3.41s\tremaining: 1.92s\n",
      "32:\tlearn: 0.0823884\ttotal: 3.56s\tremaining: 1.83s\n",
      "33:\tlearn: 0.0805000\ttotal: 3.65s\tremaining: 1.72s\n",
      "34:\tlearn: 0.0787392\ttotal: 3.75s\tremaining: 1.61s\n",
      "35:\tlearn: 0.0774628\ttotal: 3.87s\tremaining: 1.51s\n",
      "36:\tlearn: 0.0738371\ttotal: 3.97s\tremaining: 1.4s\n",
      "37:\tlearn: 0.0725306\ttotal: 4.09s\tremaining: 1.29s\n",
      "38:\tlearn: 0.0706251\ttotal: 4.19s\tremaining: 1.18s\n",
      "39:\tlearn: 0.0691414\ttotal: 4.3s\tremaining: 1.07s\n",
      "40:\tlearn: 0.0669289\ttotal: 4.42s\tremaining: 971ms\n",
      "41:\tlearn: 0.0640828\ttotal: 4.56s\tremaining: 868ms\n",
      "42:\tlearn: 0.0622237\ttotal: 4.65s\tremaining: 757ms\n",
      "43:\tlearn: 0.0605597\ttotal: 4.77s\tremaining: 650ms\n",
      "44:\tlearn: 0.0598033\ttotal: 4.88s\tremaining: 543ms\n",
      "45:\tlearn: 0.0582605\ttotal: 4.97s\tremaining: 432ms\n",
      "46:\tlearn: 0.0569356\ttotal: 5.08s\tremaining: 324ms\n",
      "47:\tlearn: 0.0547228\ttotal: 5.17s\tremaining: 215ms\n",
      "48:\tlearn: 0.0533896\ttotal: 5.32s\tremaining: 108ms\n",
      "49:\tlearn: 0.0525226\ttotal: 5.43s\tremaining: 0us\n",
      "Learning rate set to 0.354967\n",
      "0:\tlearn: 0.5053386\ttotal: 103ms\tremaining: 5.06s\n",
      "1:\tlearn: 0.3842845\ttotal: 237ms\tremaining: 5.68s\n",
      "2:\tlearn: 0.3417221\ttotal: 338ms\tremaining: 5.3s\n",
      "3:\tlearn: 0.3003372\ttotal: 431ms\tremaining: 4.95s\n",
      "4:\tlearn: 0.2715960\ttotal: 552ms\tremaining: 4.96s\n",
      "5:\tlearn: 0.2519926\ttotal: 647ms\tremaining: 4.74s\n",
      "6:\tlearn: 0.2325762\ttotal: 799ms\tremaining: 4.91s\n",
      "7:\tlearn: 0.2112276\ttotal: 920ms\tremaining: 4.83s\n",
      "8:\tlearn: 0.2006553\ttotal: 1.03s\tremaining: 4.69s\n",
      "9:\tlearn: 0.1854750\ttotal: 1.17s\tremaining: 4.67s\n",
      "10:\tlearn: 0.1765507\ttotal: 1.27s\tremaining: 4.52s\n",
      "11:\tlearn: 0.1714130\ttotal: 1.43s\tremaining: 4.52s\n",
      "12:\tlearn: 0.1669150\ttotal: 1.52s\tremaining: 4.32s\n",
      "13:\tlearn: 0.1576214\ttotal: 1.6s\tremaining: 4.11s\n",
      "14:\tlearn: 0.1526237\ttotal: 1.71s\tremaining: 4s\n",
      "15:\tlearn: 0.1483137\ttotal: 1.85s\tremaining: 3.94s\n",
      "16:\tlearn: 0.1404869\ttotal: 1.95s\tremaining: 3.79s\n",
      "17:\tlearn: 0.1352333\ttotal: 2.08s\tremaining: 3.7s\n",
      "18:\tlearn: 0.1299351\ttotal: 2.21s\tremaining: 3.61s\n",
      "19:\tlearn: 0.1228986\ttotal: 2.3s\tremaining: 3.45s\n",
      "20:\tlearn: 0.1195768\ttotal: 2.42s\tremaining: 3.34s\n",
      "21:\tlearn: 0.1156553\ttotal: 2.54s\tremaining: 3.23s\n",
      "22:\tlearn: 0.1100407\ttotal: 2.69s\tremaining: 3.16s\n",
      "23:\tlearn: 0.1055583\ttotal: 2.79s\tremaining: 3.02s\n",
      "24:\tlearn: 0.1030606\ttotal: 2.88s\tremaining: 2.88s\n",
      "25:\tlearn: 0.1009403\ttotal: 2.97s\tremaining: 2.74s\n",
      "26:\tlearn: 0.0973774\ttotal: 3.12s\tremaining: 2.65s\n",
      "27:\tlearn: 0.0937798\ttotal: 3.22s\tremaining: 2.53s\n",
      "28:\tlearn: 0.0888235\ttotal: 3.32s\tremaining: 2.4s\n",
      "29:\tlearn: 0.0873355\ttotal: 3.45s\tremaining: 2.3s\n",
      "30:\tlearn: 0.0830174\ttotal: 3.55s\tremaining: 2.17s\n",
      "31:\tlearn: 0.0808719\ttotal: 3.63s\tremaining: 2.04s\n",
      "32:\tlearn: 0.0783526\ttotal: 3.74s\tremaining: 1.92s\n",
      "33:\tlearn: 0.0743673\ttotal: 3.82s\tremaining: 1.8s\n",
      "34:\tlearn: 0.0716239\ttotal: 3.93s\tremaining: 1.68s\n",
      "35:\tlearn: 0.0705548\ttotal: 4.03s\tremaining: 1.57s\n",
      "36:\tlearn: 0.0683631\ttotal: 4.13s\tremaining: 1.45s\n",
      "37:\tlearn: 0.0677818\ttotal: 4.25s\tremaining: 1.34s\n",
      "38:\tlearn: 0.0663387\ttotal: 4.34s\tremaining: 1.22s\n",
      "39:\tlearn: 0.0646557\ttotal: 4.42s\tremaining: 1.1s\n",
      "40:\tlearn: 0.0637500\ttotal: 4.5s\tremaining: 988ms\n",
      "41:\tlearn: 0.0624617\ttotal: 4.58s\tremaining: 872ms\n",
      "42:\tlearn: 0.0607032\ttotal: 4.66s\tremaining: 758ms\n",
      "43:\tlearn: 0.0596195\ttotal: 4.75s\tremaining: 647ms\n",
      "44:\tlearn: 0.0575256\ttotal: 4.87s\tremaining: 541ms\n",
      "45:\tlearn: 0.0567292\ttotal: 4.94s\tremaining: 430ms\n",
      "46:\tlearn: 0.0558029\ttotal: 5.02s\tremaining: 320ms\n",
      "47:\tlearn: 0.0552908\ttotal: 5.1s\tremaining: 213ms\n",
      "48:\tlearn: 0.0517148\ttotal: 5.19s\tremaining: 106ms\n",
      "49:\tlearn: 0.0498268\ttotal: 5.3s\tremaining: 0us\n",
      "Learning rate set to 0.354991\n",
      "0:\tlearn: 0.4917351\ttotal: 120ms\tremaining: 5.9s\n",
      "1:\tlearn: 0.3745263\ttotal: 240ms\tremaining: 5.77s\n",
      "2:\tlearn: 0.3337455\ttotal: 320ms\tremaining: 5.01s\n",
      "3:\tlearn: 0.2943365\ttotal: 404ms\tremaining: 4.65s\n",
      "4:\tlearn: 0.2684860\ttotal: 521ms\tremaining: 4.69s\n",
      "5:\tlearn: 0.2448224\ttotal: 631ms\tremaining: 4.63s\n",
      "6:\tlearn: 0.2298468\ttotal: 748ms\tremaining: 4.59s\n",
      "7:\tlearn: 0.2123524\ttotal: 870ms\tremaining: 4.57s\n",
      "8:\tlearn: 0.2012901\ttotal: 956ms\tremaining: 4.36s\n",
      "9:\tlearn: 0.1825800\ttotal: 1.09s\tremaining: 4.37s\n",
      "10:\tlearn: 0.1755724\ttotal: 1.23s\tremaining: 4.34s\n",
      "11:\tlearn: 0.1681823\ttotal: 1.33s\tremaining: 4.21s\n",
      "12:\tlearn: 0.1630141\ttotal: 1.42s\tremaining: 4.03s\n",
      "13:\tlearn: 0.1588874\ttotal: 1.51s\tremaining: 3.88s\n",
      "14:\tlearn: 0.1517853\ttotal: 1.65s\tremaining: 3.84s\n",
      "15:\tlearn: 0.1466084\ttotal: 1.74s\tremaining: 3.7s\n",
      "16:\tlearn: 0.1427617\ttotal: 1.83s\tremaining: 3.55s\n",
      "17:\tlearn: 0.1381756\ttotal: 1.97s\tremaining: 3.5s\n",
      "18:\tlearn: 0.1300924\ttotal: 2.1s\tremaining: 3.42s\n",
      "19:\tlearn: 0.1272538\ttotal: 2.19s\tremaining: 3.29s\n",
      "20:\tlearn: 0.1232246\ttotal: 2.3s\tremaining: 3.18s\n",
      "21:\tlearn: 0.1201178\ttotal: 2.38s\tremaining: 3.04s\n",
      "22:\tlearn: 0.1165696\ttotal: 2.49s\tremaining: 2.92s\n",
      "23:\tlearn: 0.1136729\ttotal: 2.61s\tremaining: 2.83s\n",
      "24:\tlearn: 0.1098542\ttotal: 2.71s\tremaining: 2.71s\n",
      "25:\tlearn: 0.1074865\ttotal: 2.83s\tremaining: 2.61s\n",
      "26:\tlearn: 0.1048637\ttotal: 2.93s\tremaining: 2.5s\n",
      "27:\tlearn: 0.1031061\ttotal: 3.06s\tremaining: 2.41s\n",
      "28:\tlearn: 0.0980497\ttotal: 3.18s\tremaining: 2.31s\n",
      "29:\tlearn: 0.0928338\ttotal: 3.26s\tremaining: 2.17s\n",
      "30:\tlearn: 0.0905704\ttotal: 3.34s\tremaining: 2.05s\n",
      "31:\tlearn: 0.0873413\ttotal: 3.48s\tremaining: 1.96s\n",
      "32:\tlearn: 0.0845326\ttotal: 3.61s\tremaining: 1.86s\n",
      "33:\tlearn: 0.0782649\ttotal: 3.7s\tremaining: 1.74s\n",
      "34:\tlearn: 0.0750263\ttotal: 3.83s\tremaining: 1.64s\n",
      "35:\tlearn: 0.0734242\ttotal: 3.96s\tremaining: 1.54s\n",
      "36:\tlearn: 0.0726169\ttotal: 4.08s\tremaining: 1.43s\n",
      "37:\tlearn: 0.0709189\ttotal: 4.18s\tremaining: 1.32s\n",
      "38:\tlearn: 0.0698770\ttotal: 4.28s\tremaining: 1.21s\n",
      "39:\tlearn: 0.0680469\ttotal: 4.38s\tremaining: 1.09s\n",
      "40:\tlearn: 0.0656720\ttotal: 4.47s\tremaining: 981ms\n",
      "41:\tlearn: 0.0630902\ttotal: 4.58s\tremaining: 872ms\n",
      "42:\tlearn: 0.0623612\ttotal: 4.68s\tremaining: 762ms\n",
      "43:\tlearn: 0.0616191\ttotal: 4.76s\tremaining: 650ms\n",
      "44:\tlearn: 0.0595881\ttotal: 4.86s\tremaining: 541ms\n",
      "45:\tlearn: 0.0583180\ttotal: 4.94s\tremaining: 430ms\n",
      "46:\tlearn: 0.0541168\ttotal: 5.07s\tremaining: 324ms\n",
      "47:\tlearn: 0.0531998\ttotal: 5.2s\tremaining: 217ms\n",
      "48:\tlearn: 0.0518538\ttotal: 5.27s\tremaining: 108ms\n",
      "49:\tlearn: 0.0506466\ttotal: 5.36s\tremaining: 0us\n",
      "Learning rate set to 0.390458\n",
      "0:\tlearn: 0.4766219\ttotal: 128ms\tremaining: 6.25s\n",
      "1:\tlearn: 0.3690289\ttotal: 233ms\tremaining: 5.6s\n",
      "2:\tlearn: 0.3226103\ttotal: 331ms\tremaining: 5.18s\n",
      "3:\tlearn: 0.2807691\ttotal: 425ms\tremaining: 4.89s\n",
      "4:\tlearn: 0.2608972\ttotal: 515ms\tremaining: 4.64s\n",
      "5:\tlearn: 0.2331633\ttotal: 626ms\tremaining: 4.59s\n",
      "6:\tlearn: 0.2130689\ttotal: 763ms\tremaining: 4.69s\n",
      "7:\tlearn: 0.1973148\ttotal: 876ms\tremaining: 4.6s\n",
      "8:\tlearn: 0.1848328\ttotal: 995ms\tremaining: 4.53s\n",
      "9:\tlearn: 0.1717317\ttotal: 1.12s\tremaining: 4.48s\n",
      "10:\tlearn: 0.1611049\ttotal: 1.23s\tremaining: 4.35s\n",
      "11:\tlearn: 0.1515676\ttotal: 1.36s\tremaining: 4.29s\n",
      "12:\tlearn: 0.1468286\ttotal: 1.46s\tremaining: 4.15s\n",
      "13:\tlearn: 0.1435100\ttotal: 1.6s\tremaining: 4.12s\n",
      "14:\tlearn: 0.1385044\ttotal: 1.71s\tremaining: 3.99s\n",
      "15:\tlearn: 0.1352783\ttotal: 1.79s\tremaining: 3.8s\n",
      "16:\tlearn: 0.1303558\ttotal: 1.88s\tremaining: 3.65s\n",
      "17:\tlearn: 0.1267823\ttotal: 1.99s\tremaining: 3.54s\n",
      "18:\tlearn: 0.1222228\ttotal: 2.1s\tremaining: 3.42s\n",
      "19:\tlearn: 0.1174604\ttotal: 2.23s\tremaining: 3.35s\n",
      "20:\tlearn: 0.1154644\ttotal: 2.35s\tremaining: 3.25s\n",
      "21:\tlearn: 0.1132777\ttotal: 2.46s\tremaining: 3.14s\n",
      "22:\tlearn: 0.1109222\ttotal: 2.58s\tremaining: 3.02s\n",
      "23:\tlearn: 0.1079507\ttotal: 2.66s\tremaining: 2.89s\n",
      "24:\tlearn: 0.1044650\ttotal: 2.79s\tremaining: 2.79s\n",
      "25:\tlearn: 0.0999156\ttotal: 2.89s\tremaining: 2.67s\n",
      "26:\tlearn: 0.0972372\ttotal: 3.01s\tremaining: 2.57s\n",
      "27:\tlearn: 0.0931636\ttotal: 3.1s\tremaining: 2.44s\n",
      "28:\tlearn: 0.0882971\ttotal: 3.19s\tremaining: 2.31s\n",
      "29:\tlearn: 0.0869483\ttotal: 3.29s\tremaining: 2.19s\n",
      "30:\tlearn: 0.0845575\ttotal: 3.43s\tremaining: 2.1s\n",
      "31:\tlearn: 0.0838902\ttotal: 3.52s\tremaining: 1.98s\n",
      "32:\tlearn: 0.0818041\ttotal: 3.63s\tremaining: 1.87s\n",
      "33:\tlearn: 0.0801960\ttotal: 3.73s\tremaining: 1.76s\n",
      "34:\tlearn: 0.0761814\ttotal: 3.82s\tremaining: 1.64s\n",
      "35:\tlearn: 0.0748753\ttotal: 3.91s\tremaining: 1.52s\n",
      "36:\tlearn: 0.0704692\ttotal: 4.03s\tremaining: 1.42s\n",
      "37:\tlearn: 0.0689011\ttotal: 4.12s\tremaining: 1.3s\n",
      "38:\tlearn: 0.0661951\ttotal: 4.22s\tremaining: 1.19s\n",
      "39:\tlearn: 0.0648224\ttotal: 4.32s\tremaining: 1.08s\n",
      "40:\tlearn: 0.0640314\ttotal: 4.48s\tremaining: 984ms\n",
      "41:\tlearn: 0.0635796\ttotal: 4.6s\tremaining: 875ms\n",
      "42:\tlearn: 0.0623980\ttotal: 4.7s\tremaining: 765ms\n",
      "43:\tlearn: 0.0609701\ttotal: 4.84s\tremaining: 661ms\n",
      "44:\tlearn: 0.0600248\ttotal: 4.97s\tremaining: 552ms\n",
      "45:\tlearn: 0.0593300\ttotal: 5.08s\tremaining: 442ms\n",
      "46:\tlearn: 0.0574586\ttotal: 5.16s\tremaining: 329ms\n",
      "47:\tlearn: 0.0562329\ttotal: 5.23s\tremaining: 218ms\n",
      "48:\tlearn: 0.0554970\ttotal: 5.32s\tremaining: 108ms\n",
      "49:\tlearn: 0.0546664\ttotal: 5.41s\tremaining: 0us\n",
      "Model saved to disk at: temporary_files/CatBoost_Model.pickle\n",
      "Model saved to disk at: temporary_files/Random_Forest_Model.pickle\n",
      "Model building complete, final results with train/test datasets below:\n",
      "\n",
      "           model          best_params  best_score  best_standard_deviation\n",
      "0       CatBoost   {'iterations': 50}    0.954328                 0.004435\n",
      "1  Random_Forest  {'n_estimators': 1}    0.784346                 0.017832\n"
     ]
    }
   ],
   "source": [
    "# Build the models.\n",
    "# TODO - EXPLAIN SAVE OPTION....\n",
    "ml_model.build_models(save_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the models now built, we can see the models seem to be xxxxx\n",
    "\n",
    "We can now evaluate the quality of the models on the validation dataset. Again, thankfully the accuracy is quite high.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the CatBoost model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CatComp       0.96      0.94      0.95       586\n",
      "  NotCatComp       0.96      0.97      0.97       826\n",
      "\n",
      "    accuracy                           0.96      1412\n",
      "   macro avg       0.96      0.96      0.96      1412\n",
      "weighted avg       0.96      0.96      0.96      1412\n",
      "\n",
      "Classification report for the Random_Forest model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     CatComp       0.74      0.71      0.73       586\n",
      "  NotCatComp       0.80      0.82      0.81       826\n",
      "\n",
      "    accuracy                           0.78      1412\n",
      "   macro avg       0.77      0.77      0.77      1412\n",
      "weighted avg       0.78      0.78      0.78      1412\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model quality\n",
    "print(ml_model.evaluate_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular way to evaluate model quality is to generate confusion matrices. \n",
    "\n",
    "We can do that as well as shown below. \n",
    "You can easily plot these confusion matrices in whatever graphing program you like, but in this case, I will use seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = ml_model.generate_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(confusion_matrices[\"CatBoost\"], annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(confusion_matrices[\"Random_Forest\"], annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Work up the Machine Learning with the post_proccessing.py module. \n",
    "\n",
    "With this module, we can analyse our results in more detail to understand what features each model determined where important for distignugshing between each state. \n",
    "\n",
    "In order to perform the analysis we will need to load in the models previously generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will make an instance of the SupervisedPostProcessor class.\n",
    "post_proc = post_proccessing.SupervisedPostProcessor(\n",
    "    out_dir=\"outputs/retro_aldol_ml\",\n",
    ")\n",
    "\n",
    "# Option 1 - Load models from the instance of the SupervisedModel class. \n",
    "post_proc.load_models_from_instance(supervised_model=ml_model)\n",
    "\n",
    "# Option 2 - Load models from disk.\n",
    "post_proc.load_models_from_disk(models_to_use=[\"CatBoost\", \"Random_Forest\"]) # \"Ada_Boost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/retro_aldol_ml/CatBoost_Feature_Importances.csv written to disk.\n",
      "outputs/retro_aldol_ml/Random_Forest_Feature_Importances.csv written to disk.\n",
      "All feature importances written to disk.\n"
     ]
    }
   ],
   "source": [
    "# After preparing the class we can now determine the feature importances for each model.\n",
    "post_proc.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/retro_aldol_ml/CatBoost_Per_Residue_Importances.csv written to disk.\n",
      "outputs/retro_aldol_ml/Random_Forest_Per_Residue_Importances.csv written to disk.\n",
      "All per residue feature importance scores were saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# We can also project these per feature importances onto the per-residue level. \n",
    "# This is done by summing each residues features importances and normalising so that the residue\n",
    "#  with the greatest overall  \n",
    "post_proc.get_per_res_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['out_dir', 'feat_names', 'best_models', 'all_feature_importances', 'all_per_residue_scores'])\n"
     ]
    }
   ],
   "source": [
    "# Again, if we take a look at the class attributes we can see the per feature and \n",
    "# per residue importances were not just saved to disk, but are also now stored in the class\n",
    "# meaning you can analyse them here if you wish. \n",
    "print(post_proc.__dict__.keys())\n",
    "all_per_res_scores = post_proc.all_per_residue_scores\n",
    "all_feature_scores = post_proc.all_feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 Projecting the Results onto Protein Structures with the pymol_projections.py module. \n",
    " \n",
    "Naturally, we may want to visualise some of the results we have generated above onto a protein structure. We can take advantage of the functions provided in the pymol_projections.py module to do this. \n",
    "\n",
    "As the name suggests this will output [PyMOL](https://pymol.org/) compatible python scripts which can be run to represent the results at either the: \n",
    "\n",
    "1. Per feature level. (Cylinders are drawn between both residues in each feature, with the cylinder radii marking how large the relative importance is. \n",
    "2. Per residue level. The carbon alpha of each residue will be depicted as a sphere, with the sphere radii depicting the relative importance of the residue for the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: outputs/retro_aldol_ml/CatBoost_Pymol_Per_Res_Scores.py was written to disk.\n",
      "The file: outputs/retro_aldol_ml/Random_Forest_Pymol_Per_Res_Scores.py was written to disk.\n"
     ]
    }
   ],
   "source": [
    "pymol_projections.project_multiple_per_res_scores(\n",
    "    all_per_res_scores=all_per_res_scores,\n",
    "    out_dir=\"outputs/retro_aldol_ml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: outputs/retro_aldol_ml/CatBoost_Pymol_Per_Feature_Scores.py was written to disk.\n",
      "The file: outputs/retro_aldol_ml/Random_Forest_Pymol_Per_Feature_Scores.py was written to disk.\n"
     ]
    }
   ],
   "source": [
    "pymol_projections.project_multiple_per_feature_scores(\n",
    "    all_feature_scores=all_feature_scores,\n",
    "    numb_features=\"all\",\n",
    "    out_dir=\"outputs/retro_aldol_ml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ADD Picture of the outputs here as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "add0b5d4ce7b8e8a859fa0dda4e7913231effb3978a57212389923662b8875fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('ML_Py3_8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
