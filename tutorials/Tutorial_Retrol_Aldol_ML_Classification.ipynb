{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial for Supervised and Unsupervised Learning on Simulations of a Retro Aldolase\n",
    "\n",
    "In this jupyter notebook we will use the model_building.py module to identify differences in the molecular interactions for a retro aldolase when it is in a catatlytically competent state and when it is \n",
    "\n",
    "\n",
    "across PTP1B\n",
    "when the WPD-loop of PTP1B is in the Closed state, versus when the WPD-loop is in the Open state.\n",
    "This notebook will also cover all the pre- and post-processing steps requireds to prepare, analyse and visualise the results.\n",
    "\n",
    "The dataset used here is for PTP1B is the same as what we used in the manuscript. \n",
    "\n",
    "<center><img src=\"miscellaneous/TODO.png\" alt=\"Drawing\" style=\"width: 70%\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # note temporary... \n",
    "sys.path.append(\"..\") # note temporary...\n",
    "\n",
    "from key_interactions_finder import pycontact_processing\n",
    "from key_interactions_finder import data_preperation\n",
    "from key_interactions_finder import model_building\n",
    "from key_interactions_finder import post_proccessing\n",
    "from key_interactions_finder import pymol_projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Process PyContact files with the pycontact_processing.py module \n",
    "\n",
    "In this section we will work with the PyContact output files generated. \n",
    "Here we will merge our seperate runs together and remove any false interactions that can be generated by the PyContact library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycontact_files_horizontal = [\"PyContact_Per_Frame_Interactions_Block1.csv\", \"PyContact_Per_Frame_Interactions_Block2.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block3.csv\", \"PyContact_Per_Frame_Interactions_Block4.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block5.csv\", \"PyContact_Per_Frame_Interactions_Block6.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block7.csv\", \"PyContact_Per_Frame_Interactions_Block8.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block9.csv\", \"PyContact_Per_Frame_Interactions_Block10.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block11.csv\", \"PyContact_Per_Frame_Interactions_Block12.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block13.csv\", \"PyContact_Per_Frame_Interactions_Block14.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block15.csv\", \"PyContact_Per_Frame_Interactions_Block16.csv\",\n",
    "                              \"PyContact_Per_Frame_Interactions_Block17.csv\"]\n",
    "\n",
    "pycontact_dataset = pycontact_processing.PyContactInitializer(\n",
    "    pycontact_files=pycontact_files_horizontal,\n",
    "    multiple_files=True,\n",
    "    merge_files_method=\"horizontal\",  \n",
    "    remove_false_interactions=True,\n",
    "    in_dir=\"datasets/retrol_aldolase_data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As outputted above, we can inspect the newly prepared dataset by accessing the '.prepared_df' class attribute as follows:\n",
    "pycontact_dataset.prepared_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Prepare the Dataset for Machine Learning with the data_preperation.py module. \n",
    "\n",
    "In this step, we take our processed dataframe and merge our per frame classifications file to it.\n",
    "We can also optionally perform several forms of filtering to select what types of interactions we\n",
    "would like to study.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we generate an instance of the SupervisedFeatureData class (because we have per frame class labels).\n",
    "classifications_file = \"datasets/retrol_aldolase_data/4a2s_RA95_5_Classifications.txt\"\n",
    "\n",
    "supervised_dataset = data_preperation.SupervisedFeatureData(\n",
    "    input_df=pycontact_dataset.prepared_df,\n",
    "    target_file=classifications_file,\n",
    "    is_classification=True,\n",
    "    header_present=True # If your target_file has a header present, set to True.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated above to access the newly generated dataframe we can use the class attribute as follows\n",
    "supervised_dataset.df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optional Feature Filtering\n",
    "\n",
    "In the above dataframe we have 3057 columns (so 3056 features + 1 target). We can take all of these forward for the stastical analysis or we can perform some filtering in advance (the choice is yours). \n",
    "There are five built in filtering methods available to you to perform filtering:\n",
    "\n",
    "1. **filter_by_occupancy(min_occupancy)** - Remove features that have an %occupancy less than the provided cut-off. %Occupancy is the % of frames with a non 0 value, i.e. the interaction is present in that frame.\n",
    "\n",
    "2. **filter_by_interaction_type(interaction_types_included)** - PyContact defines four types of interactions (\"Hbond\", \"Saltbr\", \"Hydrophobic\", \"Other\"). You select the interactions your want to include.\n",
    "\n",
    "3. **filter_by_main_or_side_chain(main_side_chain_types_included)** - PyContact can also define if each interaction is primarily from the backbone or side-chain for each residue. You select the interaction combinations you want to include. Options are: \"bb-bb\", \"sc-sc\", \"bb-sc\", \"sc-bb\". Where bb = backbone and sc = sidechain.\n",
    "\n",
    "4. **filter_by_avg_strength(average_strength_cut_off)** - PyContact calculates a per frame contact score/strength for each interaction. You can filter features by the average score. Values below the cut-off are removed. \n",
    "\n",
    "5. **filter_by_occupancy_by_class(min_occupancy)** - Special alternative to the the standard filter features by occupancy method. %occupancy is determined for each class (as opposed to whole dataset), meaning only observations from 1 class have to meet the cut-off to keep the feature. Only avaible to datasets with a categorical target variable (classification). \n",
    "\n",
    "\n",
    "Finally if at any point in time you want to reset any filtering you've already performed, you can use the following method: \n",
    "\n",
    "6. **reset_filtering()** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# An example of filtering the dataset using the 4 available methods. \n",
    "supervised_dataset.reset_filtering()\n",
    "print(f\"Number of features before any filtering: {len(supervised_dataset.df_processed.columns)}\")\n",
    "\n",
    "# Features with a %occupancy of less than 25% are removed. \n",
    "supervised_dataset.filter_by_occupancy_by_class(min_occupancy=25)\n",
    "print(f\"Number of features after filtering by occupancy: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# No filtering performed here as all possible combinations are included. \n",
    "supervised_dataset.filter_by_interaction_type(\n",
    "    interaction_types_included=[\"Hbond\", \"Saltbr\", \"Hydrophobic\", \"Other\"])  \n",
    "print(f\"Number of features after NOT filtering by interaction type: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# No filtering performed here as all possible combinations are included. \n",
    "supervised_dataset.filter_by_main_or_side_chain(\n",
    "    main_side_chain_types_included=[\"bb-bb\", \"sc-sc\", \"bb-sc\", \"sc-bb\"] \n",
    ")\n",
    "print(f\"Number of features after NOT filtering by main or side chain: {len(supervised_dataset.df_filtered.columns)}\")\n",
    "\n",
    "# Features with an average interaction strength less than 1.0 will be removed. \n",
    "supervised_dataset.filter_by_avg_strength(\n",
    "    average_strength_cut_off=1.0,  \n",
    ")\n",
    "print(f\"Number of features after filtering by average interaction scores: {len(supervised_dataset.df_filtered.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the class attributes of our SupervisedFeatureData() instance (we called it: supervised_dataset) using the special \"\\_\\_dict__\" method we can see two dataframes we could use in the machine learning to follow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_dataset.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are: \n",
    "- 'df_processed' - The unfiltered dataframe, 3057 features\n",
    "- 'df_filtered' - The filtered dataframe. Less than 3057 features. \n",
    "\n",
    "In the following section we will use the filtered dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Perform the Machine Learning with the model_building.py module. \n",
    "\n",
    "Now we will setup and run the supervised machine learning (ML) on the retro aldolase enzyme. Here we will apply to ML to distinguish between catalytically active and inactive conformations of the enzyme towards catalysis of XXXX. \n",
    "\n",
    "Describe the ML in more detail TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_dataset.df_filtered[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output from the above cell we can see three classes, to keep things simple we will use the clearly specified classes of \"CatComp\" and \"NotCatComp\". We can specify this with the \"classes_to_use\" parameter in the following code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model.\n",
    "ml_model = model_building.ClassificationModel(\n",
    "    dataset=supervised_dataset.df_filtered,\n",
    "    evaluation_split_ratio=0.15,\n",
    "    classes_to_use=[\"CatComp\", \"NotCatComp\"], \n",
    "    models_to_use=[\"CatBoost\", \"XGBoost\", \"Random_Forest\"],\n",
    "    scaling_method=\"min_max\",\n",
    "    out_dir=\"outputs/retro_aldol_ml_classification\",\n",
    "    cross_validation_splits=5, \n",
    "    cross_validation_repeats=3,\n",
    "    search_approach=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can go ahead and build the models.\n",
    "We have one optional parameter in the command below which is to save the models generated. This can be useful if you ever want to back and do the post-processing (described in steps 4 and 5) in the future for instance. \n",
    "\n",
    "If you set this to true all the files required will be saved to a folder called \"temporary_files\" in your current working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model.build_models(save_models=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the models now built, we can see the models seem to be quite equally matched in terms of accuracy for the train and test sets. \n",
    "We can now evaluate the quality of the models on the validation dataset (also sometimes refered to as the hold-out set).\n",
    "\n",
    "For each ML model built a pandas dataframe is generated which contains key results on the validation dataset. \n",
    "If you are unfamiliar with any of the terms presented below, [feel free to check out this guide from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = ml_model.evaluate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[\"CatBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports[\"Random_Forest\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular way to evaluate model quality is to generate confusion matrices. \n",
    "Using the below command we can generate confusion matrices (stored as numpy arrays) for each model we generated. \n",
    "\n",
    "You can then easily plot these confusion matrices in whatever graphing program you like. In this case, I will use seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices = ml_model.generate_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrices[\"XGBoost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - write in plotly instead... \n",
    "import seaborn as sns\n",
    "axis_labels = [\"NotCatComp\", \"CatComp\"]\n",
    "ax = sns.heatmap(confusion_matrices[\"XGBoost\"], annot=True, fmt=\"d\", xticklabels=axis_labels, yticklabels=axis_labels, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(confusion_matrices[\"CatBoost\"], annot=True, fmt=\"d\", xticklabels=axis_labels, yticklabels=axis_labels, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(confusion_matrices[\"Random_Forest\"], annot=True, fmt=\"d\", xticklabels=axis_labels, yticklabels=axis_labels, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Work up the Machine Learning with the post_proccessing.py module. \n",
    "\n",
    "With this module, we can analyse our results in more detail to understand what features each model determined where important for distignugshing between each state. \n",
    "\n",
    "In order to perform the analysis we will need to provide the models generated in step 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will make an instance of the SupervisedPostProcessor class.\n",
    "post_proc = post_proccessing.SupervisedPostProcessor(\n",
    "    out_dir=\"outputs/retro_aldol_ml_classification\",\n",
    ")\n",
    "\n",
    "# Option 1 - Load models from the instance of the SupervisedModel class. \n",
    "post_proc.load_models_from_instance(supervised_model=ml_model)\n",
    "\n",
    "# Option 2 - Load models from disk.\n",
    "#post_proc.load_models_from_disk(models_to_use=[\"XGBoost\", \"CatBoost\", \"Random_Forest\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After preparing the class we can now determine the feature importances for each model.\n",
    "post_proc.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also project these per feature importances onto the per-residue level. \n",
    "# This is done by summing each residues features importances and normalising so that the residue\n",
    "#  with the greatest overall  \n",
    "post_proc.get_per_res_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, if we take a look at the class attributes we can see the per feature and \n",
    "# per residue importances were not just saved to disk, but are also now stored in the class\n",
    "# meaning you can analyse them here if you wish. \n",
    "print(post_proc.__dict__.keys())\n",
    "all_per_res_scores = post_proc.all_per_residue_scores\n",
    "all_feature_scores = post_proc.all_feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise these results graphically in an interactive manner with the plotly graphing library. \n",
    "If you don't have that library installed you can do so now by uncommenting the code block below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "df_all_per_res_scores = pd.DataFrame(all_per_res_scores).reset_index()\n",
    "df_all_per_res_scores = df_all_per_res_scores.rename(columns={\"index\": \"Residue Number\"})\n",
    "df_all_per_res_scores = df_all_per_res_scores.sort_values([\"Residue Number\"], ascending=True)\n",
    "df_all_per_res_scores.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_all_per_res_scores, x=\"Residue Number\", y=[\"CatBoost\", \"XGBoost\", \"Random_Forest\"])\n",
    "fig.update_layout(\n",
    "    title=\"Per residue Relative Importances for All 3 Machine Learning Models\",\n",
    "    xaxis_title=\"Residue Number\",\n",
    "    yaxis_title=\"Relative Importance\",\n",
    "    legend_title=\"ML Models\",\n",
    "    font=dict(size=16)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Projecting the Results onto Protein Structures with the pymol_projections.py module. \n",
    " \n",
    "Naturally, we may want to visualise some of the results we have generated above onto a protein structure. We can take advantage of the functions provided in the pymol_projections.py module to do this. \n",
    "\n",
    "As the name suggests this will output [PyMOL](https://pymol.org/) compatible python scripts which can be run to represent the results at either the: \n",
    "\n",
    "1. Per feature level. (Cylinders are drawn between both residues in each feature, with the cylinder radii marking how large the relative importance is. \n",
    "2. Per residue level. The carbon alpha of each residue will be depicted as a sphere, with the sphere radii depicting the relative importance of the residue for the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymol_projections.project_multiple_per_res_scores(\n",
    "    all_per_res_scores=all_per_res_scores,\n",
    "    out_dir=\"outputs/retro_aldol_ml_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymol_projections.project_multiple_per_feature_scores(\n",
    "    all_feature_scores=all_feature_scores,\n",
    "    numb_features=\"all\",\n",
    "    out_dir=\"outputs/retro_aldol_ml_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ADD Picture of the outputs here as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "add0b5d4ce7b8e8a859fa0dda4e7913231effb3978a57212389923662b8875fe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('ML_Py3_8': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
